{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7895d5",
   "metadata": {
    "papermill": {
     "duration": 0.005183,
     "end_time": "2025-08-17T10:19:27.966297",
     "exception": false,
     "start_time": "2025-08-17T10:19:27.961114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üöÄ Self-Developed Dynamic Graph Learning Framework AdaptoFlux: Fully Automated Modeling on Titanic\n",
    "\n",
    "Welcome to **AdaptoFlux** ‚Äî an interpretable machine learning framework based on automatic function graph growth.\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Load preprocessed data\n",
    "- Train a dynamic function graph model\n",
    "- Save the graph structure as JSON\n",
    "- Visualize the graph (interactive)\n",
    "- Generate a Kaggle submission file\n",
    "\n",
    "üëâ All code is open-source. Feel free to Star & Fork!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4cbe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:27.976904Z",
     "iopub.status.busy": "2025-08-17T10:19:27.976579Z",
     "iopub.status.idle": "2025-08-17T10:19:29.633053Z",
     "shell.execute_reply": "2025-08-17T10:19:29.631786Z"
    },
    "papermill": {
     "duration": 1.66367,
     "end_time": "2025-08-17T10:19:29.634980",
     "exception": false,
     "start_time": "2025-08-17T10:19:27.971310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! git init\n",
    "! git clone https://github.com/gugugu12138/AdaptoFlux  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30210c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:29.648299Z",
     "iopub.status.busy": "2025-08-17T10:19:29.647300Z",
     "iopub.status.idle": "2025-08-17T10:19:35.015574Z",
     "shell.execute_reply": "2025-08-17T10:19:35.014279Z"
    },
    "papermill": {
     "duration": 5.37669,
     "end_time": "2025-08-17T10:19:35.017538",
     "exception": false,
     "start_time": "2025-08-17T10:19:29.640848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -r /kaggle/working/AdaptoFlux/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8aabc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:35.031530Z",
     "iopub.status.busy": "2025-08-17T10:19:35.031160Z",
     "iopub.status.idle": "2025-08-17T10:19:35.039552Z",
     "shell.execute_reply": "2025-08-17T10:19:35.038134Z"
    },
    "papermill": {
     "duration": 0.017231,
     "end_time": "2025-08-17T10:19:35.041231",
     "exception": false,
     "start_time": "2025-08-17T10:19:35.024000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /kaggle/working/AdaptoFlux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1b2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:35.054410Z",
     "iopub.status.busy": "2025-08-17T10:19:35.054056Z",
     "iopub.status.idle": "2025-08-17T10:19:39.013590Z",
     "shell.execute_reply": "2025-08-17T10:19:39.012572Z"
    },
    "papermill": {
     "duration": 3.968018,
     "end_time": "2025-08-17T10:19:39.015287",
     "exception": false,
     "start_time": "2025-08-17T10:19:35.047269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import traceback\n",
    "from ATF.core.adaptoflux import AdaptoFlux\n",
    "from ATF.CollapseManager.collapse_functions import CollapseMethod\n",
    "from ATF.ModelTrainer.LayerGrowTrainer.layer_grow_trainer import LayerGrowTrainer\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(levelname)s] %(name)s: %(message)s'\n",
    ")\n",
    "\n",
    "logging.info(\"‚úÖ Logging Test: Configuration successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3b1f2",
   "metadata": {
    "papermill": {
     "duration": 0.005384,
     "end_time": "2025-08-17T10:19:39.026689",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.021305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üß© Custom Method Pool (methods.py)\n",
    "\n",
    "Ensure `methods.py` defines basic functions (e.g., `add_values`, `multiply_values`, etc.) decorated with `@method_profile`. An example method pool is located at /kaggle/working/AdaptoFlux/examples/kaggle/titanic/methods.py\n",
    "\n",
    "Content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4bf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:39.039788Z",
     "iopub.status.busy": "2025-08-17T10:19:39.039269Z",
     "iopub.status.idle": "2025-08-17T10:19:39.054156Z",
     "shell.execute_reply": "2025-08-17T10:19:39.053120Z"
    },
    "papermill": {
     "duration": 0.023626,
     "end_time": "2025-08-17T10:19:39.055957",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.032331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code block does not need to be executed\n",
    "import math\n",
    "from ATF.methods.decorators import method_profile\n",
    "\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # ‚úÖ Unified group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def return_value(x):\n",
    "    \"\"\"\n",
    "    Returns the input value\n",
    "    :param x: Input value\n",
    "    :return: Original value\n",
    "    \"\"\"\n",
    "    return [x]\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar', 'scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # ‚úÖ Unified group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def add_values(x, y):\n",
    "    \"\"\"\n",
    "    Adds two values\n",
    "    :param x: First number\n",
    "    :param y: Second number\n",
    "    :return: Sum of x and y\n",
    "    \"\"\"\n",
    "    return [x + y]\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar', 'scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # ‚úÖ Unified group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def calculate_difference(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the difference between two numbers\n",
    "    :param a: Minuend\n",
    "    :param b: Subtrahend\n",
    "    :return: Difference\n",
    "    \"\"\"\n",
    "    return [a - b]\n",
    "\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar', 'scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # ‚úÖ Unified group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def multiply_values(x, y):\n",
    "    \"\"\"\n",
    "    Multiplies two values\n",
    "    :param x: First number\n",
    "    :param y: Second number\n",
    "    :return: Product of x and y\n",
    "    \"\"\"\n",
    "    return [x * y]\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar', 'scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def divide_values(x, y):\n",
    "    \"\"\"\n",
    "    Divides two values (with zero check)\n",
    "    :param x: Dividend\n",
    "    :param y: Divisor\n",
    "    :return: x / y or 0 if y = 0\n",
    "    \"\"\"\n",
    "    return [x / y if y != 0 else 0]\n",
    "\n",
    "@method_profile(\n",
    "    output_count=2,\n",
    "    input_types=['scalar'],\n",
    "    output_types=['scalar', 'scalar'],\n",
    "    group=\"basic\",           # ‚úÖ Unified group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def return_two_values(x):\n",
    "    \"\"\"\n",
    "    Returns two copies of the input value\n",
    "    :param x: Input value\n",
    "    :return: Original value\n",
    "    \"\"\"\n",
    "    return [x, x]\n",
    "\n",
    "# No improvement, only slows down speed and increases computation\n",
    "# @method_profile(\n",
    "#     output_count=3,\n",
    "#     input_types=['scalar'],\n",
    "#     output_types=['scalar', 'scalar', 'scalar'],\n",
    "#     group=\"basic\",           # ‚úÖ Unified group\n",
    "#     weight=1.0,\n",
    "#     vectorized=False\n",
    "# )\n",
    "# def return_three_values(x):\n",
    "#     \"\"\"\n",
    "#     Returns three copies of the input value\n",
    "#     :param x: Input value\n",
    "#     :return: Original value\n",
    "#     \"\"\"\n",
    "#     return [x, x, x]\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # Unified into basic group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def decrement(x):\n",
    "    \"\"\"\n",
    "    Decreases input by 1\n",
    "    :param x: Input value\n",
    "    :return: x - 1\n",
    "    \"\"\"\n",
    "    return [x - 1]\n",
    "\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # Unified into basic group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def increment(x):\n",
    "    \"\"\"\n",
    "    Increases input by 1\n",
    "    :param x: Input value\n",
    "    :return: x + 1\n",
    "    \"\"\"\n",
    "    return [x + 1]\n",
    "\n",
    "\n",
    "@method_profile(\n",
    "    output_count=1,\n",
    "    input_types=['scalar'],\n",
    "    output_types=['scalar'],\n",
    "    group=\"basic\",           # Unified into basic group\n",
    "    weight=1.0,\n",
    "    vectorized=False\n",
    ")\n",
    "def negate_value(x):\n",
    "    \"\"\"\n",
    "    Negates the input value\n",
    "    :param x: Input value\n",
    "    :return: -x\n",
    "    \"\"\"\n",
    "    return [-x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda82ee2",
   "metadata": {
    "papermill": {
     "duration": 0.005459,
     "end_time": "2025-08-17T10:19:39.067325",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.061866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üóÉÔ∏è Loading Titanic Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428c240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:39.081280Z",
     "iopub.status.busy": "2025-08-17T10:19:39.080599Z",
     "iopub.status.idle": "2025-08-17T10:19:39.114426Z",
     "shell.execute_reply": "2025-08-17T10:19:39.113291Z"
    },
    "papermill": {
     "duration": 0.042079,
     "end_time": "2025-08-17T10:19:39.116042",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.073963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_titanic_for_adaptoflux(train_processed_path, methods_path=None, collapse_method=CollapseMethod.SUM):\n",
    "    df = pd.read_csv(train_processed_path)\n",
    "    if 'Survived' not in df.columns:\n",
    "        raise ValueError(\"train_processed.csv must contain 'Survived' column\")\n",
    "    labels = df['Survived'].values\n",
    "    values = df.drop(columns=['Survived']).values\n",
    "    values = np.array(values, dtype=np.float64)\n",
    "    return AdaptoFlux(\n",
    "        values=values,\n",
    "        labels=labels,\n",
    "        methods_path=methods_path,\n",
    "        collapse_method=collapse_method\n",
    "    )\n",
    "\n",
    "# Load model\n",
    "model = load_titanic_for_adaptoflux(\n",
    "    train_processed_path='examples/kaggle/titanic/output/train_processed.csv',\n",
    "    methods_path='examples/kaggle/titanic/methods.py',\n",
    "    collapse_method=CollapseMethod.SUM\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaded: {model.values.shape[0]} samples, {model.values.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc160e7",
   "metadata": {
    "papermill": {
     "duration": 0.005708,
     "end_time": "2025-08-17T10:19:39.128095",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.122387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üå± Adding Custom Collapse Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836334e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:39.142027Z",
     "iopub.status.busy": "2025-08-17T10:19:39.140913Z",
     "iopub.status.idle": "2025-08-17T10:19:39.146324Z",
     "shell.execute_reply": "2025-08-17T10:19:39.145445Z"
    },
    "papermill": {
     "duration": 0.014031,
     "end_time": "2025-08-17T10:19:39.148024",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.133993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collapse_sum_positive(values):\n",
    "    total = np.sum(values)\n",
    "    return 1 if total > 0 else 0\n",
    "\n",
    "model.set_custom_collapse(collapse_sum_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131f4cc",
   "metadata": {
    "papermill": {
     "duration": 0.005677,
     "end_time": "2025-08-17T10:19:39.159650",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.153973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üèóÔ∏è Model Training (Layer-by-Layer Growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d1e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:19:39.172502Z",
     "iopub.status.busy": "2025-08-17T10:19:39.172111Z",
     "iopub.status.idle": "2025-08-17T10:20:51.660365Z",
     "shell.execute_reply": "2025-08-17T10:20:51.659264Z"
    },
    "papermill": {
     "duration": 72.496783,
     "end_time": "2025-08-17T10:20:51.662139",
     "exception": false,
     "start_time": "2025-08-17T10:19:39.165356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = LayerGrowTrainer(\n",
    "    adaptoflux_instance=model,\n",
    "    max_attempts=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "trainer.train(\n",
    "    input_data=model.values,\n",
    "    target=model.labels,\n",
    "    max_layers=15,\n",
    "    save_model=True,\n",
    "    on_retry_exhausted=\"rollback\",\n",
    "    rollback_layers=2,\n",
    "    max_total_attempts=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578bec6",
   "metadata": {
    "papermill": {
     "duration": 0.012631,
     "end_time": "2025-08-17T10:20:51.688259",
     "exception": false,
     "start_time": "2025-08-17T10:20:51.675628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üé® Visualizing Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91913495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:20:51.716974Z",
     "iopub.status.busy": "2025-08-17T10:20:51.715592Z",
     "iopub.status.idle": "2025-08-17T10:20:52.757656Z",
     "shell.execute_reply": "2025-08-17T10:20:52.756708Z"
    },
    "papermill": {
     "duration": 1.061432,
     "end_time": "2025-08-17T10:20:52.762860",
     "exception": false,
     "start_time": "2025-08-17T10:20:51.701428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read graph\n",
    "G = nx.read_gexf(\"/kaggle/working/AdaptoFlux/models/best/graph.gexf\")\n",
    "\n",
    "# Specify root node (modify 'root' according to your data)\n",
    "# If root is unknown, pick the highest-degree node or assign manually\n",
    "root = \"root\"  # Replace with your actual root node name\n",
    "if root not in G:\n",
    "    # If no explicit root, use the node with maximum degree\n",
    "    root = max(dict(G.degree()), key=lambda x: dict(G.degree())[x])\n",
    "    print(f\"Using highest-degree node as root: {root}\")\n",
    "\n",
    "# Use BFS to compute distance (layer) from root to each node\n",
    "try:\n",
    "    # For directed graphs, convert to undirected for BFS\n",
    "    if G.is_directed():\n",
    "        bfs_dist = nx.shortest_path_length(G.to_undirected(), source=root)\n",
    "    else:\n",
    "        bfs_dist = nx.shortest_path_length(G, source=root)\n",
    "except nx.NetworkXNoPath:\n",
    "    print(\"Graph is disconnected, only considering connected component containing root\")\n",
    "    # Keep only the connected component containing root\n",
    "    if G.is_directed():\n",
    "        connected_nodes = nx.node_connected_component(G.to_undirected(), root)\n",
    "    else:\n",
    "        connected_nodes = nx.node_connected_component(G, root)\n",
    "    G = G.subgraph(connected_nodes)\n",
    "    bfs_dist = nx.shortest_path_length(G.to_undirected() if G.is_directed() else G, source=root)\n",
    "\n",
    "# Group nodes by distance (layer)\n",
    "layers = {}\n",
    "for node, dist in bfs_dist.items():\n",
    "    layers.setdefault(dist, []).append(node)\n",
    "\n",
    "# Manually set layout: x-coordinates evenly spaced within each layer, y = -layer (root on top)\n",
    "pos = {}\n",
    "for layer, nodes in layers.items():\n",
    "    pos.update({node: (i, -layer) for i, node in enumerate(nodes)})  # y = -layer ensures root is at top\n",
    "\n",
    "# Set node colors (optional: color by layer)\n",
    "node_colors = [bfs_dist[node] for node in G.nodes]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(\n",
    "    G, pos,\n",
    "    with_labels=True,\n",
    "    node_color=node_colors,\n",
    "    cmap='viridis',\n",
    "    node_size=600,\n",
    "    font_size=6,\n",
    "    font_color='black',\n",
    "    edge_color='gray',\n",
    "    arrows=True if G.is_directed() else False,\n",
    "    width=1.0,\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "plt.title(f\"Hierarchical Layout from Root: {root}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b6d0a",
   "metadata": {
    "papermill": {
     "duration": 0.019919,
     "end_time": "2025-08-17T10:20:52.803466",
     "exception": false,
     "start_time": "2025-08-17T10:20:52.783547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìä Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce950b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:20:52.845787Z",
     "iopub.status.busy": "2025-08-17T10:20:52.844820Z",
     "iopub.status.idle": "2025-08-17T10:20:53.126919Z",
     "shell.execute_reply": "2025-08-17T10:20:53.126026Z"
    },
    "papermill": {
     "duration": 0.304781,
     "end_time": "2025-08-17T10:20:53.128481",
     "exception": false,
     "start_time": "2025-08-17T10:20:52.823700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _evaluate_accuracy(output: np.ndarray, target: np.ndarray) -> float:\n",
    "    try:\n",
    "        if len(output.shape) == 1 or output.shape[1] == 1:\n",
    "            pred_classes = (output >= 0.5).astype(int).flatten()\n",
    "        else:\n",
    "            pred_classes = np.argmax(output, axis=1)\n",
    "        true_labels = np.array(target).flatten()\n",
    "        return np.mean(pred_classes == true_labels)\n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "pred = model.infer_with_graph(model.values)\n",
    "acc = _evaluate_accuracy(pred, model.labels)\n",
    "print(f\"üéØ Final accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03cd115",
   "metadata": {
    "papermill": {
     "duration": 0.019943,
     "end_time": "2025-08-17T10:20:53.169428",
     "exception": false,
     "start_time": "2025-08-17T10:20:53.149485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üì§ Generating Kaggle Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058b54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:20:53.212731Z",
     "iopub.status.busy": "2025-08-17T10:20:53.212404Z",
     "iopub.status.idle": "2025-08-17T10:20:53.340862Z",
     "shell.execute_reply": "2025-08-17T10:20:53.339942Z"
    },
    "papermill": {
     "duration": 0.152711,
     "end_time": "2025-08-17T10:20:53.342623",
     "exception": false,
     "start_time": "2025-08-17T10:20:53.189912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_titanic_for_adaptoflux(train_processed_path, methods_path=None, collapse_method=CollapseMethod.SUM):\n",
    "    \"\"\"\n",
    "    Load data from preprocessed Titanic training CSV into AdaptoFlux-compatible format.\n",
    "\n",
    "    :param train_processed_path: Path to preprocessed train_processed.csv\n",
    "    :param methods_path: Method path (passed to AdaptoFlux)\n",
    "    :param collapse_method: Collapse method (passed to AdaptoFlux)\n",
    "    :return: AdaptoFlux instance\n",
    "    \"\"\"\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(train_processed_path)\n",
    "\n",
    "    # Ensure 'Survived' column exists\n",
    "    if 'Survived' not in df.columns:\n",
    "        raise ValueError(\"train_processed.csv must contain 'Survived' column as label\")\n",
    "\n",
    "    # Separate labels and features\n",
    "    labels = df['Survived'].values  # 1D labels\n",
    "    values = df.drop(columns=['Survived']).values  # 2D feature matrix\n",
    "\n",
    "    # Convert to numpy float64 type (prevent int64/float64 type mismatches)\n",
    "    values = np.array(values, dtype=np.float64)\n",
    "\n",
    "    # Create AdaptoFlux instance\n",
    "    adaptoflux_instance = AdaptoFlux(\n",
    "        values=values,\n",
    "        labels=labels,\n",
    "        methods_path=methods_path,\n",
    "        collapse_method=collapse_method\n",
    "    )\n",
    "\n",
    "    return adaptoflux_instance\n",
    "\n",
    "model = load_titanic_for_adaptoflux(train_processed_path='examples/kaggle/titanic/output/test_processed.csv',\n",
    "                                    methods_path='examples/kaggle/titanic/methods.py')\n",
    "\n",
    "model.set_custom_collapse(collapse_sum_positive)\n",
    "\n",
    "model.load_model(folder='models/best')\n",
    "\n",
    "pred = model.infer_with_graph(model.values)\n",
    "\n",
    "# Generate corresponding PassengerId starting from 892\n",
    "passenger_ids = range(892, 892 + len(pred))\n",
    "\n",
    "# Build DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': pred\n",
    "})\n",
    "\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Submission file generated: /kaggle/working/submission.csv\")\n",
    "\n",
    "print(\"üìÅ Files in /kaggle/working:\")\n",
    "print(os.listdir(\"/kaggle/working\"))\n",
    "\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096c8f7",
   "metadata": {
    "papermill": {
     "duration": 0.019964,
     "end_time": "2025-08-17T10:20:53.383217",
     "exception": false,
     "start_time": "2025-08-17T10:20:53.363253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üôè Acknowledgments\n",
    "\n",
    "Thanks to Kaggle for providing the Titanic dataset.\n",
    "\n",
    "If you like this project, please:\n",
    "- ‚≠ê Star the repository\n",
    "- üí¨ Share your thoughts in the comments!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 91.148467,
   "end_time": "2025-08-17T10:20:54.024413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-17T10:19:22.875946",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
