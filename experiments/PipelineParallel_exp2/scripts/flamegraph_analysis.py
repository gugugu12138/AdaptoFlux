import time
import statistics
import os
import psutil
import pandas as pd
import numpy as np
import threading
import platform
import subprocess
import logging
from tqdm import tqdm
from ATF.core.adaptoflux import AdaptoFlux
import csv
import functools

# ========================
# é…ç½®åŒºï¼ˆä¿®æ”¹è¿™é‡Œå³å¯ï¼‰
# ========================

# ğŸ” é€‰æ‹©ä½ è¦åˆ†æçš„3ä¸ªæ¨¡å‹ï¼ˆæ ¹æ®ä½ çš„ç¼–å·ï¼‰
TARGET_MODELS = [
    "model_8",
    "model_14",
    "model_21"
]

MODEL_BASE_DIR = 'experiments/PipelineParallel_exp2/models'
OUTPUT_FLAMEGRAPH_DIR = 'experiments/PipelineParallel_exp2/results/flamegraph'
OUTPUT_CSV = 'experiments/PipelineParallel_exp2/results/flamegraph_results.csv'

# æ¨ç†å‚æ•°
INFERENCE_PER_RUN = 10      # æ¯æ¬¡æ¨ç†æ¬¡æ•°ï¼ˆå¿…é¡»è¶³å¤Ÿé•¿è®© py-spy é‡‡æ ·ï¼‰
WARMUP_ITERATIONS = 5        # æ¯æ¬¡è¿è¡Œå‰é¢„çƒ­5æ¬¡ï¼ˆå¿½ç•¥ï¼‰
REPEAT_CONFIGS = 1           # æ¯ä¸ªé…ç½®åªè·‘ä¸€æ¬¡ï¼ˆä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œç«ç„°å›¾åªéœ€ä¸€æ¬¡é«˜è´¨é‡é‡‡æ ·ï¼‰

# æ˜¯å¦å¯ç”¨ sleep æ¨¡æ‹Ÿé«˜å»¶è¿Ÿï¼Ÿ
USE_SLEEP = [False, True]    # False: æ— sleep (çœŸå®è´Ÿè½½) | True: æœ‰sleep (æ¨¡æ‹Ÿå»¶è¿Ÿ)

# py-spy å‚æ•°
PYSPY_RATE = 1000            # é‡‡æ ·é¢‘ç‡ï¼ˆHzï¼‰
PYSPY_DURATION = 30          # é‡‡é›†æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
PYSPY_CMD = "py-spy"         # ç¡®ä¿å·²å®‰è£…ï¼špip install py-spy

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(name)s: %(message)s')
logger = logging.getLogger(__name__)

# ========================
# å·¥å…·å‡½æ•°
# ========================

def get_model_path(model_name):
    return os.path.join(MODEL_BASE_DIR, model_name)

def ensure_dir(path):
    os.makedirs(path, exist_ok=True)

class FlameGraphExecutor:
    def __init__(self, model_path: str, num_cores: int = 8):
        self.model_path = model_path
        self.num_cores = num_cores
        self.adaptoflux = None
        self._load_model()

    def _load_model(self):
        try:
            self.adaptoflux = AdaptoFlux(
                values=np.zeros((1, 1)),
                labels=np.zeros(1),
                methods_path='experiments/PipelineParallel_exp2/scripts/methods_GIL.py'
            )
            self.adaptoflux.load_model(folder=self.model_path)
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ {self.model_path}: {e}")
            raise e

    def forward(self, values: np.ndarray, use_sleep: bool = False):
        """æ‰§è¡Œä¸€æ¬¡æ¨ç†ï¼Œå¯é€‰åœ¨æ–¹æ³•ä¸­æ’å…¥ sleep"""
        try:
            original_functions = {}  # ä¿å­˜åŸå§‹çš„ function å¯¹è±¡

            if use_sleep:
                logger.info("âš¡ æ­£åœ¨ä¸ºæ‰€æœ‰æ–¹æ³•æ³¨å…¥ time.sleep(0.001) æ¨¡æ‹Ÿé«˜å»¶è¿Ÿ...")

                for method_name, method_info in list(self.adaptoflux.methods.items()):
                    if not isinstance(method_info, dict) or "function" not in method_info:
                        continue
                    original_func = method_info["function"]
                    if not callable(original_func):
                        continue

                    original_functions[method_name] = original_func

                    def make_wrapped_func(orig_func):
                        def wrapped(*args, **kwargs):
                            result = orig_func(*args, **kwargs)
                            time.sleep(0.001)
                            return result
                        return functools.wraps(orig_func)(wrapped)

                    self.adaptoflux.methods[method_name]["function"] = make_wrapped_func(original_func)

                logger.info("âœ… æ‰€æœ‰æ–¹æ³•å·²æˆåŠŸæ³¨å…¥ sleep å»¶è¿Ÿ")
            
            else:
                logger.info("âš¡ ä½¿ç”¨åŸå§‹æ–¹æ³•ï¼Œæ—  sleep å»¶è¿Ÿ")

                for method_name, method_info in list(self.adaptoflux.methods.items()):
                    if not isinstance(method_info, dict) or "function" not in method_info:
                        continue
                    original_func = method_info["function"]
                    if not callable(original_func):
                        continue

                    original_functions[method_name] = original_func

                    def make_wrapped_func(orig_func):
                        def wrapped(*args, **kwargs):
                            result = orig_func(*args, **kwargs)
                            return result
                        return functools.wraps(orig_func)(wrapped)

                    self.adaptoflux.methods[method_name]["function"] = make_wrapped_func(original_func)

            _ = self.adaptoflux.infer_with_task_parallel(values, num_workers=self.num_cores)

            logger.info("ğŸ”„ æ­£åœ¨æ¢å¤åŸå§‹æ–¹æ³•...")
            for method_name, orig_func in original_functions.items():
                if method_name in self.adaptoflux.methods:
                    self.adaptoflux.methods[method_name]["function"] = orig_func
            logger.info("âœ… åŸå§‹æ–¹æ³•å·²æ¢å¤")

        except Exception as e:
            logger.error(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            raise

    def get_graph_node_count(self):
        if not self.adaptoflux or not hasattr(self.adaptoflux, 'graph'):
            return 0
        return len([
            n for n in self.adaptoflux.graph.nodes 
            if n not in ["root", "collapse"]
        ])

def collect_performance_data(executor: FlameGraphExecutor, values: np.ndarray, use_sleep: bool, run_id: str):
    """æ”¶é›†æ€§èƒ½æ•°æ®ï¼Œä¸åŒ…å«ç«ç„°å›¾é‡‡é›†"""
    thread_count_before = threading.active_count()

    start_time = time.perf_counter()
    success_count = 0
    for i in range(INFERENCE_PER_RUN):
        if executor.forward(values, use_sleep=use_sleep):
            success_count += 1
    end_time = time.perf_counter()

    thread_count_after = threading.active_count()

    total_time_sec = end_time - start_time
    avg_latency_ms = (total_time_sec * 1000) / INFERENCE_PER_RUN
    throughput = INFERENCE_PER_RUN / total_time_sec

    return {
        'avg_latency_ms': avg_latency_ms,
        'throughput_samples_per_sec': throughput,
        'success_count': success_count,
        'thread_count_before': thread_count_before,
        'thread_count_after': thread_count_after,
        'total_time_sec': total_time_sec
    }

def record_flamegraph(model_name: str, use_sleep: bool, executor: FlameGraphExecutor, values: np.ndarray):
    """å¯åŠ¨ py-spy é‡‡é›†ç«ç„°å›¾ï¼Œå¹¶è¿”å›è¾“å‡ºè·¯å¾„ã€å¹³å‡CPUã€å¹³å‡å†…å­˜"""
    pid = os.getpid()
    output_file = os.path.join(OUTPUT_FLAMEGRAPH_DIR, f"{model_name}_{'sleep' if use_sleep else 'nosleep'}.svg")

    logger.info(f"ğŸ”¥ æ­£åœ¨ä¸º {model_name} {'æœ‰sleep' if use_sleep else 'æ— sleep'} é‡‡é›†ç«ç„°å›¾... PID={pid}")

    cmd = [
        PYSPY_CMD,
        "record",
        "--output", output_file,
        "--pid", str(pid),
        "--rate", str(PYSPY_RATE),
        "--duration", str(PYSPY_DURATION)
    ]

    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    # å¼‚æ­¥ç›‘æ§çº¿ç¨‹ï¼šé‡‡é›†æ¨ç†æœŸé—´çš„ CPU å’Œå†…å­˜
    cpu_samples = []
    memory_samples = []
    stop_monitoring = threading.Event()

    def monitor():
        proc_obj = psutil.Process(pid)
        try:
            proc_obj.cpu_percent()  # åˆå§‹åŒ–åŸºå‡†ï¼ˆé‡è¦ï¼ï¼‰
        except psutil.NoSuchProcess:
            return
        while not stop_monitoring.is_set():
            try:
                cpu_pct = proc_obj.cpu_percent()  # éé˜»å¡ï¼Œè¿”å›è‡ªä¸Šæ¬¡é‡‡æ ·ä»¥æ¥çš„å€¼
                mem_mb = proc_obj.memory_info().rss / (1024 * 1024)
                cpu_samples.append(cpu_pct)
                memory_samples.append(mem_mb)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                break
            time.sleep(0.5)

    monitor_thread = threading.Thread(target=monitor, daemon=True)
    monitor_thread.start()

    # å¼€å§‹æ¨ç†ï¼ˆåŒæ—¶ç›‘æ§ï¼‰
    logger.info("â–¶ï¸  å¼€å§‹æ‰§è¡Œæ¨ç†ä»¥è§¦å‘é‡‡æ ·...")
    start_time = time.time()

    for _ in range(WARMUP_ITERATIONS):
        executor.forward(values, use_sleep=use_sleep)

    for i in range(INFERENCE_PER_RUN):
        executor.forward(values, use_sleep=use_sleep)
        if i % 20 == 0:
            elapsed = time.time() - start_time
            if elapsed > PYSPY_DURATION * 0.8:
                logger.info(f"â³ å·²è¿è¡Œ {elapsed:.1f}sï¼Œæ¥è¿‘é‡‡æ ·ç»“æŸæ—¶é—´...")

    # ç­‰å¾… py-spy å®Œæˆ
    try:
        stdout, stderr = proc.communicate(timeout=60)
        if proc.returncode != 0:
            logger.error(f"âŒ py-spy å¤±è´¥: {stderr.decode()}")
            return None, None, None
        else:
            logger.info(f"âœ… ç«ç„°å›¾å·²ä¿å­˜è‡³: {output_file}")
    except subprocess.TimeoutExpired:
        proc.kill()
        logger.warning("âš ï¸ py-spy è¶…æ—¶ï¼Œå¯èƒ½æœªé‡‡é›†å®Œæ•´æ•°æ®ï¼Œè¯·æ‰‹åŠ¨é‡è¯•ã€‚")
        return None, None, None

    # åœæ­¢ç›‘æ§
    stop_monitoring.set()
    monitor_thread.join(timeout=2)

    avg_cpu = sum(cpu_samples) / len(cpu_samples) if cpu_samples else 0.0
    avg_mem = sum(memory_samples) / len(memory_samples) if memory_samples else 0.0

    return output_file, avg_cpu, avg_mem

def main():
    # å‡†å¤‡è¾“å…¥æ•°æ®
    try:
        df = pd.read_csv('experiments/PipelineParallel_exp2/data/test_processed.csv')
        if 'Survived' in df.columns:
            values = df.drop(columns=['Survived']).values
        else:
            values = df.values
        values = values[:100].astype(np.float64)
        logger.info(f"âœ… è¾“å…¥æ•°æ®åŠ è½½æˆåŠŸ: {values.shape}")
    except Exception as e:
        logger.error(f"âŒ è¾“å…¥æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    ensure_dir(OUTPUT_FLAMEGRAPH_DIR)

    # åˆ›å»ºç»“æœCSVæ–‡ä»¶ï¼ˆå¸¦è¡¨å¤´ï¼‰
    csv_header = [
        'model_path', 'num_cores', 'avg_latency_ms', 'throughput_samples_per_sec',
        'std_latency_ms', 'timestamp', 'cpu_util_percent', 'memory_mb', 'python_version',
        'graph_node_count', 'thread_count_before', 'thread_count_after',
        'use_sleep', 'flamegraph_file'
    ]
    file_exists = os.path.exists(OUTPUT_CSV)
    with open(OUTPUT_CSV, 'a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(csv_header)

    # éå†æ¯ä¸ªæ¨¡å‹å’Œé…ç½®
    for model_name in TARGET_MODELS:
        model_path = get_model_path(model_name)
        logger.info(f"\n{'='*60}\nğŸ¯ æ­£åœ¨å¤„ç†æ¨¡å‹: {model_name}\n{'='*60}")

        for use_sleep in USE_SLEEP:
            config_str = "sleep" if use_sleep else "nosleep"
            logger.info(f"âš™ï¸  é…ç½®: {config_str}")

            try:
                # åˆå§‹åŒ–æ‰§è¡Œå™¨
                executor = FlameGraphExecutor(model_path, num_cores=8)
                graph_node_count = executor.get_graph_node_count()

                # å…ˆæ”¶é›†æ€§èƒ½æ•°æ®ï¼ˆå¿«é€Ÿï¼‰
                perf_data = collect_performance_data(executor, values, use_sleep, run_id=f"{model_name}_{config_str}")

                # é‡‡é›†ç«ç„°å›¾å¹¶è·å–æœŸé—´çš„å¹³å‡ CPU å’Œå†…å­˜
                flamegraph_path, avg_cpu, avg_mem = record_flamegraph(model_name, use_sleep, executor, values)

                if not flamegraph_path:
                    logger.warning(f"âš ï¸ ç«ç„°å›¾é‡‡é›†å¤±è´¥ï¼Œè·³è¿‡è®°å½•")
                    continue

                # è®°å½•ç»“æœåˆ°CSV â€”â€” å®‰å…¨å¤„ç† None/ç©ºå€¼
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                py_version = platform.python_version()

                # å®‰å…¨æ ¼å¼åŒ–ï¼šè‹¥ä¸º None æˆ–æ— æ•ˆï¼Œå†™ç©ºå­—ç¬¦ä¸²
                def safe_float(x, default=""):
                    return f"{x:.1f}" if x is not None and isinstance(x, (int, float)) else default

                row = [
                    model_path, 8,
                    f"{perf_data['avg_latency_ms']:.6f}",
                    f"{perf_data['throughput_samples_per_sec']:.6f}",
                    "0.0",  # std_latency_ms: åªè·‘ä¸€æ¬¡ï¼Œè®¾ä¸º0
                    timestamp,
                    safe_float(avg_cpu),      # âœ… å®‰å…¨å¤„ç†
                    safe_float(avg_mem),      # âœ… å®‰å…¨å¤„ç†
                    py_version,
                    graph_node_count,
                    perf_data['thread_count_before'],
                    perf_data['thread_count_after'],
                    use_sleep,
                    flamegraph_path
                ]

                with open(OUTPUT_CSV, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(row)

                logger.info(f"ğŸ“Š ç»“æœå·²è®°å½•: {model_name} {config_str} | CPU: {avg_cpu:.1f}% | MEM: {avg_mem:.1f}MB")

            except Exception as e:
                logger.error(f"âŒ å¤„ç† {model_name} {use_sleep} æ—¶å‡ºé”™: {e}")

    logger.info(f"\nğŸ‰ æ‰€æœ‰ç›®æ ‡æ¨¡å‹åˆ†æå®Œæˆï¼")
    logger.info(f"ğŸ“ ç«ç„°å›¾ä¿å­˜äº: {OUTPUT_FLAMEGRAPH_DIR}")
    logger.info(f"ğŸ“‹ æ•°æ®ä¿å­˜äº: {OUTPUT_CSV}")

if __name__ == "__main__":
    main()