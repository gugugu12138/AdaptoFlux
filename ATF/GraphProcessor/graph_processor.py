import networkx as nx
import numpy as np
from collections import Counter
import math
from ..CollapseManager.collapse_functions import CollapseFunctionManager, CollapseMethod
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GraphProcessor:
    def __init__(self, graph: nx.MultiDiGraph, methods: dict, collapse_method=CollapseMethod.SUM):
        """
        åˆå§‹åŒ–å›¾å¤„ç†å™¨ã€‚
        
        å‚æ•°:
            graph (nx.MultiDiGraph): åˆå§‹å›¾ç»“æ„
            methods (dict): å¯ç”¨æ–¹æ³•å­—å…¸ {method_name: {"function": ..., "input_count": int, "output_count": int}}
            collapse_method (callable): èšåˆå‡½æ•°ï¼Œé»˜è®¤ä¸º sum
        """
        self.discard_node_method_name = "null"
        self.graph = graph.copy() if graph else nx.MultiDiGraph()
        self.methods = methods
        self.layer = self.get_max_layer_from_graph()  # è®°å½•å½“å‰å±‚æ•°ï¼ˆå¯é€‰ï¼‰

        self.collapse_manager = CollapseFunctionManager(method=collapse_method)

    def set_graph(self, new_graph):
        if not hasattr(new_graph, 'nodes') or not hasattr(new_graph, 'edges'):
            raise ValueError("new_graph ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å›¾å¯¹è±¡")
        self.graph = new_graph
        # è‡ªåŠ¨åŒæ­¥ layer çŠ¶æ€
        self.layer = self.get_max_layer_from_graph()
        print(f"å›¾ç»“æ„å·²æ›´æ–°ï¼Œå½“å‰æœ€å¤§å±‚æ•°ï¼š{self.layer}ã€‚")

    def set_methods(self, new_methods):
        """æ›´æ–° methodsï¼ˆå‡½æ•°å­—å…¸æˆ–æ¨¡å—ï¼‰"""
        if not isinstance(new_methods, dict) and not callable(new_methods):
            raise TypeError("methods åº”è¯¥æ˜¯ä¸€ä¸ªå‡½æ•°å­—å…¸æˆ–å¯è°ƒç”¨å¯¹è±¡")
        self.methods = new_methods
        print("Methods å·²æ›´æ–°ã€‚")

    def append_nx_layer(self, result, discard_unmatched='to_discard', discard_node_method_name="null"):
        """
        å‘å›¾ä¸­æ·»åŠ ä¸€å±‚æ–°èŠ‚ç‚¹ã€‚
        """
        self.discard_node_method_name = discard_node_method_name

        self.layer += 1
        new_index_edge = 0
        method_counts = {method_name: 0 for method_name in self.methods}
        if discard_node_method_name not in method_counts:
            method_counts[discard_node_method_name] = 0
        v = "collapse"
        collapse_edges = list(self.graph.in_edges(v, data=True))

        # å¤„ç†æœ‰æ•ˆåˆ†ç»„
        for method_name, groups in result['valid_groups'].items():
            if method_name == discard_node_method_name:
                continue
            for group in groups:
                new_target_node = f"{self.layer}_{method_counts[method_name]}_{method_name}"
                self.graph.add_node(
                    new_target_node,
                    method_name=method_name,
                    layer=self.layer,
                    is_passthrough=False   # â† å…³é”®ï¼šæ˜¾å¼æ ‡è®°
                )

                for u, _, data in collapse_edges:
                    if data.get('data_coord') in group:
                        self.graph.remove_edge(u, v)
                        self.graph.add_edge(u, new_target_node, **data)

                for local_output_index in range(self.methods[method_name]["output_count"]):
                    self.graph.add_edge(new_target_node, v, output_index=local_output_index, data_coord=new_index_edge, data_type=self.methods[method_name]["output_types"][local_output_index])
                    new_index_edge += 1

                method_counts[method_name] += 1
            
            # # === æ–°å¢ï¼šæ£€æµ‹æ— å…¥è¾¹çš„æ–°èŠ‚ç‚¹ ===
            # for method_name, count in method_counts.items():
            #     if method_name == "unmatched":
            #         continue
            #     for i in range(count):
            #         new_node = f"{self.layer}_{i}_{method_name}"
            #         if self.graph.in_degree(new_node) == 0:
            #             print(f"[è­¦å‘Š] èŠ‚ç‚¹ '{new_node}' æ²¡æœ‰å…¥è¾¹ï¼å…¶å±æ€§ä¸ºï¼š")
            #             print(dict(self.graph.nodes[new_node]))
            #             print(result['valid_groups'])

        # æ”¶é›†æ‰€æœ‰è¾“å…¥è¾¹çš„ data_type
        input_data_types = []
        
        # å¤„ç† discard_node_method_name
        unmatched_groups = result.get('unmatched', [])
        if unmatched_groups and discard_unmatched == 'to_discard':
            for group in unmatched_groups:
                node_name = f"{self.layer}_{method_counts[discard_node_method_name]}_{discard_node_method_name}"
                self.graph.add_node(
                    node_name,
                    method_name=discard_node_method_name,
                    layer=self.layer,
                    is_passthrough=True   # â† å…³é”®ï¼šæ˜¾å¼æ ‡è®°
                )

                # æ”¶é›†æ‰€æœ‰è¾“å…¥è¾¹çš„ data_typeï¼Œå¹¶é‡å®šå‘è¾¹
                input_data_types = []
                for u, _, data in collapse_edges:
                    if data.get('data_coord') in group:
                        input_data_types.append(data.get('data_type'))  # æå–åŸå§‹è¾¹çš„æ•°æ®ç±»å‹
                        self.graph.remove_edge(u, v)
                        self.graph.add_edge(u, node_name, **data)

                # æŒ‰é¡ºåºä¸ºæ¯æ¡è¾“å…¥è¾¹åˆ›å»ºä¸€æ¡è¾“å‡ºè¾¹ï¼Œç»§æ‰¿å…¶ data_type
                for local_output_index, used_data_type in enumerate(input_data_types):
                    self.graph.add_edge(
                        node_name, v,
                        output_index=local_output_index,
                        data_coord=new_index_edge,
                        data_type=used_data_type  # â† ä½¿ç”¨å¯¹åº”è¾“å…¥è¾¹çš„ç±»å‹
                    )
                    new_index_edge += 1

                method_counts[discard_node_method_name] += 1

        elif unmatched_groups and discard_unmatched == 'ignore':
            logging.warning(
                "discard_unmatched='ignore' ç­–ç•¥æœªç»å……åˆ†æµ‹è¯•ï¼Œå¯èƒ½å­˜åœ¨æœªé¢„è§è¡Œä¸ºã€‚"
                "å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»å¼€å‘è€…ã€‚"
            )
            logging.warning(
                "âš ï¸  UNTESTED PATH: discard_unmatched='ignore' is experimental. "
                "Data will be DROPPED (edges removed from 'collapse'). "
                "Use at your own risk."
            )
            # TODO: Add unit tests for 'ignore' mode (2025-10-18)
            logging.warning("Experimental 'ignore' mode: unmatched data is dropped.")
            # === æ–°å¢é€»è¾‘ï¼šå½»åº•ä¸¢å¼ƒ unmatched æ•°æ® ===
            # å°† unmatched_groups æ‰å¹³åŒ–ä¸ºä¸€ä¸ªé›†åˆï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾
            unmatched_coords = set()
            for group in unmatched_groups:
                unmatched_coords.update(group)

            # éå†åŸå§‹ collapse å…¥è¾¹ï¼ˆå·²ç¼“å­˜ï¼‰ï¼Œåˆ é™¤å±äº unmatched çš„è¾¹
            for u, _, data in collapse_edges:
                if data.get('data_coord') in unmatched_coords:
                    self.graph.remove_edge(u, v)
            # æ³¨æ„ï¼šä¸åˆ›å»ºæ–°èŠ‚ç‚¹ï¼Œä¹Ÿä¸æ·»åŠ æ–°è¾¹ â†’ æ•°æ®è¢«ä¸¢å¼ƒ

        elif unmatched_groups:
            raise ValueError(f"æœªçŸ¥çš„ discard_unmatched å€¼ï¼š{discard_unmatched}")

        return self.graph

    def remove_last_nx_layer(self):
        """
        åˆ é™¤å›¾ä¸­çš„æœ€åä¸€å±‚èŠ‚ç‚¹ã€‚
        """
        collapse_node = "collapse"
        incoming_edges = list(self.graph.in_edges(collapse_node, data=True))
        nodes_to_remove = set(u for u, v, d in incoming_edges)

        if not nodes_to_remove:
            print("æ²¡æœ‰å¯åˆ é™¤çš„å±‚ã€‚")
            return

        input_edges_map = {
            node: list(self.graph.in_edges(node, data=True)) for node in nodes_to_remove
        }

        for node in nodes_to_remove:
            for prev_node, _, edge_data in input_edges_map[node]:
                self.graph.add_edge(prev_node, collapse_node, **edge_data)

        for node in nodes_to_remove:
            if node != "root":
                self.graph.remove_node(node)
            else:
                print(f"è·³è¿‡åˆ é™¤èŠ‚ç‚¹ï¼š{node}ï¼ˆè¿™æ˜¯ä¿ç•™çš„æ ¹èŠ‚ç‚¹ï¼‰")

        self.layer -= 1
        return self.graph

    def infer_with_graph(self, values):
        """
        ä½¿ç”¨å›¾ç»“æ„å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ¨ç†ï¼Œæ”¯æŒä»»æ„å¯¹è±¡ï¼ˆéä»…æ•°å€¼ï¼‰ã€‚
        
        å‚æ•°:
            values: 
                - è‹¥ä¸º numpy array: å¿…é¡»æ˜¯ (N, D) shapeï¼Œdtype å¯ä¸º object
                - è‹¥ä¸º list: å¿…é¡»æ˜¯ [[feat0, feat1, ...], ...] çš„äºŒç»´ç»“æ„
        
        è¿”å›:
            collapsed_output: 1D numpy array of scalars (shape [N,])
        """
        import numpy as np

        # === 1. æ ‡å‡†åŒ–è¾“å…¥ä¸º list of listsï¼ˆæ ·æœ¬ Ã— è¾“å…¥ç‰¹å¾ï¼‰===
        if isinstance(values, np.ndarray):
            if values.ndim != 2:
                raise ValueError(f"Input values must be 2D, got shape {values.shape}")
            # è½¬ä¸º list of listsï¼Œä¿ç•™å¯¹è±¡å¼•ç”¨
            input_samples = [list(row) for row in values]
        elif isinstance(values, list):
            if not all(isinstance(row, (list, tuple)) for row in values):
                raise ValueError("Each sample in values must be a list/tuple of features.")
            input_samples = [list(row) for row in values]
        else:
            raise TypeError("values must be a 2D numpy array or list of lists.")

        num_samples = len(input_samples)
        if num_samples == 0:
            return np.array([])

        # === 2. åˆå§‹åŒ–èŠ‚ç‚¹è¾“å‡ºå­—å…¸ ===
        node_outputs = {}
        node_outputs["root"] = input_samples  # list of lists

        # === 3. æ‹“æ‰‘æ’åºï¼ˆæ’é™¤ root å’Œ collapseï¼‰===
        nodes_in_order = list(nx.topological_sort(self.graph))
        nodes_in_order = [n for n in nodes_in_order if n not in {"root", "collapse"}]

        # === 4. é€èŠ‚ç‚¹æ‰§è¡Œ ===
        for node in nodes_in_order:
            node_data = self.graph.nodes[node]
            method_name = node_data.get("method_name")

            # === å¤„ç† is_passthroughï¼ˆå…¼å®¹è€æ¨¡å‹ï¼‰===
            if "is_passthrough" not in node_data:
                is_passthrough = (
                    method_name is None or 
                    (isinstance(method_name, str) and method_name.lower() == 'null')
                )
            else:
                is_passthrough = bool(node_data.get("is_passthrough", False))

            # === æ”¶é›†æ‰€æœ‰è¾“å…¥ç‰¹å¾ï¼ˆæŒ‰æ ·æœ¬å¯¹é½ï¼‰===
            predecessors = list(self.graph.predecessors(node))
            if not predecessors:
                raise ValueError(f"Node '{node}' has no predecessors.")

            # æŒ‰è¾¹æ”¶é›†ï¼šæ¯ä¸ªè¾“å…¥è¾¹å¯¹åº”ä¸€ä¸ªâ€œè¾“å…¥ç‰¹å¾åˆ—è¡¨â€ï¼ˆé•¿åº¦ = num_samplesï¼‰
            input_feature_lists = []  # List[List[Any]]: [input_slot][sample_idx]

            for src in predecessors:
                edges_from_src = self.graph[src][node]  # Multi-edge dict
                for edge_key in edges_from_src:
                    edge_data = edges_from_src[edge_key]
                    output_idx = edge_data.get("output_index")
                    src_output = node_outputs[src]  # list of lists

                    if output_idx is None:
                        # é€ä¼ æ•´ä¸ªè¾“å‡ºï¼ˆç½•è§ï¼Œé€šå¸¸ç”¨äº rootï¼‰
                        extracted = [sample_output for sample_output in src_output]
                    else:
                        # æå–ç¬¬ output_idx ä¸ªè¾“å‡ºç‰¹å¾
                        extracted = [sample_output[output_idx] for sample_output in src_output]
                    input_feature_lists.append(extracted)

            # === æ‰§è¡ŒèŠ‚ç‚¹ ===
            if is_passthrough:
                if len(input_feature_lists) != 1:
                    raise ValueError(f"Passthrough node '{node}' must have exactly one input, got {len(input_feature_lists)}")
                # é€ä¼ ï¼šè¾“å‡º = è¾“å…¥
                node_outputs[node] = input_feature_lists[0]  # list of objects (one per sample)
                continue

            # === æ­£å¸¸æ–¹æ³•æ‰§è¡Œ ===
            if method_name not in self.methods:
                raise ValueError(f"Unknown method: {method_name}")

            method_info = self.methods[method_name]
            func = method_info["function"]
            expected_input_count = method_info["input_count"]
            expected_output_count = method_info["output_count"]
            is_vectorized = method_info.get("vectorized", False)

            if len(input_feature_lists) != expected_input_count:
                raise ValueError(
                    f"Node '{node}' method '{method_name}' expects {expected_input_count} inputs, "
                    f"but got {len(input_feature_lists)} from edges."
                )

            # å°è¯•å‘é‡åŒ–æ‰§è¡Œï¼ˆä»…å½“æ–¹æ³•æ ‡è®°ä¸º vectorized=Trueï¼‰
            node_output_samples = None
            if is_vectorized:
                try:
                    # === å°è¯•æ„å»ºæ‰¹é‡è¾“å…¥ ===
                    batched_inputs = []
                    for input_list in input_feature_lists:
                        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å…ƒç´ ç±»å‹ä¸€è‡´ä¸”å¯å †å 
                        first = input_list[0]
                        
                        # æƒ…å†µ1: å…¨æ˜¯æ ‡é‡ï¼ˆint/float/np.numberï¼‰
                        if all(isinstance(x, (int, float, np.number)) for x in input_list):
                            batched = np.array(input_list)
                        # æƒ…å†µ2: å…¨æ˜¯ numpy æ•°ç»„ä¸” shape ä¸€è‡´
                        elif all(isinstance(x, np.ndarray) for x in input_list):
                            shapes = [x.shape for x in input_list]
                            if all(s == shapes[0] for s in shapes):
                                batched = np.stack(input_list, axis=0)  # (N, ...)
                            else:
                                raise ValueError("Array shapes mismatch, cannot vectorize")
                        # æƒ…å†µ3: å…¶ä»–ç±»å‹ï¼ˆstr, dict ç­‰ï¼‰â†’ æ— æ³•å‘é‡åŒ–
                        else:
                            raise ValueError("Non-numeric or mixed types, cannot vectorize")
                            
                        batched_inputs.append(batched)
                    
                    batched_outputs = func(*batched_inputs)  # åº”è¿”å› (N, output_count) æˆ– tuple of (N,)
                    
                    # === æ ‡å‡†åŒ–è¾“å‡ºä¸º list of lists ===
                    if isinstance(batched_outputs, tuple):
                        # å¤šè¾“å‡ºï¼šæ¯ä¸ªæ˜¯ (N,) æˆ– (N, ...)
                        if len(batched_outputs) != expected_output_count:
                            raise ValueError(f"Expected {expected_output_count} outputs, got {len(batched_outputs)}")
                        # è½¬ç½®: [(N,), (N,)] â†’ [(out0_s0, out1_s0), ...]
                        node_output_samples = []
                        for i in range(num_samples):
                            sample_outs = [batched_outputs[j][i] for j in range(expected_output_count)]
                            # å¦‚æœè¾“å‡ºæ˜¯æ•°ç»„ï¼Œä¿ç•™ä¸ºæ•°ç»„ï¼ˆä¸å¼ºåˆ¶æ ‡é‡ï¼‰
                            node_output_samples.append(sample_outs)
                    else:
                        # å•è¾“å‡ºæˆ– (N, output_count)
                        if batched_outputs.ndim == 1:
                            # (N,) â†’ æ¯ä¸ªæ ·æœ¬ä¸€ä¸ªæ ‡é‡
                            if expected_output_count != 1:
                                raise ValueError(f"Expected {expected_output_count} outputs, but got 1D array")
                            node_output_samples = [[x] for x in batched_outputs]
                        elif batched_outputs.ndim == 2:
                            # (N, output_count)
                            if batched_outputs.shape[1] != expected_output_count:
                                raise ValueError(f"Output shape {batched_outputs.shape} mismatches output_count={expected_output_count}")
                            node_output_samples = batched_outputs.tolist()
                        else:
                            raise ValueError(f"Unsupported output ndim: {batched_outputs.ndim}")
                            
                except Exception as e:
                    # å›é€€åˆ°é€æ ·æœ¬æ¨¡å¼ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
                    logger.warning(
                        f"Vectorized execution failed for method '{method_name}' (inputs: {[type(x[0]) for x in input_feature_lists]}), "
                        f"fallback to sample-by-sample. Error: {e}"
                    )
                    is_vectorized = False  # è§¦å‘ä¸‹æ–¹é€æ ·æœ¬é€»è¾‘

            # === å›é€€ï¼šé€æ ·æœ¬æ‰§è¡Œï¼ˆåŸé€»è¾‘ï¼‰===
            if not is_vectorized:
                node_output_samples = []
                for sample_idx in range(num_samples):
                    sample_inputs = [input_list[sample_idx] for input_list in input_feature_lists]
                    try:
                        result = func(*sample_inputs)
                    except Exception as e:
                        raise RuntimeError(
                            f"Error in method '{method_name}' at sample {sample_idx}:\n"
                            f"  Inputs: {sample_inputs}\n"
                            f"  Error: {e}"
                        ) from e

                    if not isinstance(result, (list, tuple)):
                        result = [result]
                    result = list(result)

                    if len(result) != expected_output_count:
                        raise ValueError(
                            f"Method '{method_name}' returned {len(result)} outputs, "
                            f"but expected {expected_output_count} (output_count)."
                        )

                    node_output_samples.append(result)

            # ä¿å­˜ç»“æœ
            node_outputs[node] = node_output_samples

        # === 5. èšåˆåˆ° collapse èŠ‚ç‚¹ ===
        collapse_inputs = []  # List[Tuple[global_coord, List[Any]]]
        for u, v, data in self.graph.in_edges("collapse", data=True):
            local_idx = data.get("output_index")
            global_coord = data.get("data_coord")
            if local_idx is None or global_coord is None:
                raise ValueError(f"Edge from {u} to collapse missing output_index or data_coord")

            src_output = node_outputs[u]  # list of lists
            feature_values = [sample_output[local_idx] for sample_output in src_output]
            collapse_inputs.append((global_coord, feature_values))

        if not collapse_inputs:
            raise ValueError("No inputs connected to 'collapse' node.")

        # æŒ‰ global_coord æ’åºä»¥ä¿è¯é¡ºåºä¸€è‡´
        collapse_inputs.sort(key=lambda x: x[0])
        all_features_per_sample = list(zip(*[feat_list for _, feat_list in collapse_inputs]))  # transpose

        # === 6. åº”ç”¨ collapse å‡½æ•° ===
        collapsed_results = []
        for sample_features in all_features_per_sample:
            try:
                # collapse æ¥æ”¶ listï¼Œè¿”å›ä»»æ„å¯¹è±¡ï¼ˆæ ‡é‡ã€å‘é‡ã€å­—ç¬¦ä¸²ç­‰ï¼‰
                collapsed_val = self.collapse_manager.collapse(list(sample_features))
                collapsed_results.append(collapsed_val)
            except Exception as e:
                raise RuntimeError(
                    f"Error in collapse function with inputs {list(sample_features)}:\n{e}"
                ) from e

        # è¿”å›ç»“æœåˆ—è¡¨ï¼ˆä¸å¼ºåˆ¶è½¬ä¸º np.arrayï¼‰
        return collapsed_results
    
    def infer_with_task_parallel(self, values, num_workers=4):
        from concurrent.futures import ThreadPoolExecutor
        import threading
        import queue

        # åˆå§‹åŒ–
        node_outputs = {"root": values}
        lock = threading.Lock()
        in_degree_remaining = {}
        ready_queue = queue.Queue()

        # æ„å»ºæ‹“æ‰‘ä¾èµ–å›¾ï¼Œå¹¶åˆå§‹åŒ–æ¯ä¸ªèŠ‚ç‚¹çš„å¾…å®Œæˆå‰é©±æ•°
        for node in self.graph.nodes:
            if node in ["root", "collapse"]:
                continue
            preds = list(self.graph.predecessors(node))
            in_degree_remaining[node] = len(preds)
            if len(preds) == 0:
                ready_queue.put(node)

        for succ in self.graph.successors("root"):
            # å¯¹æ¯ä¸ªä» root æŒ‡å‘çš„èŠ‚ç‚¹ï¼Œå‡å°‘ä¸€ä¸ªä¾èµ–ï¼ˆå› ä¸º root å·²å®Œæˆï¼‰
            if succ in in_degree_remaining:
                in_degree_remaining[succ] -= 1
                if in_degree_remaining[succ] == 0:
                    ready_queue.put(succ)

        # collapse ç‰¹æ®Šå¤„ç†ï¼šæ‰€æœ‰æŒ‡å‘å®ƒçš„èŠ‚ç‚¹å®Œæˆåæ‰å¯æ‰§è¡Œ
        collapse_in_edges = list(self.graph.in_edges("collapse"))
        collapse_deps = len(collapse_in_edges)
        if collapse_deps == 0:
            return np.array([])

        # å·¥ä½œå‡½æ•°
        import traceback  # ğŸ‘ˆ ç¡®ä¿æ–‡ä»¶é¡¶éƒ¨å·²å¯¼å…¥

        def process_node(node):
            try:
                with lock:
                    predecessors = list(self.graph.predecessors(node))
                    inputs = []
                    for src in predecessors:
                        try:
                            # âœ… ä¿®å¤ï¼šéå†æ‰€æœ‰ä» src åˆ° node çš„è¾¹
                            edges_from_src = self.graph[src][node]  # {key: edge_data}
                            for edge_key in edges_from_src:
                                edge_data = edges_from_src[edge_key]
                                output_idx = edge_data.get("output_index")
                                if src not in node_outputs:
                                    raise KeyError(f"å‰ç½®èŠ‚ç‚¹ '{src}' çš„è¾“å‡ºå°šæœªè®¡ç®—")
                                src_output = node_outputs[src]
                                if output_idx is not None:
                                    col = src_output[:, output_idx:output_idx+1]
                                else:
                                    col = src_output
                                inputs.append(col)
                        except Exception as e:
                            raise RuntimeError(f"æ„å»ºèŠ‚ç‚¹ '{node}' çš„è¾“å…¥æ—¶å‡ºé”™ï¼ˆæ¥è‡ªå‰ç½®èŠ‚ç‚¹ '{src}'ï¼‰: {e}") from e

                    if len(inputs) == 0:
                        raise ValueError(f"èŠ‚ç‚¹ '{node}' æ²¡æœ‰è¾“å…¥æ•°æ®")
                    flat_input = np.hstack(inputs) if len(inputs) > 1 else inputs[0]

                # æ‰§è¡Œå‡½æ•°
                node_data = self.graph.nodes[node]  # âœ… ç¡®ä¿ node_data è¢«å®šä¹‰
                method_name = node_data.get("method_name")

                # âœ… æ–°å¢ï¼šå…¼å®¹è€ç‰ˆæœ¬æ¨¡å‹ï¼Œå¤„ç†ç¼ºå¤± is_passthrough çš„æƒ…å†µ
                if "is_passthrough" not in node_data:
                    logger.warning(
                        f"âš ï¸ èŠ‚ç‚¹ '{node}' ç¼ºå°‘ 'is_passthrough' å±æ€§ï¼Œæ£€æµ‹åˆ°è€ç‰ˆæœ¬æ¨¡å‹ã€‚"
                        f"æ–¹æ³•å: {method_name}ã€‚æœªæ¥ç‰ˆæœ¬å°†å–æ¶ˆå¯¹è€æ¨¡å‹çš„æ”¯æŒï¼Œè¯·å°½å¿«å‡çº§æ¨¡å‹æ ¼å¼ã€‚"
                    )
                    # æ¨æ–­ï¼šmethod_name ä¸º None æˆ–å­—ç¬¦ä¸² 'null'ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰æ—¶è§†ä¸º passthrough
                    if method_name is None or (isinstance(method_name, str) and method_name.lower() == 'null'):
                        is_passthrough = True
                    else:
                        is_passthrough = False
                else:
                    is_passthrough = bool(node_data.get("is_passthrough", False))

                # âœ… ä½¿ç”¨æ¨æ–­/æå–å‡ºçš„ is_passthrough è¿›è¡Œåˆ¤æ–­
                if is_passthrough:
                    with lock:
                        predecessors = list(self.graph.predecessors(node))
                        if len(predecessors) > 1:
                            raise ValueError(f"èŠ‚ç‚¹ {node} ä½¿ç”¨äº† 'passthrough' æ–¹æ³•ï¼Œä½†æœ‰å¤šä¸ªå‰é©±èŠ‚ç‚¹ã€‚è¿™è¿åè®¾è®¡çº¦æŸã€‚")

                        node_outputs[node] = flat_input.copy()

                        # è§¦å‘åç»§èŠ‚ç‚¹
                        for succ in self.graph.successors(node):
                            if succ == "collapse":
                                continue
                            if succ in in_degree_remaining:
                                in_degree_remaining[succ] -= 1
                                if in_degree_remaining[succ] == 0:
                                    ready_queue.put(succ)
                    
                    output_shape = node_outputs[node].shape
                    # print(f"[âœ… SUCCESS] èŠ‚ç‚¹ {node} (method=unmatched) æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {output_shape}")
                    return  # âš ï¸ ç›´æ¥è¿”å›ï¼Œè·³è¿‡åç»­å‡½æ•°æ‰§è¡Œé€»è¾‘

                # ========== åŸæœ‰å‡½æ•°æ‰§è¡Œé€»è¾‘ ==========
                if not method_name:
                    raise ValueError(f"èŠ‚ç‚¹ '{node}' æœªæŒ‡å®š method_name")

                if method_name not in self.methods:
                    raise KeyError(f"æ–¹æ³• '{method_name}' æœªåœ¨ self.methods ä¸­æ³¨å†Œ")

                func = self.methods[method_name]["function"]
                if not callable(func):
                    raise TypeError(f"æ–¹æ³• '{method_name}' ä¸æ˜¯å¯è°ƒç”¨å¯¹è±¡")

                outputs = []
                for i, row in enumerate(flat_input):
                    try:
                        res = func(*row)
                        if isinstance(res, (int, float)):
                            res = [res]
                        elif isinstance(res, np.ndarray):
                            res = res.tolist()
                        outputs.append(res)
                    except Exception as e:
                        raise RuntimeError(f"åœ¨èŠ‚ç‚¹ '{node}' æ‰§è¡Œç¬¬ {i} è¡Œè¾“å…¥æ—¶å‡ºé”™: {e} | è¾“å…¥æ•°æ®: {row}") from e

                output_array = np.array(outputs)

                # å†™å›è¾“å‡ºï¼ˆéœ€åŠ é”ï¼‰
                with lock:
                    node_outputs[node] = output_array
                    # è§¦å‘åç»§èŠ‚ç‚¹æ£€æŸ¥
                    for succ in self.graph.successors(node):
                        if succ == "collapse":
                            continue
                        if succ not in in_degree_remaining:
                            print(f"[WARNING] åç»§èŠ‚ç‚¹ '{succ}' ä¸åœ¨ in_degree_remaining ä¸­ï¼Œè·³è¿‡ä¾èµ–æ›´æ–°ã€‚")
                            continue
                        in_degree_remaining[succ] -= 1
                        if in_degree_remaining[succ] == 0:
                            ready_queue.put(succ)

                # print(f"[âœ… SUCCESS] èŠ‚ç‚¹ {node} æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {output_array.shape}")
                # print(f"[ğŸ§µ THREAD DONE] èŠ‚ç‚¹ {node} çº¿ç¨‹å·²å®Œå…¨é€€å‡º")
                return  # ç¡®ä¿æ˜¾å¼è¿”å›

            except Exception as e:
                error_msg = f"[ğŸ”¥ CRITICAL ERROR in process_node] èŠ‚ç‚¹ '{node}' æ‰§è¡Œå¤±è´¥: {e}"
                print(error_msg)
                traceback.print_exc()
                # å¯é€‰ï¼šå°†é”™è¯¯èŠ‚ç‚¹æ”¾å…¥ç‰¹æ®Šé˜Ÿåˆ— or è®¾ç½®å…¨å±€é”™è¯¯æ ‡å¿—
                # ä¾‹å¦‚ï¼š
                # with lock:
                #     global_error_flag.set()
                #     error_queue.put((node, str(e)))
                raise  # é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚æ•è·ï¼ˆå¦‚ ThreadPoolExecutor ä¼šæ ‡è®° future ä¸ºå¤±è´¥ï¼‰

        # å¯åŠ¨çº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            # ğŸ‘‡ è®¡ç®—æ€»èŠ‚ç‚¹æ•°ï¼ˆæ’é™¤ root å’Œ collapseï¼‰
            total_nodes_to_execute = len([
                n for n in self.graph.nodes 
                if n not in ["root", "collapse"]
            ])
            submitted_nodes = set()  # ç”¨äºå»é‡å’Œè®¡æ•°

            # print(f"[ğŸ¯ æ€»å…±éœ€è¦æ‰§è¡Œ {total_nodes_to_execute} ä¸ªèŠ‚ç‚¹]")

            while len(submitted_nodes) < total_nodes_to_execute:
                try:
                    node = ready_queue.get(timeout=1)
                    if node in submitted_nodes:
                        continue  # é˜²æ­¢é‡å¤æäº¤ï¼ˆè™½ç„¶ç†è®ºä¸Šä¸ä¼šï¼Œä½†å®‰å…¨ç¬¬ä¸€ï¼‰
                    submitted_nodes.add(node)
                    futures.append(executor.submit(process_node, node))
                    # print(f"[ğŸ“¤ å·²æäº¤èŠ‚ç‚¹ {len(submitted_nodes)}/{total_nodes_to_execute}]: {node}")
                except queue.Empty:
                    # é˜Ÿåˆ—æš‚æ—¶ç©ºï¼Œä½†è¿˜æ²¡æäº¤å®Œæ‰€æœ‰èŠ‚ç‚¹ â†’ ç­‰å¾…å­çº¿ç¨‹ç”Ÿæˆæ–°èŠ‚ç‚¹
                    # print(f"[â³ é˜Ÿåˆ—ç©ºï¼Œç­‰å¾…ä¸­... å·²æäº¤ {len(submitted_nodes)}/{total_nodes_to_execute}]")
                    # time.sleep(0.1)  # é¿å…å¿™ç­‰ï¼ŒèŠ‚çœ CPU å®é™…å·¥ç¨‹ä¸­å¯ä»¥ä½¿ç”¨ï¼Œè¿™é‡Œè¿½æ±‚å®éªŒç²¾åº¦æ²¡å†™ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š
                    continue

            # print(f"[âœ… æ‰€æœ‰ {total_nodes_to_execute} ä¸ªèŠ‚ç‚¹å·²æäº¤ï¼Œå…± {len(futures)} ä¸ªä»»åŠ¡ï¼Œå¼€å§‹ç­‰å¾…æ‰§è¡Œå®Œæˆ...]")

            # ç­‰å¾…å…¨éƒ¨å®Œæˆ
            for f in futures:
                f.result()

        # æœ€åå¤„ç† collapse èŠ‚ç‚¹
        # print('æ­£åœ¨èšåˆ collapse èŠ‚ç‚¹...')
        collapse_inputs = []
        for u, v, data in self.graph.in_edges("collapse", data=True):
            local_idx = data["output_index"]
            global_coord = data["data_coord"]
            col_data = node_outputs[u][:, local_idx]
            collapse_inputs.append((global_coord, col_data))

        collapse_inputs.sort(key=lambda x: x[0])
        raw_output = np.column_stack([col for _, col in collapse_inputs])
        result = np.apply_along_axis(self.collapse_manager.collapse, axis=1, arr=raw_output)
        # print('å®Œæˆ')
        return result

    def infer_with_graph_single(self, sample, use_pipeline=False, num_workers=4):
        """
        ä½¿ç”¨å›¾ç»“æ„å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œæ¨ç†è®¡ç®—ï¼Œå¯é€‰æ‹©æ˜¯å¦ä½¿ç”¨å¹¶è¡Œæµæ°´çº¿ã€‚

        å‚æ•°:
            sample (np.ndarray or list): å•ä¸ªæ ·æœ¬ï¼Œå½¢çŠ¶ä¸º [ç‰¹å¾ç»´åº¦]
            use_pipeline (bool): æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹æµæ°´çº¿æ¨ç†
            num_workers (int): æµæ°´çº¿ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ˆä»…å½“ use_pipeline=True æ—¶æœ‰æ•ˆï¼‰

        è¿”å›:
            float or np.ndarray: ç»è¿‡å›¾ç»“æ„å¤„ç†åçš„ç»“æœï¼ˆé€šè¿‡ collapse è¾“å‡ºï¼‰
        """
        # é€‰æ‹©æ¨ç†æ–¹å¼
        if use_pipeline:
            result = self.infer_with_pipeline(values, num_workers=num_workers)
        else:
            result = self.infer_with_graph(values)

        return result[0]
    
    # åœ¨ GraphProcessor ç±»ä¸­
    def replace_node_method(
        self,
        old_node_id: str,
        new_method_name: str
    ) -> str:
        """
        æ›¿æ¢å›¾ä¸­ä¸€ä¸ªèŠ‚ç‚¹çš„æ–¹æ³•ï¼Œå¹¶æ›´æ–°å…¶ ID å’Œæ‰€æœ‰ç›¸è¿çš„è¾¹ã€‚
        ä¸åšå›¾å…¨èŠ‚ç‚¹åˆ·æ–°ï¼ˆå…¨èŠ‚ç‚¹åˆ·æ–°è€—èƒ½é«˜å¹¶ä¸”æ¨ç†ä¸ä¾èµ–å…·ä½“idï¼Œå¯èƒ½åç»­åšä¸ªå•ç‹¬æ–¹æ³•ï¼‰
        è¯¥æ–¹æ³•ä¸åšç±»å‹æ£€æµ‹
        
        :param old_node_id: è¦æ›¿æ¢çš„æ—§èŠ‚ç‚¹ IDï¼ˆå¦‚ "2_3_return_value"ï¼‰
        :param new_method_name: æ–°çš„æ–¹æ³•åï¼ˆå¦‚ "add_values"ï¼‰
        :return: æ–°èŠ‚ç‚¹çš„ IDï¼ˆå¦‚ "2_0_add_values"ï¼‰
        """
        if new_method_name not in self.methods:
            raise ValueError(f"Method '{new_method_name}' not registered in methods.")
        graph = self.graph

        # === 1. è·å–æ—§èŠ‚ç‚¹ä¿¡æ¯ ===
        if old_node_id not in graph:
            raise ValueError(f"Node '{old_node_id}' not found in graph.")
        
        old_data = graph.nodes[old_node_id]
        old_method = old_data.get("method_name")
        if old_method is None:
            raise ValueError(f"Node '{old_node_id}' has no 'method_name' attribute.")

        # === 2. è§£ææ—§ ID è·å– layer å’Œ index å‰ç¼€ ===
        # æ—§ ID æ ¼å¼: {layer}_{index}_{method_name} æˆ– {layer}_{index}_unmatched
        id_parts = old_node_id.split('_', 2)  # æœ€å¤š split æˆ 3 éƒ¨åˆ†
        if len(id_parts) < 3:
            raise ValueError(f"Invalid node ID format: '{old_node_id}'")
        
        layer_str, index_str, _ = id_parts
        try:
            layer = int(layer_str)
        except ValueError:
            raise ValueError(f"Invalid layer in node ID: '{old_node_id}'")

        # === 3. ç”Ÿæˆæ–° ID ===
        new_base_name = new_method_name  # âœ… å…³é”®ï¼šå®šä¹‰ new_base_name
        
        existing_indices = set()
        prefix = f"{layer}_"
        suffix = f"_{new_base_name}"
        for nid in graph.nodes:
            if nid.startswith(prefix) and nid.endswith(suffix):
                idx_part = nid[len(prefix): -len(suffix)]
                if idx_part.isdigit():
                    existing_indices.add(int(idx_part))

        new_index = 0
        while new_index in existing_indices:
            new_index += 1
        new_node_id = f"{layer}_{new_index}_{new_base_name}"

        if new_node_id in graph:
            raise RuntimeError(f"Node ID collision: {new_node_id} already exists!")

        # === 4. ä¿å­˜æ—§èŠ‚ç‚¹çš„å…¥è¾¹å’Œå‡ºè¾¹ ===
        in_edges = list(graph.in_edges(old_node_id, keys=True, data=True))
        out_edges = list(graph.out_edges(old_node_id, keys=True, data=True))

        # === 5. åˆ é™¤æ—§èŠ‚ç‚¹ ===
        graph.remove_node(old_node_id)

        # === 6. æ·»åŠ æ–°èŠ‚ç‚¹ ===
        is_passthrough = (new_method_name == self.discard_node_method_name)
        graph.add_node(new_node_id, method_name=new_method_name, is_passthrough=is_passthrough)

        # === 7. é‡è¿å…¥è¾¹ï¼ˆsource -> new_node_idï¼‰===
        for src, _, key, data in in_edges:
            graph.add_edge(src, new_node_id, key=key, **data)

        # === 8. é‡è¿å‡ºè¾¹ï¼ˆnew_node_id -> targetï¼‰===
        for _, dst, key, data in out_edges:
            graph.add_edge(new_node_id, dst, key=key, **data)

        logger.debug(
            "Replaced node '%s' (%s) with '%s' (%s)",
            old_node_id, old_method, new_node_id, new_method_name
        )
        
        return new_node_id

    def _is_processing_node(self, node):
        """
        åˆ¤æ–­ä¸€ä¸ªèŠ‚ç‚¹æ˜¯å¦æ˜¯éœ€è¦æ‰§è¡Œå‡½æ•°çš„â€œå¤„ç†èŠ‚ç‚¹â€ã€‚
        æ’é™¤ rootã€collapse å’Œ passthroughï¼ˆå¦‚ discard/unmatchedï¼‰èŠ‚ç‚¹ã€‚
        """
        if node in {"root", "collapse"}:
            return False
        
        node_data = self.graph.nodes.get(node, {})

        # å¦‚æœæ˜¯ passthrough èŠ‚ç‚¹ï¼ˆå¦‚ discard_node_method_name å¯¹åº”çš„èŠ‚ç‚¹ï¼‰ï¼Œä¸è§†ä¸ºå¤„ç†èŠ‚ç‚¹
        if node_data.get("is_passthrough", False):
            return False
        
        return True

    def get_graph_entropy(self):
        """
        è®¡ç®—å›¾ç»“æ„çš„ç†µå€¼ï¼ŒåŸºäºèŠ‚ç‚¹å’Œæ–¹æ³•ç±»å‹çš„åˆ†å¸ƒã€‚
        ç¤ºä¾‹è®¡ç®—æ–¹æ³•ï¼Œå¯æ ¹æ®å®é™…éœ€æ±‚æ›¿æ¢ã€‚
        :return: è®¡ç®—å¾—åˆ°çš„å›¾ç»“æ„ç†µå€¼
        """
        method_counter = Counter()

        # ç»Ÿè®¡æ¯ç§æ–¹æ³•çš„å‡ºç°æ¬¡æ•°
        for node in self.graph.nodes:
            data = self.graph.nodes[node]
            method_name = data.get("method_name")
            if method_name and method_name != "null":  # å¿½ç•¥ null èŠ‚ç‚¹
                method_counter[method_name] += 1

        if not method_counter:
            return 0.0

        # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
        total = sum(method_counter.values())
        probabilities = [count / total for count in method_counter.values()]

        # è®¡ç®—é¦™å†œç†µ
        entropy = -sum(p * math.log2(p) for p in probabilities if p > 0)

        return entropy

    def get_method_counter(self):
        """
        ç»Ÿè®¡å›¾ä¸­å„ method_name çš„å‡ºç°æ¬¡æ•°
        """
        from collections import Counter
        method_counter = Counter()

        for node in self.graph.nodes:
            data = self.graph.nodes[node]
            method_name = data.get("method_name")
            if method_name and method_name != "null":  # å¿½ç•¥ null èŠ‚ç‚¹
                method_counter[method_name] += 1

        return method_counter

    def get_max_layer_from_graph(self):
        max_layer = 0
        for node in self.graph.nodes:
            if node == 'root' or node == 'collapse':
                continue
            if isinstance(node, str) and '_' in node:
                layer = int(node.split('_')[0])
                if layer > max_layer:
                    max_layer = layer
        return max_layer