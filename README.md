[English](README_en.md) | 中文
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/gugugu12138/AdaptoFlux)

# AdaptoFlux 项目简介（简洁版）

AdaptoFlux（池流算法）是一种基于“**方法池 + 图结构优化**”的新型机器学习框架。其核心思想是通过组合方法池中的先验知识，动态构建和优化数据流图（DFG），以实现跨任务的知识共享与迁移，从而提升模型的学习效率与适应能力。

主要特点：
-   **方法池（Method Pool）**：集成映射函数（F）与动作函数（O），支持纯计算与状态交互。
-   **动态数据流图（DFG）**：以 `root` -> `处理节点` -> `collapse` 为核心结构，支持模块化计算与路径组合。
-   **图演（GraphEvo）优化框架**：通过“多样初始化→逐节点精炼→模块化压缩→方法池进化”四步闭环，实现图结构自进化。
-   **多类型图结构**：原生支持有向无环图 (DAG)、含宏观环路的图、脉冲驱动型图，适配不同任务范式。
-   **高可解释性与灵活性**：显式图结构便于理解和调试，适用于符号回归、小样本建模、游戏AI等场景。

---

# AdaptoFlux

**一种基于方法池实现知识复用与持续学习的新型机器学习框架**

🚧 本项目目前为开发阶段（WIP）。功能尚不完整，API 可能会变更。

## 项目概述

AdaptoFlux（池流算法）是一种基于“**方法池 + 图结构优化**”的新型机器学习框架，旨在解决传统模型“从头训练、知识难复用”的痛点。它通过引入“方法池”机制，将历史任务中积累的优秀策略（如数据预处理、特征提取、决策规则等）封装为可复用的“工具”，并在面对新任务时，智能地选择和组合这些工具，动态构建出最优的数据处理流水线（即数据流图）。

与依赖梯度更新的深度学习或元学习不同，AdaptoFlux的核心是**图结构的动态构建与优化**。它不局限于纯数值运算，还能集成具有副作用的动作（如环境交互），这使其在具身智能、游戏AI等复杂场景中具有天然优势。框架的显式图结构也带来了极强的可解释性，开发者可以清晰地看到AI的决策过程。

## 进展情况

-   **图演（GraphEvo）框架**：已完成“方法池进化”，“多样初始化”和“逐节点精炼”的核心逻辑，正在开发“模块化压缩”与模块。
-   **图结构系统**：目前仅支持DAG。
并行加速：已实现基于有向图拓扑感知的动态任务并行加速，可并发执行无依赖节点，显著缩短高压情况下的推理延迟。
-   **方法池管理**：动态导入和装饰器系统已稳定。

## 未来工作

-   **完善图演框架**：完成“模块化压缩”（识别并替换等效子图）。
-   **路径生成器的类型匹配和权重系统**：完成路径生成器的类型匹配和权重系统
-   **升级LayerGrowTrainer**：
    -   **升级接受策略**：为 `_should_accept` 函数添加更多可选算法。
-   **实现脉冲驱动图**：为游戏NPC和实时系统开发事件触发机制。
-   **实现含宏观环路的图**：完成含宏观环路的图的反馈机制和自进化。
-   **增强方法池**：
    -   实现方法池的遗传算法筛选器，用于从大型方法池中快速定位最优子集。
    -   为方法池装饰器增加更完善的输入/输出类型检查和自动文档生成功能。
    -   支持多方法池并行处理不同数据流。
-   **应用探索**：
    -   编写在不修改MLP权重的情况下，用AdaptoFlux图作为其前端数据预处理器的示例。
    -   在游戏引擎中集成AdaptoFlux，实现具备复杂决策逻辑的NPC。
-   **可视化**

# 如何使用

1.  创建新的 conda 环境：

```bash
conda create -n AdaptoFlux python=3.12
conda activate AdaptoFlux
```

2.  克隆仓库：

```bash
git clone https://github.com/gugugu12138/AdaptoFlux.git
cd AdaptoFlux
```

3.  安装依赖：

```bash
pip install -r requirements.txt
```

# 修改方法池

AdaptoFlux的核心是方法池。您可以通过修改 `methods.py` 或创建新的Python文件来扩展它。

每个方法都需使用 `@method_profile` 装饰器进行注册，该装饰器定义了方法的输入/输出数量、数据类型、分组和权重等关键元信息。

```python
from ATF.core.adaptoflux import method_profile

@method_profile(
    output_count=1,
    input_types=['scalar'],
    output_types=['scalar'],
    group='math',
    weight=1.0,
    vectorized=True
)
def add_one(a):
    """将输入值加一"""
    return [a + 1]
```

**灵活运用**：AdaptoFlux 支持将任何函数或模型（如 MLP、随机森林）封装为方法。为了最大化框架的可解释性优势，建议将复杂模型置于图的末端（如 `collapse` 节点），让 AdaptoFlux 的前置图结构作为其可解释的数据预处理器。当然，您也可以将它们放在图的任意位置，以实现更复杂的知识组合。

# 核心概念与架构说明

## 1. 方法池系统 (Method Pool, Q)

方法池是AdaptoFlux的知识库，包含所有可用的操作单元。每个方法是一个具身化行为，可能包含计算和状态变更。

*   **函数池 (F)**：纯计算操作，无副作用。例如：`f(x) = x * 2 + 1`。
*   **动作池 (O)**：具有副作用的操作，如修改状态、发送指令。例如：`send_notification("Hello")`。

### 可逆性分类 (针对函数池 F)
| 类型 | 特性 | 反向推导能力 |
| :--- | :--- | :--- |
| **完全可逆 (FR)** | 仅凭输出即可唯一还原所有输入。 | 完全可逆 |
| **可逆 (R)** | 结合部分输入信息，可唯一还原完整输入。 | 条件可逆 |
| **非可逆 (N)** | 多个输入可能映射到同一输出。 | 不可逆 |

### 副作用分类 (针对动作池 O)
| 类型 | 特性 | 影响自身 | 影响环境 |
| :--- | :--- | :--- | :--- |
| 自身副作用池 | 仅修改自身内部状态。 | 是 | 否 |
| 环境副作用池 | 仅与外部环境交互。 | 否 | 是 |
| 双重副作用池 | 同时影响自身和环境。 | 是 | 是 |

## 2. 图系统 (Data Flow Graph, DFG)

AdaptoFlux的计算模型是一个广义的数据流图 `G = (V, E)`，包含三类核心节点：

*   **`root` 节点**：图的入口，接收原始输入数据。
*   **`处理` 节点**：执行方法池中的具体方法，是图的主体。
*   **`collapse` 节点**：图的出口，负责将中间结果转换为最终输出格式。**强烈不建议**将其与`root`节点物理合并，即使是为了构建反馈环路。正确的做法是保留独立的`collapse`节点，并将其输出边连接回`root`。

### 三种核心图结构类型
*   **有向无环图 (DAG)**：适用于静态、一次性计算任务（如批处理）。
*   **含宏观环路的图**：通过将`collapse`输出连接回`root`（或中间节点）实现反馈，适用于在线学习、状态持续更新。
*   **脉冲驱动型图**：由外部事件或信号触发执行，适用于实时响应系统（如游戏AI）。

## 3. 训练与优化：图演 (GraphEvo) 框架

AdaptoFlux的核心优化逻辑是**图演（GraphEvo）框架**，这是一个四阶段的自进化闭环：

1.  **多样初始化**：随机生成多个初始图结构，选择性能最佳者作为起点。
2.  **逐节点精炼**：在固定图结构上，逐个尝试替换处理节点（需保证输入/输出类型兼容），采用贪心策略，只接受能提升性能的替换。
3.  **方法池进化**：将训练过程中发现的高频、高性能子图结构，抽象封装为新的方法，注入方法池，供后续任务使用。
4.  **模块化压缩**：识别图中可被更小子图等效替换的部分，用高性能、高效率的子结构进行替换。

### 方法池进化机制详解

**方法池进化**是 GraphEvo 框架实现“自增强”能力的核心：它将演化过程中反复出现且表现优异的子图结构自动提炼为可复用的**新计算原语（即“方法”）**，并注入全局方法池，从而在后续任务或演化轮次中扩展搜索空间、加速优化过程。

该机制高效可行的关键在于一个设计约束：**在“逐节点精炼”阶段，图的拓扑结构（节点连接关系）始终保持不变**。这意味着所有演化快照（snapshots）共享相同的图骨架，使得我们可以跨轮次对齐“相同逻辑位置”的节点，而无需进行昂贵的子图同构匹配。

#### 1. 拓扑签名对齐节点

每个节点通过其**拓扑签名（topological signature）** 被唯一标识，签名定义为：

```
(layer, in_coords, out_coords)
```

- `layer`：节点在计算图中的拓扑深度；
- `in_coords` / `out_coords`：输入/输出边上携带的数据坐标集合（代表数据来源与去向）。

该签名与节点 ID 或具体方法无关，仅反映其在数据流中的结构角色，因此可在不同快照间稳定对齐同一逻辑位置的节点。

#### 2. 高频子图发现流程

基于对齐后的节点，系统执行以下三步自动挖掘高频子图：

1. **方法频次统计**  
   遍历所有演化快照，统计每个拓扑签名位置上各类方法的出现次数，构建 `signature → {method: count}` 映射。

2. **高频节点筛选与连通分量提取**  
   移除出现频次低于阈值的节点，剩余节点在原图中自然形成若干**连通子图**——这些即为潜在的可复用模块。

3. **同构合并去重（可选，通常在多任务中使用）**  
   对相同规模的连通子图进行轻量子图同构检测（如 WL 哈希），合并结构相同的子图并累加其总频次，避免冗余。

#### 3. 高置信度准入机制

并非所有高频子图都能进入方法池。只有满足以下任一条件的子图才会被抽象为新方法：

- **演化稳定性**：在单任务的多轮演化中高频且持续出现（如 ≥80% 轮次包含）；
- **跨任务泛化性**：在多个相关任务中被独立发现并复用，表明其具备通用语义。

所有候选子图必须通过统一验证流程，无例外通道。这确保了方法池仅包含经过充分验证的高质量计算单元，防止过拟合或噪声结构污染进化过程。

#### 4. 效率优势

得益于拓扑不变性，整个方法池进化过程的时间复杂度仅为 $\mathcal{O}(G N T)$（$G$：任务数，$N$：节点数，$T$：演化轮次），远低于通用子图挖掘的指数级开销 $\mathcal{O}(G T \cdot N^{k_{\max}})$。这使得 GraphEvo 能在大规模图结构上实现高效、可持续的自进化。

> **闭环增强效应**：新方法注入后，后续演化可直接调用这些高层抽象模块，从而探索更复杂的结构组合，形成“发现 → 抽象 → 复用 → 再发现”的正向循环，持续提升模型性能与架构表达能力。

### 核心构建机制：层叠式生成-评估-回退

在“多样初始化”和“逐节点精炼”阶段，采用“层叠式生成-评估-回退”机制来扩展或修改图：
1.  **生成**：基于当前图的输出结构，生成候选的新层或新节点。
2.  **评估**：将候选结构临时加入图中，通过一次快速前向传播评估其性能。
3.  **决策与回退**：若性能提升则接受；否则撤销更改，尝试其他候选方案。

### 遗传算法的角色

遗传算法在AdaptoFlux中主要扮演**辅助筛选**的角色：
*   **方法池筛选**：当拥有一个庞大的基础方法池时，可以用遗传算法快速筛选出一个针对当前任务的、高性能的子方法池。
*   **全局图结构探索**：作为一种计算开销较大的离线策略，可用于在多个已训练好的模型图结构之间进行交叉变异，探索更优组合。

## 4. 性能与理论分析

### 搜索空间
AdaptoFlux的搜索空间（所有可能的图结构）随方法池大小和图的层数呈指数级增长。图演框架通过分阶段、贪心和模块化等策略，将搜索空间从指数级压缩到工程可行的多项式级别。

### 理论最大层数
图的深度并非无限。定义方法 `a` 的输入输出比为 `r_a = inputs(a) / outputs(a)`，方法池的期望压缩比为 `H = Σ(W_i * r_i)`。当第 `L` 层的数据量 `n_L = n0 * H^L` 低于方法池中任意方法所需的最小输入量时，扩展终止。最大层数 `L_max` 可估算为：
`L_max = ⌊log(n_min / n0) / log H⌋` (当 H > 1 时)

### 前向传播加速

为最大化单次推理或训练迭代的硬件利用率，AdaptoFlux 实现了一种 **基于有向图拓扑感知的动态任务并行加速方法**。

**核心思想**：利用图结构的有向无环特性，动态识别“就绪节点”（即所有前驱已执行完成的节点），并使用多线程并发执行这些节点。

**实现流程**：
1.  **依赖分析与初始化**：对图中所有非根节点统计其入度（前驱节点数量）。入度为 0 的节点（除 `root` 外）被加入就绪队列。
2.  **动态调度**：使用线程池并发执行就绪队列中的节点。每当一个节点执行完成，其所有后继节点的“剩余入度”减 1；若减至 0，则加入就绪队列。
3.  **同步与聚合**：所有节点执行完毕后，按 `collapse` 节点的输入边顺序聚合输出，完成单样本推理。

**优势**：
-   **低延迟**：通过并发执行无依赖节点，显著缩短单次前向传播时间。
-   **通用性强**：适用于任意有向无环计算图，无需预先划分阶段。
-   **资源自适应**：线程数可配置，适应不同硬件环境。

**性能瓶颈**：
该方法的加速效果受限于图中的**关键路径长度**（即最长依赖链）和**节点计算负载的不均衡性**。未来工作将探索更智能的节点调度策略与负载均衡机制。

---

## 应用示例

![球壳问题训练模型可视化](assets\images\球壳模型可视化.png)  
*图1：在球壳问题上训练得到的AdaptoFlux模型结构可视化（DFG图）*

![训练决策图](assets\images\球壳决策可视化训练.png)  
*图2：模型在训练集上的决策边界或路径激活情况*

![测试决策图](assets\images\球壳决策可视化测试.png)  
*图3：模型在测试集上的泛化表现与决策路径*
