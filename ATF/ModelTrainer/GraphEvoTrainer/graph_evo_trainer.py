# graph_evo_trainer.py
from ..model_trainer import ModelTrainer
import numpy as np
import logging
import random
import copy
from typing import Optional, List, Dict, Any, Tuple
import os
import json
import traceback
from ...PathGenerator.path_generator import PathGenerator
from ...GraphProcessor.graph_processor import GraphProcessor
from ...core.evolved_method import EvolvedMethod
from collections import defaultdict
import networkx as nx
from networkx.readwrite import json_graph
from datetime import datetime

from .method_pool_evolver import MethodPoolEvolver

from .Components import (
    BFSSubgraphSampler,
    SubgraphIOExtractor,
    SubgraphReplacer,
    MSEEquivalenceChecker
)

from .refinement_strategies import (
    refine_random_single_step,
    refine_full_sweep_step,
    refine_multi_node_joint_step,
)

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class GraphEvoTrainer(ModelTrainer):
    """
    ä¸€ä¸ªç»§æ‰¿è‡ª ModelTrainer çš„å…·ä½“è®­ç»ƒå™¨ã€‚
    è¯¥è®­ç»ƒå™¨å®ç°äº† AdaptoFlux çš„å›¾æ¼”ï¼ˆGraphEvoï¼‰ä¼˜åŒ–æ¡†æ¶ã€‚
    é€šè¿‡â€œå¤šæ ·åˆå§‹åŒ– â†’ é€èŠ‚ç‚¹ç²¾ç‚¼ â†’ æ¨¡å—åŒ–å‹ç¼© â†’ æ–¹æ³•æ± è¿›åŒ–â€çš„é—­ç¯æµç¨‹ï¼Œå®ç°å›¾ç»“æ„çš„è‡ªè¿›åŒ–ä¼˜åŒ–ã€‚
    """

    def __init__(
        self,
        # çˆ¶ç±»å‚æ•°
        adaptoflux_instance,
        loss_fn='mse',
        task_type='regression',
        use_pipeline=False,      # â† æ–°å¢
        num_workers=4,           # â† æ–°å¢
        custom_loss_evaluator=None,      # â† æ–°å¢ï¼šè‡ªå®šä¹‰æŸå¤±è¯„ä¼°å™¨
        custom_accuracy_evaluator=None,   # â† æ–°å¢ï¼šè‡ªå®šä¹‰å‡†ç¡®ç‡è¯„ä¼°å™¨
        acceptance_strategy=None,  # â† æ–°å¢ï¼šè‡ªå®šä¹‰æ¥å—ç­–ç•¥

        # æœ¬ç±»å‚æ•°
        num_initial_models: int = 5,
        max_refinement_steps: int = 100,
        compression_threshold: float = 0.95,
        max_init_layers: int = 3,
        init_mode: str = "fixed",
        init_layers_list: Optional[List[int]] = None,
        frozen_nodes: Optional[List[str]] = None,
        frozen_methods: Optional[List[str]] = None,
        refinement_strategy: str = "random_single",
        custom_refinement_strategy_func: Optional[callable] = None,  # â† æ–°å¢
        candidate_pool_mode: str = "group",
        fallback_mode: Optional[str] = None,
        enable_evolution: bool = True,
        evolution_sampling_frequency: int = 1,
        evolution_trigger_count: int = 3,
        evolution_cleanup_mode: str = "full",
        consensus_threshold: Optional[float] = None,  # <-- æ–°å¢
        methods_per_evolution: int = 1,
        min_subgraph_size_for_evolution: int = 2,  # <-- æ–°å¢å‚æ•°

        verbose: bool = True,

        enable_compression: bool = False,
        compression_mode: str = "symbolic",  # æ–°å¢ï¼šé»˜è®¤ä¸º symbolic
        symbolic_compression_rules: Optional[List[Tuple[Any, Any]]] = None,  # æ–°å¢

        **kwargs
    ):
        """
        åˆå§‹åŒ– GraphEvoTrainerï¼Œç”¨äºæ‰§è¡Œ AdaptoFlux çš„å›¾ç»“æ„è‡ªè¿›åŒ–ä¼˜åŒ–æµç¨‹ã€‚

        æœ¬è®­ç»ƒå™¨é€šè¿‡å››ä¸ªæ ¸å¿ƒé˜¶æ®µå®ç°å›¾ç»“æ„çš„è¿­ä»£ä¼˜åŒ–ï¼š
        1. **å¤šæ ·åˆå§‹åŒ–**ï¼šç”Ÿæˆå¤šä¸ªéšæœºåˆå§‹å›¾ï¼Œé€‰æ‹©æ€§èƒ½æœ€ä¼˜è€…ä½œä¸ºèµ·ç‚¹ï¼›
        2. **é€èŠ‚ç‚¹ç²¾ç‚¼**ï¼šå¯¹å›¾ä¸­å¯ä¼˜åŒ–èŠ‚ç‚¹å°è¯•æ–¹æ³•æ›¿æ¢ï¼Œå±€éƒ¨æœç´¢æ›´ä¼˜ç»“æ„ï¼›
        3. **æ–¹æ³•æ± è¿›åŒ–**ï¼ˆå¯é€‰ï¼‰ï¼šåŸºäºè®°å½•çš„é«˜æ€§èƒ½å›¾ç»“æ„ï¼ŒæŠ½è±¡æ–°æ–¹æ³•æ³¨å…¥æ–¹æ³•æ± ã€‚
        4. **æ¨¡å—åŒ–å‹ç¼©**ï¼ˆå¯é€‰ï¼‰ï¼šè¯†åˆ«å¹¶æ›¿æ¢ç­‰æ•ˆçš„é«˜æ•ˆå­å›¾ï¼Œå®ç°ç»“æ„ç®€åŒ–ï¼›
        

        å‚æ•°æ§åˆ¶è¯´æ˜ï¼š
        - **åˆå§‹åŒ–æ§åˆ¶**ï¼šé€šè¿‡ `num_initial_models`ã€`init_mode` ç­‰æ§åˆ¶åˆå§‹å¤šæ ·æ€§ï¼›
        - **ç²¾ç‚¼æ§åˆ¶**ï¼šé€šè¿‡ `refinement_strategy`ã€`frozen_nodes` ç­‰æ§åˆ¶å±€éƒ¨æœç´¢è¡Œä¸ºï¼›
        - **è¿›åŒ–æ§åˆ¶**ï¼šé€šè¿‡ `evolution_sampling_frequency`ã€`evolution_trigger_count` ç­‰æ§åˆ¶è¿›åŒ–è§¦å‘æœºåˆ¶ã€‚
        - **å‹ç¼©æ§åˆ¶**ï¼šé€šè¿‡ `enable_compression`ã€`compression_threshold` æ§åˆ¶æ˜¯å¦å¯ç”¨åŠç­‰æ•ˆæ€§æ ‡å‡†ï¼›
        :param adaptoflux_instance: å·²åˆå§‹åŒ–çš„ AdaptoFlux å®ä¾‹ï¼Œä½œä¸ºä¼˜åŒ–çš„åŸºç¡€æ¨¡æ¿ã€‚
        :param num_initial_models: å¤šæ ·åˆå§‹åŒ–é˜¶æ®µç”Ÿæˆçš„å€™é€‰æ¨¡å‹æ•°é‡ã€‚
        :param max_refinement_steps: å•æ¬¡ç²¾ç‚¼é˜¶æ®µå…è®¸çš„æœ€å¤§ä¼˜åŒ–æ­¥æ•°ã€‚
        :param max_total_refinement_attempts: æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­å…è®¸çš„æœ€å¤§å€™é€‰æ–¹æ³•è¯„ä¼°æ¬¡æ•°ï¼ˆç”¨äºé™åˆ¶è®¡ç®—èµ„æºæ¶ˆè€—ï¼‰ã€‚è‹¥ä¸º None åˆ™ä¸é™åˆ¶ã€‚
        :param compression_threshold: æ¨¡å—åŒ–å‹ç¼©é˜¶æ®µåˆ¤å®šå­å›¾ç­‰æ•ˆçš„ MSE ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå€¼è¶Šå°è¦æ±‚è¶Šä¸¥æ ¼ï¼‰ã€‚
        :param max_init_layers: åˆå§‹åŒ–æ—¶æ¯ä¸ªå€™é€‰æ¨¡å‹æœ€å¤šæ·»åŠ çš„éšæœºå±‚æ•°ï¼ˆä»…åœ¨ init_mode="fixed" æ—¶ç”Ÿæ•ˆï¼‰ã€‚
        :param init_mode: åˆå§‹åŒ–æ¨¡å¼ï¼Œ"fixed" è¡¨ç¤ºæ‰€æœ‰æ¨¡å‹æ·»åŠ ç›¸åŒå±‚æ•°ï¼Œ"list" è¡¨ç¤ºæŒ‰ init_layers_list æŒ‡å®šã€‚
        :param init_layers_list: å½“ init_mode="list" æ—¶ï¼ŒæŒ‡å®šæ¯ä¸ªå€™é€‰æ¨¡å‹çš„åˆå§‹åŒ–å±‚æ•°ï¼Œé•¿åº¦éœ€ â‰¥ num_initial_modelsã€‚
        :param frozen_nodes: æ˜¾å¼å†»ç»“çš„èŠ‚ç‚¹åç§°åˆ—è¡¨ï¼ˆå¦‚ ["root", "collapse"]ï¼‰ï¼Œè¿™äº›èŠ‚ç‚¹åœ¨ç²¾ç‚¼é˜¶æ®µä¸ä¼šè¢«ä¿®æ”¹ã€‚
        :param frozen_methods: æ˜¾å¼å†»ç»“çš„æ–¹æ³•åç§°åˆ—è¡¨ï¼ˆå¦‚ ["return_value"]ï¼‰ï¼Œä½¿ç”¨è¿™äº›æ–¹æ³•çš„èŠ‚ç‚¹å°†è‡ªåŠ¨è¢«å†»ç»“ã€‚
        :param refinement_strategy: ç²¾ç‚¼ç­–ç•¥ï¼Œå¯é€‰å€¼ï¼š
            - "random_single"ï¼šéšæœºå•ç‚¹ä¼˜åŒ–ï¼›
            - "full_sweep"ï¼šå…¨å›¾éå†ä¼˜åŒ–ï¼›
            - "multi_node_joint"ï¼šå¤šèŠ‚ç‚¹è”åˆä¼˜åŒ–ï¼ˆæœªå®ç°ï¼Œå ä½ï¼‰ï¼›
            - "custom"ï¼šä½¿ç”¨ custom_refinement_strategy_func æä¾›çš„å‡½æ•°ï¼›
            - æˆ–ç›´æ¥ä¼ å…¥ä¸€ä¸ª callable å‡½æ•°å¯¹è±¡ã€‚
        :param custom_refinement_strategy_func: å½“ refinement_strategy="custom" æ—¶ï¼Œ
            æä¾›çš„è‡ªå®šä¹‰ç­–ç•¥å‡½æ•°ã€‚å‡½æ•°ç­¾åéœ€ä¸ `_refine_random_single_step` ä¸€è‡´ã€‚
        :param candidate_pool_mode: æ„å»ºå€™é€‰æ–¹æ³•æ± çš„ç­–ç•¥ï¼Œ"all"ï¼ˆæ‰€æœ‰æ–¹æ³•ï¼‰ã€"group"ï¼ˆåŒç»„æ–¹æ³•ï¼‰æˆ– "self"ï¼ˆä»…è‡ªèº«ï¼‰ã€‚
        :param fallback_mode: å½“æ— ç±»å‹å…¼å®¹æ–¹æ³•æ—¶çš„å…œåº•ç­–ç•¥ï¼Œ"all"/"group_first"/"self"/"error"ã€‚
        :param enable_compression: æ˜¯å¦å¯ç”¨æ¨¡å—åŒ–å‹ç¼©é˜¶æ®µã€‚
        :param enable_evolution: æ˜¯å¦å¯ç”¨æ–¹æ³•æ± è¿›åŒ–é˜¶æ®µã€‚
        :param evolution_sampling_frequency: æ¯éš”å¤šå°‘ä¸ªè®­ç»ƒè½®æ¬¡ï¼ˆå³ä¸€æ¬¡å®Œæ•´çš„ã€Œç²¾ç‚¼+å‹ç¼©ã€å¾ªç¯ï¼‰è®°å½•ä¸€æ¬¡å½“å‰å›¾ç»“æ„å¿«ç…§ï¼Œç”¨äºåç»­æ–¹æ³•æ± è¿›åŒ–ã€‚ä¾‹å¦‚è®¾ä¸º 2 è¡¨ç¤ºæ¯ 2 è½®ä¿å­˜ä¸€æ¬¡å¿«ç…§ã€‚
        :param evolution_trigger_count: å½“ç´¯è®¡è®°å½•çš„å›¾å¿«ç…§æ•°é‡è¾¾åˆ°æ­¤å€¼æ—¶ï¼Œè§¦å‘ä¸€æ¬¡æ–¹æ³•æ± è¿›åŒ–ã€‚
        :param evolution_cleanup_mode: è¿›åŒ–å®Œæˆåå¦‚ä½•æ¸…ç†å·²è®°å½•çš„å¿«ç…§ï¼Œ"full"ï¼ˆæ¸…ç©ºå…¨éƒ¨ï¼‰æˆ– "oldest"ï¼ˆä»…ç§»é™¤æœ€æ—©çš„ä¸€ä¸ªï¼‰ã€‚
        :param methods_per_evolution: æ¯æ¬¡æ–¹æ³•æ± è¿›åŒ–æ—¶ï¼Œæœ€å¤šä»è®°å½•çš„å›¾ç»“æ„ä¸­æŠ½è±¡å¹¶æ·»åŠ çš„æ–°æ–¹æ³•æ•°é‡ã€‚
        :param verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ä¿¡æ¯ã€‚
        :param kwargs: å…¶ä»–å¯é€‰ç»„ä»¶ï¼Œå¦‚è‡ªå®šä¹‰çš„ subgraph_samplerã€io_extractor ç­‰ã€‚
        """

        super().__init__(adaptoflux_instance, loss_fn, task_type, use_pipeline, num_workers,
                         custom_loss_evaluator, custom_accuracy_evaluator, acceptance_strategy)
        self.method_pool_evolver = MethodPoolEvolver(self)
        self.num_initial_models = num_initial_models
        self.max_refinement_steps = max_refinement_steps
        self.compression_threshold = compression_threshold
        self.max_init_layers = max_init_layers
        self.init_mode = init_mode
        self.init_layers_list = init_layers_list
        self.frozen_nodes = set(frozen_nodes) if frozen_nodes else set()
        self.frozen_methods = set(frozen_methods) if frozen_methods else set()  # <-- ä¿å­˜ä¸ºé›†åˆ
        self.candidate_pool_mode = candidate_pool_mode
        self.fallback_mode = fallback_mode or 'self' 

        self.refinement_strategy = refinement_strategy
        self.custom_refinement_strategy_func = custom_refinement_strategy_func

        self.enable_evolution = enable_evolution
        self.evolution_sampling_frequency = evolution_sampling_frequency
        self.evolution_trigger_count = evolution_trigger_count
        self.evolution_cleanup_mode = evolution_cleanup_mode

        self.methods_per_evolution = methods_per_evolution
        self.verbose = verbose

        # æ¨¡å—åŒ–å‹ç¼©ç›¸å…³
        self.enable_compression = enable_compression
        self.compression_mode = compression_mode
        self.consensus_threshold = consensus_threshold
        self.symbolic_compression_rules = symbolic_compression_rules or []

        # æ ¡éªŒ compression_mode
        if self.compression_mode not in {"symbolic", "numerical"}:
            raise ValueError("compression_mode must be 'symbolic' or 'numerical'")
            

        self.subgraph_sampler = kwargs.get('subgraph_sampler') or BFSSubgraphSampler(max_nodes=4)
        self.io_extractor = kwargs.get('io_extractor') or SubgraphIOExtractor()
        # self.replacer = kwargs.get('replacer') or SubgraphReplacer()
        self.equivalence_checker = kwargs.get('equivalence_checker') or MSEEquivalenceChecker(
            threshold=self.compression_threshold
        )

        self.min_subgraph_size_for_evolution = min_subgraph_size_for_evolution
        if self.min_subgraph_size_for_evolution < 1:
            raise ValueError("min_subgraph_size_for_evolution must be at least 1")

        # æ ¡éªŒå‚æ•°
        if self.methods_per_evolution < 1:
            raise ValueError("methods_per_evolution must be >= 1")
        if self.init_mode == "list":
            if self.init_layers_list is None:
                raise ValueError("init_mode='list' requires init_layers_list to be provided.")
            if len(self.init_layers_list) < self.num_initial_models:
                raise ValueError(f"init_layers_list length ({len(self.init_layers_list)}) must be >= num_initial_models ({self.num_initial_models})")
        if self.consensus_threshold is not None:
            if not (0.0 <= self.consensus_threshold <= 1.0):
                raise ValueError("consensus_threshold must be in [0.0, 1.0] or None")

        # ç”¨äºè®°å½•å®Œæ•´å›¾ç»“æ„å¿«ç…§ï¼ˆç”¨äºæ–¹æ³•æ± è¿›åŒ–ï¼‰
        self.graph_snapshots: List[Any] = []
        
        # åŸæœ‰ _strategy_map
        self._strategy_map = {
            "random_single": refine_random_single_step,
            "full_sweep": refine_full_sweep_step,
            "multi_node_joint": refine_multi_node_joint_step,
            # TODO: å¤šèŠ‚ç‚¹è”åˆä¼˜åŒ–ï¼ˆè§ä¸‹æ–‡ï¼‰
        }

        # æ–°å¢ï¼šæ”¯æŒè‡ªå®šä¹‰å‡½æ•°
        if custom_refinement_strategy_func is not None:
            self._strategy_map["custom"] = custom_refinement_strategy_func
            if refinement_strategy == "custom":
                pass  # åˆæ³•
        else:
            if refinement_strategy == "custom":
                raise ValueError("custom strategy requires custom_refinement_strategy_func")

        # æ ¡éªŒ
        valid_pool_modes = {"all", "group", "self"}
        valid_fallback_modes = {"all", "group_first", "self", "error"}
        if self.candidate_pool_mode not in valid_pool_modes:
            raise ValueError(f"Invalid candidate_pool_mode: {self.candidate_pool_mode}")
        if self.fallback_mode not in valid_fallback_modes:
            raise ValueError(f"Invalid fallback_mode: {self.fallback_mode}")


    def _phase_diverse_initialization(self, input_data: np.ndarray, target: np.ndarray) -> Dict[str, Any]:
        """
        é˜¶æ®µä¸€ï¼šå¤šæ ·åˆå§‹åŒ– (Diverse Initialization)
        éšæœºç”Ÿæˆå¤šç»„åˆå§‹æ¨¡å‹ï¼Œé€šè¿‡å¿«é€Ÿè¯„ä¼°ç­›é€‰å‡ºæœ€ä¼˜è€…ä½œä¸ºä¼˜åŒ–èµ·ç‚¹ã€‚

        :param input_data: ç”¨äºè¯„ä¼°çš„è¾“å…¥æ•°æ®
        :param target: å¯¹åº”çš„æ ‡ç­¾
        :return: åŒ…å«æœ€ä¼˜æ¨¡å‹ä¿¡æ¯çš„å­—å…¸ {'best_model': AdaptoFluxå®ä¾‹, 'best_loss': float, 'best_acc': float}
        """
        if self.verbose:
            logger.info(f"[Phase 1] Diverse Initialization: Generating {self.num_initial_models} candidate models...")

        candidates = []
        for i in range(self.num_initial_models):
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ã€ç‹¬ç«‹çš„ AdaptoFlux å®ä¾‹å‰¯æœ¬
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ AdaptoFlux ç±»æœ‰ä¸€ä¸ª `clone()` æ–¹æ³•æˆ–ç±»ä¼¼çš„æœºåˆ¶
            # å¦‚æœæ²¡æœ‰ï¼Œæ‚¨éœ€è¦å®ç°ä¸€ä¸ªæ·±æ‹·è´é€»è¾‘ï¼Œç¡®ä¿ graph å’Œ methods éƒ½è¢«å¤åˆ¶
            try:
                candidate_af = self.adaptoflux.clone()
            except AttributeError:
                # å¦‚æœæ²¡æœ‰ clone æ–¹æ³•ï¼Œåˆ™è¿›è¡Œæ·±æ‹·è´
                candidate_af = copy.deepcopy(self.adaptoflux)
                # é‡ç½®å…¶å†…éƒ¨çŠ¶æ€ï¼Œç¡®ä¿ç‹¬ç«‹æ€§
                candidate_af.graph_processor.graph = copy.deepcopy(self.adaptoflux.graph_processor.graph)
                candidate_af.methods = copy.deepcopy(self.adaptoflux.methods)

            # æ ¹æ®åˆå§‹åŒ–æ¨¡å¼å†³å®šæ·»åŠ å±‚æ•°
            if self.init_mode == "fixed":
                layers_to_add = self.max_init_layers
            elif self.init_mode == "list":
                layers_to_add = self.init_layers_list[i]  # ç¬¬ i ä¸ªå€™é€‰æ¨¡å‹ä½¿ç”¨åˆ—è¡¨ä¸­ç¬¬ i é¡¹
            else:
                raise ValueError(f"Unsupported init_mode: {self.init_mode}")

            # å¯¹å€™é€‰æ¨¡å‹è¿›è¡Œéšæœºåˆå§‹åŒ–
            self._randomly_initialize_graph(candidate_af, num_layers_to_add=layers_to_add)

            # è¯„ä¼°å€™é€‰æ¨¡å‹
            loss = self._evaluate_loss(input_data, target, adaptoflux_instance=candidate_af)
            acc = self._evaluate_accuracy(input_data, target, adaptoflux_instance=candidate_af)

            candidates.append({
                'model': candidate_af,
                'loss': loss,
                'accuracy': acc,
                'id': i
            })

            if self.verbose:
                logger.info(f"  Candidate {i+1}/{self.num_initial_models}: Loss={loss:.6f}, Acc={acc:.4f}")

        # é€‰æ‹©æŸå¤±æœ€ä½çš„æ¨¡å‹ä½œä¸ºæœ€ä¼˜æ¨¡å‹
        best_candidate = min(candidates, key=lambda x: x['loss'])

        if self.verbose:
            logger.info(f"[Phase 1] Selected best initial model (ID: {best_candidate['id']}) with Loss={best_candidate['loss']:.6f}, Acc={best_candidate['accuracy']:.4f}")

        return {
            'best_model': best_candidate['model'],
            'best_loss': best_candidate['loss'],
            'best_accuracy': best_candidate['accuracy']
        }

    def _randomly_initialize_graph(self, adaptoflux_instance, num_layers_to_add: int = 3):
        """
        ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œç”¨äºå¯¹ç»™å®šçš„ AdaptoFlux å®ä¾‹è¿›è¡Œéšæœºçš„å›¾ç»“æ„åˆå§‹åŒ–ã€‚
        é€šè¿‡è°ƒç”¨å…¶ `append_nx_layer` æ–¹æ³•éšæœºæ·»åŠ å‡ å±‚ã€‚

        :param adaptoflux_instance: è¦åˆå§‹åŒ–çš„ AdaptoFlux å®ä¾‹
        :param num_layers_to_add: è¦æ·»åŠ çš„å±‚æ•°
        """
        while adaptoflux_instance.graph_processor.layer > 0:
            adaptoflux_instance.remove_last_nx_layer()
        for _ in range(num_layers_to_add):
            candidate_plan = adaptoflux_instance.process_random_method()
            if candidate_plan["valid_groups"]:
                try:
                    adaptoflux_instance.append_nx_layer(
                        candidate_plan,
                        discard_unmatched='to_discard',
                        discard_node_method_name="null"
                    )
                except Exception as e:
                    logger.warning(f"Failed to add random layer during initialization: {e}", exc_info=True)
                    # å¦‚æœæ·»åŠ å¤±è´¥ï¼Œè·³è¿‡ï¼Œä¸å½±å“æ•´ä½“æµç¨‹

    def _phase_node_refinement(self, adaptoflux_instance, input_data: np.ndarray, target: np.ndarray) -> Dict[str, Any]:
        """
        é˜¶æ®µäºŒï¼šé€èŠ‚ç‚¹ç²¾ç‚¼ (Node-wise Refinement)
        
        ç›®æ ‡ï¼š
            å¯¹å›¾ä¸­æ¯ä¸ªâ€œå¯å¤„ç†èŠ‚ç‚¹â€ï¼ˆprocessing nodeï¼‰ï¼Œå°è¯•ç”¨å…¼å®¹çš„æ›¿ä»£æ–¹æ³•è¿›è¡Œæ›¿æ¢ï¼Œ
            ä»¥é™ä½æŸå¤±ï¼ˆæˆ–æå‡å‡†ç¡®ç‡ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ª**å±€éƒ¨æœç´¢ä¼˜åŒ–è¿‡ç¨‹**ã€‚
        
        ç­–ç•¥ï¼š
            æ”¯æŒå¤šç§ä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚éšæœºå•ç‚¹ã€å®Œæ•´éå†ï¼‰ï¼Œç”± `self.refinement_strategy` æ§åˆ¶ã€‚
            æ¯æ¬¡æ›¿æ¢éƒ½åŸºäºå°æ‰¹é‡æ•°æ®å¿«é€Ÿè¯„ä¼°ï¼Œé¿å…å…¨é‡è®¡ç®—å¼€é”€ã€‚
        
        å†»ç»“æœºåˆ¶ï¼š
            - `frozen_nodes`: æ˜¾å¼å†»ç»“çš„èŠ‚ç‚¹ååˆ—è¡¨ï¼ˆå¦‚ "root", "collapse"ï¼‰
            - `frozen_methods`: æ˜¾å¼å†»ç»“çš„æ–¹æ³•ååˆ—è¡¨ï¼ˆå¦‚ ["return_value"]ï¼‰ï¼Œè‡ªåŠ¨å†»ç»“ä½¿ç”¨è¿™äº›æ–¹æ³•çš„èŠ‚ç‚¹
        
        è¿”å›ï¼š
            åŒ…å«æœ€ç»ˆæ¨¡å‹ã€æ€§èƒ½æŒ‡æ ‡ã€æ­¥æ•°ç­‰ä¿¡æ¯çš„å­—å…¸ã€‚
        """
        # æ‰“å°æ—¥å¿—ï¼šå¼€å§‹ç²¾ç‚¼é˜¶æ®µ
        if self.verbose:
            logger.info(f"[Phase 2] Node-wise Refinement: Starting refinement with strategy '{self.refinement_strategy}'...")


        # è·å–å›¾å¤„ç†å™¨å’Œå½“å‰æ€§èƒ½æŒ‡æ ‡
        gp = adaptoflux_instance.graph_processor
        current_loss = self._evaluate_loss(input_data, target, adaptoflux_instance=adaptoflux_instance)
        current_acc = self._evaluate_accuracy(input_data, target, adaptoflux_instance=adaptoflux_instance)

        # åˆå§‹åŒ–çŠ¶æ€å˜é‡
        improvement_made = False  # æ ‡è®°æœ¬è½®æ˜¯å¦å‘ç”Ÿè¿‡æ”¹è¿›
        steps_taken = 0           # å®é™…æ‰§è¡Œçš„â€œä¼˜åŒ–æ­¥æ•°â€ï¼ˆæ³¨æ„ï¼šä¸åŒç­–ç•¥æ­¥æ•°å®šä¹‰ä¸åŒï¼‰

        # === 1. è·å–æ‰€æœ‰â€œå¯å¤„ç†èŠ‚ç‚¹â€å¹¶åº”ç”¨å†»ç»“è§„åˆ™ ===
        # `_is_processing_node(node)` æ˜¯ GraphProcessor çš„æ–¹æ³•ï¼Œç”¨äºåˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦æ˜¯â€œä¸­é—´è®¡ç®—èŠ‚ç‚¹â€
        # ï¼ˆé€šå¸¸æ’é™¤ "root"ã€"collapse" ç­‰ç‰¹æ®ŠèŠ‚ç‚¹ï¼‰
        processing_nodes = [node for node in gp.graph.nodes() if gp._is_processing_node(node)]

        # åˆå¹¶æ˜¾å¼å†»ç»“çš„èŠ‚ç‚¹å’ŒåŸºäºæ–¹æ³•åå†»ç»“çš„èŠ‚ç‚¹
        final_frozen_nodes = set(self.frozen_nodes)  # æ˜¾å¼å†»ç»“çš„èŠ‚ç‚¹åé›†åˆ

        # å¦‚æœç”¨æˆ·æŒ‡å®šäº†å†»ç»“çš„æ–¹æ³•åï¼ˆå¦‚ ["return_value"]ï¼‰ï¼Œåˆ™è‡ªåŠ¨å†»ç»“æ‰€æœ‰ä½¿ç”¨è¿™äº›æ–¹æ³•çš„èŠ‚ç‚¹
        if self.frozen_methods:
            method_frozen_nodes = {
                node for node in processing_nodes
                if gp.graph.nodes[node].get('method_name') in self.frozen_methods
            }
            final_frozen_nodes.update(method_frozen_nodes)  # åˆå¹¶åˆ°å†»ç»“é›†åˆ

        # ä»å¯å¤„ç†èŠ‚ç‚¹ä¸­ç§»é™¤æ‰€æœ‰å†»ç»“èŠ‚ç‚¹
        if final_frozen_nodes:
            processing_nodes = [node for node in processing_nodes if node not in final_frozen_nodes]

        # æ‰“å°æ—¥å¿—ï¼šæŠ¥å‘Šå¯ä¼˜åŒ–èŠ‚ç‚¹æ•°é‡
        if self.verbose:
            logger.info(f"  Found {len(processing_nodes)} processing nodes to refine "
                        f"(excluding {len(final_frozen_nodes)} frozen nodes).")

        # === 2. è·å–ä¼˜åŒ–ç­–ç•¥å‡½æ•° ===
        # `_strategy_map` å°†å­—ç¬¦ä¸²ç­–ç•¥åæ˜ å°„åˆ°å…·ä½“å®ç°å‡½æ•°
        strategy_func = self._strategy_map[self.refinement_strategy]

        # === 3. ä¸»ä¼˜åŒ–å¾ªç¯ ===
        for step in range(self.max_refinement_steps):

            if (self.max_total_refinement_attempts is not None and
                self._total_refinement_attempts >= self.max_total_refinement_attempts):
                if self.verbose:
                    logger.info(
                        f"[Phase 2] Stopped early: reached max_total_refinement_attempts="
                        f"{self.max_total_refinement_attempts} (at step {step})."
                    )
                break

            # å®‰å…¨é€€å‡ºï¼šé˜²æ­¢è¶…è¿‡æœ€å¤§æ­¥æ•°ï¼ˆè™½ç„¶ç­–ç•¥å‡½æ•°å¯èƒ½ä¸€æ¬¡æ‰§è¡Œå¤šæ­¥ï¼‰
            if steps_taken >= self.max_refinement_steps:
                break

            # è‹¥æ— å¯ä¼˜åŒ–èŠ‚ç‚¹ï¼Œæå‰é€€å‡º
            if not processing_nodes:
                break

            # è°ƒç”¨å…·ä½“ç­–ç•¥å‡½æ•°æ‰§è¡Œä¸€æ¬¡ä¼˜åŒ–å°è¯•
            # è¿”å›å€¼è¯´æ˜ï¼ˆè§ç­–ç•¥å‡½æ•°æ–‡æ¡£ï¼‰ï¼š
            #   imp: bool â†’ æ˜¯å¦å‘ç”Ÿæ”¹è¿›
            #   new_loss, new_acc: æ”¹è¿›åçš„æŒ‡æ ‡
            #   step_inc: int â†’ æœ¬æ¬¡å®é™…æ¶ˆè€—çš„â€œæ­¥æ•°â€ï¼ˆå¦‚ full_sweep ä¸€æ¬¡å¯èƒ½æ›¿æ¢å¤šä¸ªèŠ‚ç‚¹ï¼‰
            #   updated_nodes: List[str] â†’ æ›´æ–°åçš„å¯å¤„ç†èŠ‚ç‚¹åˆ—è¡¨ï¼ˆå›¾ç»“æ„å¯èƒ½å˜åŒ–ï¼‰
            imp, new_loss, new_acc, step_inc, updated_nodes = strategy_func(
                self, adaptoflux_instance, input_data, target, processing_nodes, current_loss, gp
            )

            if imp:
                # å¦‚æœå‘ç”Ÿæ”¹è¿›ï¼Œæ›´æ–°å…¨å±€çŠ¶æ€
                improvement_made = True
                current_loss = new_loss
                current_acc = new_acc
                steps_taken += step_inc
                processing_nodes = updated_nodes  # ä½¿ç”¨æœ€æ–°èŠ‚ç‚¹åˆ—è¡¨

                # æ³¨æ„ï¼šæ—¥å¿—å·²åœ¨ç­–ç•¥å‡½æ•°å†…éƒ¨æ‰“å°ï¼ˆé¿å…é‡å¤ï¼‰ï¼Œæ‰€ä»¥è¿™é‡Œä¸åšé¢å¤–è¾“å‡º
            else:
                # æ— æ”¹è¿›ï¼šç»§ç»­ä¸‹ä¸€è½®å°è¯•ï¼ˆä¸æå‰ç»ˆæ­¢ï¼Œå› ä¸ºåç»­å¯èƒ½æœ‰æ”¹è¿›ï¼‰
                # ä¹Ÿå¯åœ¨æ­¤å¤„åŠ å…¥â€œæ—©åœâ€é€»è¾‘ï¼ˆå¦‚è¿ç»­ N æ¬¡æ— æ”¹è¿›åˆ™é€€å‡ºï¼‰
                pass

        # === 4. æ‰“å°æœ€ç»ˆç»“æœæ—¥å¿— ===
        if self.verbose:
            if improvement_made:
                logger.info(f"[Phase 2] Refinement completed in {steps_taken} steps. Final Loss: {current_loss:.6f}, Acc: {current_acc:.4f}")
            else:
                logger.info(f"[Phase 2] Refinement completed. No improvements found within {self.max_refinement_steps} steps.")

        # === 5. è¿”å›ç»“æœ ===
        return {
            'final_model': adaptoflux_instance,      # ä¼˜åŒ–åçš„æ¨¡å‹ï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
            'final_loss': current_loss,              # æœ€ç»ˆæŸå¤±
            'final_accuracy': current_acc,           # æœ€ç»ˆå‡†ç¡®ç‡
            'steps_taken': steps_taken,              # å®é™…æ‰§è¡Œæ­¥æ•°
            'improvement_made': improvement_made,     # æ˜¯å¦æœ‰æ”¹è¿›
            'total_refinement_attempts': self._total_refinement_attempts,  # å‰å‘æ¨ç†æ¬¡æ•°
        }

    def _get_compatible_methods_for_node(
        self, 
        adaptoflux_instance, 
        node_name: str, 
    ) -> List[str]:
        """
        è·å–ä¸å›¾ä¸­æŒ‡å®šèŠ‚ç‚¹å…¼å®¹çš„å€™é€‰æ–¹æ³•åˆ—è¡¨ã€‚

        æ–°å¢å‚æ•°:
            allow_fallback_on_empty (bool): 
                å½“ç±»å‹å…¼å®¹æ–¹æ³•ä¸ºç©ºæ—¶ï¼Œæ˜¯å¦å…è®¸å›é€€åˆ°éç±»å‹å®‰å…¨çš„å…œåº•ç­–ç•¥ã€‚
                - Trueï¼ˆé»˜è®¤ï¼‰ï¼šå¯ç”¨å…œåº•ï¼Œä¿è¯è¿”å›éç©ºåˆ—è¡¨ï¼›
                - Falseï¼šè‹¥æ— ç±»å‹å…¼å®¹æ–¹æ³•ï¼Œç›´æ¥æŠ›å‡º RuntimeErrorã€‚

        å…¶ä½™å‚æ•°è¯´æ˜è§åŸæ³¨é‡Šã€‚
        """
        
        gp = adaptoflux_instance.graph_processor
        methods = adaptoflux_instance.methods
        all_method_names = list(methods.keys())

        if not all_method_names:
            return []

        # === 1. è·å–åŸå§‹æ–¹æ³• ===
        node_data = gp.graph.nodes[node_name]
        original_method_name = node_data.get("method_name")
        if original_method_name is None or original_method_name not in methods:
            error_msg = (
                f"Node '{node_name}' has no valid 'method_name'.\n"
                f"  - Current method_name: {original_method_name}\n"
                f"  - Available methods: {sorted(methods.keys())}\n"
                f"  - Node data: {node_data}"
            )
            logger.error("CRITICAL GRAPH ERROR:\n%s", error_msg)
            # æ‰“å°å®Œæ•´å †æ ˆï¼ˆä¾¿äºå®šä½æ˜¯å“ªä¸ªè°ƒç”¨é“¾å¯¼è‡´çš„ï¼‰
            logger.error("Full traceback:\n%s", traceback.format_exc())
            # æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢ç¨‹åºï¼ˆé™¤éå¤–å±‚æœ‰ç‰¹æ®Šå¤„ç†ï¼‰
            raise RuntimeError(error_msg)

        # === 2. æå–åŸå§‹ç±»å‹ ===
        orig_info = methods[original_method_name]
        orig_input_types = orig_info.get("input_types", []) or []
        orig_output_types = orig_info.get("output_types", []) or []
        def is_type_compatible(method_name: str) -> bool:
            info = methods[method_name]
            m_input = info.get("input_types", []) or []
            m_output = info.get("output_types", []) or []
            return m_input == orig_input_types and m_output == orig_output_types

        # === 3. æ„å»ºå€™é€‰æ±  ===
        if self.candidate_pool_mode == "all":
            candidate_pool = all_method_names
        elif self.candidate_pool_mode == "self":
            candidate_pool = [original_method_name]
        else:  # "group"
            node_group = methods[original_method_name].get("group", "default")
            candidate_pool = [
                name for name, info in methods.items()
                if info.get("group", "default") == node_group
            ]

        # === 4. ç­›é€‰ç±»å‹å…¼å®¹æ–¹æ³• ===
        compatible_methods = [name for name in candidate_pool if is_type_compatible(name)]
        # print(f"Node '{node_name}' compatible methods: {compatible_methods}")

        # === 5. å¤„ç†ç©ºç»“æœ ===
        if not compatible_methods:
            log_msg = (f"Node '{node_name}' has no compatible methods.")
            logger.debug(log_msg)

            if self.fallback_mode == "error":
                raise RuntimeError(f"Strict mode: no type-compatible methods for node '{node_name}'...")

            # === æ‰§è¡Œå…œåº•å›é€€ ===
            if self.fallback_mode == "all":
                result = all_method_names
            elif self.fallback_mode == "group_first":
                node_group = methods[original_method_name].get("group", "default")
                group_methods = [name for name, info in methods.items() if info.get("group") == node_group]
                result = group_methods[:1] if group_methods else all_method_names[:1]
            elif self.fallback_mode == "self":
                result = [original_method_name]  # ğŸ‘ˆ å…³é”®ï¼šåªè¿”å›è‡ªå·±
            else:
                result = all_method_names  # fallback

            logger.warning("Falling back to non-type-safe methods for node '%s'...", node_name)
            return result

        return compatible_methods

    def _phase_modular_compression(self, adaptoflux_instance, input_data: np.ndarray, target: np.ndarray) -> Dict[str, Any]:
        if not self.enable_compression:
            return self._return_original_result(adaptoflux_instance, input_data, target)

        if self.compression_mode == "symbolic":
            return self._phase_symbolic_compression(adaptoflux_instance, input_data, target)
        elif self.compression_mode == "numerical":
            if self.verbose:
                logger.warning(
                    "âš ï¸ Numerical modular compression is UNFINISHED and UNSAFE. "
                    "It uses hard-coded 'add' replacement and is likely broken. "
                    "Use symbolic compression with explicit rules instead."
                )
            return self._phase_numerical_compression_legacy(adaptoflux_instance, input_data, target)
        else:
            raise ValueError(f"Unknown compression_mode: {self.compression_mode}")

    def _return_original_result(self, adaptoflux_instance, input_data, target):
        """
        è¾…åŠ©æ–¹æ³•ï¼šè¿”å›æœªè¿›è¡Œä»»ä½•å‹ç¼©çš„åŸå§‹æ¨¡å‹è¯„ä¼°ç»“æœã€‚

        å½“æ¨¡å—åŒ–å‹ç¼©å› ä»¥ä¸‹åŸå› è·³è¿‡æ—¶è°ƒç”¨ï¼š
        - å‹ç¼©åŠŸèƒ½è¢«ç¦ç”¨ï¼ˆenable_compression=Falseï¼‰
        - æœªèƒ½é‡‡æ ·åˆ°æœ‰æ•ˆå­å›¾
        - I/O æå–å¤±è´¥
        - å€™é€‰æ›¿ä»£æ–¹æ³•ä¸å¯ç”¨
        - ç­‰æ•ˆæ€§éªŒè¯æœªé€šè¿‡
        - å›¾æ›¿æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸

        è¯¥æ–¹æ³•ç¡®ä¿å‹ç¼©é˜¶æ®µå§‹ç»ˆè¿”å›ç»“æ„ä¸€è‡´çš„ç»“æœå­—å…¸ï¼Œä¾¿äºä¸»è®­ç»ƒå¾ªç¯ç»Ÿä¸€å¤„ç†ã€‚

        :param adaptoflux_instance: å½“å‰çš„ AdaptoFlux å®ä¾‹ï¼ˆæœªä¿®æ”¹ï¼‰
        :param input_data: ç”¨äºè¯„ä¼°çš„è¾“å…¥æ•°æ®
        :param target: å¯¹åº”çš„æ ‡ç­¾
        :return: è¡¨ç¤ºâ€œæ— å‹ç¼©â€çš„æ ‡å‡†ç»“æœå­—å…¸
        """
        loss = self._evaluate_loss(input_data, target, adaptoflux_instance=adaptoflux_instance)
        acc = self._evaluate_accuracy(input_data, target, adaptoflux_instance=adaptoflux_instance)
        return {
            'final_model': adaptoflux_instance,
            'final_loss': loss,
            'final_accuracy': acc,
            'compression_applied': False,
            'compressed_subgraphs': 0
        }

    def _phase_method_pool_evolution(
        self,
        adaptoflux_instance,
        snapshots: List[Any],
        max_methods: int = 1,
        enable_graph_isomorphism_clustering: bool = True,
        evolved_methods_save_dir: Optional[str] = None,
        subgraph_selection_policy: str = "largest"
    ) -> Dict[str, Any]:
        """
        è–„å±‚åŒ…è£…å™¨ï¼šä¿æŒ API å…¼å®¹æ€§ï¼Œå§”æ‰˜ç»™ MethodPoolEvolver
        Thin wrapper: maintains API compatibility, delegates to MethodPoolEvolver
        """
        return self.method_pool_evolver.evolve(
            adaptoflux_instance=adaptoflux_instance,
            snapshots=snapshots,
            max_methods=max_methods,
            enable_graph_isomorphism_clustering=enable_graph_isomorphism_clustering,
            evolved_methods_save_dir=evolved_methods_save_dir,
            subgraph_selection_policy=subgraph_selection_policy
        )

    def train(
        self,
        input_data: np.ndarray,
        target: np.ndarray,
        max_evo_cycles: int = 5,
        enable_early_stop: bool = True,      # â† æ–°å¢å¼€å…³
        early_stop_eps: float = 1e-6,        # â† å»ºè®®æ”¹åé¿å…å’Œæ•°å€¼è®¡ç®—åº“çš„ eps å†²çª
        save_model: bool = True,
        model_save_path: Optional[str] = None,
        save_best_model: bool = True,
        best_model_subfolder: str = "best",
        final_model_subfolder: str = "final",
        subgraph_selection_policy: str = "largest",
        skip_initialization: bool = False,
        max_total_refinement_attempts: Optional[int] = None,  # <-- æ–°å¢å‚æ•°
        **kwargs
    ) -> dict:
        """
        å®ç°åŸºç±»çš„ train æ–¹æ³•ã€‚
        æ‰§è¡Œå®Œæ•´çš„â€œå›¾æ¼”â€ä¼˜åŒ–å¾ªç¯ã€‚

        :param input_data: ç”¨äºå¿«é€Ÿè¯„ä¼°çš„è¾“å…¥æ•°æ®ï¼ˆå°æ‰¹é‡ï¼‰
        :param target: å¯¹åº”çš„æ ‡ç­¾
        :param max_evo_cycles: æœ€å¤šæ‰§è¡Œçš„è®­ç»ƒè½®æ¬¡æ•°ã€‚
        :param save_model: æ˜¯å¦åœ¨è®­ç»ƒç»“æŸåä¿å­˜æ¨¡å‹
        :param model_save_path: æ¨¡å‹ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
        :param save_best_model: æ˜¯å¦ä¿å­˜è¿‡ç¨‹ä¸­é‡åˆ°çš„æœ€ä½³æ¨¡å‹
        :param best_model_subfolder: æœ€ä½³æ¨¡å‹ä¿å­˜çš„å­ç›®å½•
        :param final_model_subfolder: æœ€ç»ˆæ¨¡å‹ä¿å­˜çš„å­ç›®å½•
        :param skip_initialization: è‹¥ä¸º Trueï¼Œåˆ™è·³è¿‡å¤šæ ·åˆå§‹åŒ–é˜¶æ®µï¼Œç›´æ¥ä½¿ç”¨å½“å‰ adaptoflux å®ä¾‹çš„å›¾ç»“æ„ä½œä¸ºä¼˜åŒ–èµ·ç‚¹ã€‚
                            é€‚ç”¨äº CombinedTrainer æˆ–äººå·¥é¢„è®¾æ¨¡å‹åœºæ™¯ã€‚
        :param kwargs: å…¶ä»–å¯é€‰å‚æ•°
        :return: ä¸€ä¸ªåŒ…å«è®­ç»ƒè¿‡ç¨‹ä¿¡æ¯çš„å­—å…¸
        """

        self.max_total_refinement_attempts = max_total_refinement_attempts
        self._total_refinement_attempts = 0  # <-- æ–°å¢è®¡æ•°å™¨

        # åé¢å¯èƒ½ç¼–å†™å•ä»»åŠ¡ä½¿ç”¨å¤šä¸ªå®ä¾‹çš„çŸ¥è¯†æå–ï¼ˆæ¶ˆè€—æ€§èƒ½æ›´é«˜ï¼Œä½†æå–å‡ºæ¥çš„çŸ¥è¯†åº”è¯¥æ•ˆæœæ›´å¥½ï¼‰ï¼Œä»¥åŠå¤šä»»åŠ¡é€‚é…
        # åé¢æ·»åŠ å¯é€‰å‚æ•°ï¼Œæ§åˆ¶è¯¥è½®è®­ç»ƒå¾—åˆ°çš„æ–°çŸ¥è¯†æ˜¯å¦ç›´æ¥åŠ å…¥æ–¹æ³•æ± ï¼Œæˆ–ä¿å­˜ä¸ºå›¾ä½¿ç”¨ã€‚

        if self.verbose:
            init_msg = "Skipping diverse initialization" if skip_initialization else "Starting diverse initialization"
            logger.info(f"Starting GraphEvoTrainer. {init_msg}. Max evolution cycles: {max_evo_cycles}")

        results = {
            "evo_cycles_completed": 0,
            "phase_results": [],
            "total_refinement_steps": 0,
            "total_compressions": 0,
            "total_methods_evolved": 0,
            "best_accuracy": -1.0,
            "best_accuracy_cycle": -1,
            "best_model_snapshot": None,
            "best_model_cycle": -1
        }

        # === é˜¶æ®µä¸€ï¼šå¤šæ ·åˆå§‹åŒ–ï¼ˆå¯é€‰ï¼‰===
        if not skip_initialization:
            init_result = self._phase_diverse_initialization(input_data, target)
            current_af = init_result['best_model']
            current_loss = init_result['best_loss']
            current_acc = init_result['best_accuracy']

            # æ›´æ–°å…¨å±€çŠ¶æ€ï¼ˆå³ä½¿è·³è¿‡ï¼Œåç»­ä¹Ÿä¼šç”¨ current_af è¦†ç›–ï¼‰
            self.adaptoflux = current_af

            # è®°å½•åˆå§‹åŒ–ç»“æœ
            if current_acc > results['best_accuracy']:
                results['best_accuracy'] = current_acc
                results['best_accuracy_cycle'] = 0
                results['best_model_snapshot'] = copy.deepcopy(current_af)
                results['best_model_cycle'] = 0

            results['phase_results'].append({
                'cycle': 0,
                'phase': 'initialization',
                'result': init_result
            })
        else:
            # ç›´æ¥ä½¿ç”¨å½“å‰å®ä¾‹çš„æ¨¡å‹
            current_af = copy.deepcopy(self.adaptoflux)
            current_loss = self._evaluate_loss(input_data, target)
            current_acc = self._evaluate_accuracy(input_data, target)

            # åˆå§‹åŒ–å³ä¸ºå½“å‰çŠ¶æ€
            if current_acc > results['best_accuracy']:
                results['best_accuracy'] = current_acc
                results['best_accuracy_cycle'] = 0
                results['best_model_snapshot'] = copy.deepcopy(current_af)
                results['best_model_cycle'] = 0

            results['phase_results'].append({
                'cycle': 0,
                'phase': 'initialization_skipped',
                'result': {
                    'loss': current_loss,
                    'accuracy': current_acc,
                    'model_used': 'current_adaptoflux'
                }
            })

        # å¼€å§‹è¿›åŒ–å¾ªç¯
        for cycle in range(1, max_evo_cycles + 1):
            if self.verbose:
                logger.info(f"--- Starting Evolution Cycle {cycle}/{max_evo_cycles} ---")

            cycle_results = {'cycle': cycle}

            # é˜¶æ®µäºŒï¼šé€èŠ‚ç‚¹ç²¾ç‚¼
            refinement_result = self._phase_node_refinement(current_af, input_data, target)
            current_af = refinement_result['final_model']
            current_loss = refinement_result['final_loss']
            current_acc = refinement_result['final_accuracy']

            # ã€âœ… æ–°å¢æ—©åœé€»è¾‘ã€‘
            if enable_early_stop and current_acc >= 1.0 - early_stop_eps:
                if self.verbose:
                    logger.info(f"ğŸ¯ Early stopping triggered at cycle {cycle}: accuracy={current_acc:.6f} >= {1.0 - eps}")
                results['evo_cycles_completed'] = cycle
                break  # ç«‹å³ç»ˆæ­¢åç»­è¿›åŒ–è½®æ¬¡

            results['total_refinement_steps'] += refinement_result['steps_taken']

            cycle_results['refinement'] = refinement_result

            # é˜¶æ®µä¸‰ï¼šæ–¹æ³•æ± è¿›åŒ–ï¼ˆåŸºäºå¿«ç…§è§¦å‘ï¼‰
            if self.enable_evolution:
                # 1. æŒ‰é¢‘ç‡è®°å½•å›¾å¿«ç…§
                if cycle % self.evolution_sampling_frequency == 0:
                    snapshot = copy.deepcopy(current_af)
                    self.graph_snapshots.append(snapshot)
                    if self.verbose:
                        logger.debug(f"Saved graph snapshot #{len(self.graph_snapshots)} at cycle {cycle}")

                # 2. æ£€æŸ¥æ˜¯å¦è§¦å‘è¿›åŒ–
                if len(self.graph_snapshots) >= self.evolution_trigger_count:

                    evolved_dir = os.path.join(model_save_path, "evolved_methods")

                    # 3. æ‰§è¡Œè¿›åŒ–
                    evolution_result = self._phase_method_pool_evolution(
                        current_af,
                        snapshots=self.graph_snapshots,
                        max_methods=self.methods_per_evolution,
                        evolved_methods_save_dir=evolved_dir,
                        subgraph_selection_policy=subgraph_selection_policy
                    )
                    results['total_methods_evolved'] += evolution_result['methods_added']
                    cycle_results['evolution'] = evolution_result

                    # 4. æ¸…ç†å¿«ç…§
                    if self.evolution_cleanup_mode == "full":
                        self.graph_snapshots.clear()
                    elif self.evolution_cleanup_mode == "oldest":
                        if self.graph_snapshots:
                            self.graph_snapshots.pop(0)
                else:
                    cycle_results['evolution'] = {
                        'skipped': True,
                        'reason': 'insufficient_snapshots'
                    }
            else:
                cycle_results['evolution'] = {
                    'skipped': True,
                    'reason': 'disabled'
                }

            # æ›´æ–°å…¨å±€çŠ¶æ€
            self.adaptoflux = current_af

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°çš„æœ€ä½³æ¨¡å‹
            if current_acc > results['best_accuracy']:
                results['best_accuracy'] = current_acc
                results['best_accuracy_cycle'] = cycle
                results['best_model_snapshot'] = copy.deepcopy(current_af)
                results['best_model_cycle'] = cycle

            results['evo_cycles_completed'] += 1
            results['phase_results'].append(cycle_results)

            if self.verbose:
                logger.info(f"--- Cycle {cycle} completed. Current Acc: {current_acc:.4f}, Best Acc: {results['best_accuracy']:.4f} ---")

        if self.verbose:
            logger.info(f"GraphEvoTrainer finished after {results['evo_cycles_completed']} cycles.")


        # === é˜¶æ®µå››ï¼ˆåå¤„ç†ï¼‰ï¼šæ¨¡å—åŒ–å‹ç¼©ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰===
        final_compression_result = None
        if self.enable_compression:
            if self.verbose:
                logger.info("[Post-Training] Applying Modular Compression once on final model...")
                logger.warning(f"è¯¥å‡½æ•°ï¼ˆ_phase_modular_compressionï¼‰ä»åœ¨å¼€å‘ä¸­ï¼Œå¤§æ¦‚ç‡æ— æ³•è¾¾åˆ°é¢„æœŸæ•ˆæœï¼Œä¸å»ºè®®å¼€å¯ï¼Œå¦‚éœ€ä½¿ç”¨å»ºè®®åœ¨ATF.ModelTrainer.GraphEvoTrainerä¸­ä¿®æ”¹æˆ–ä½¿ç”¨è§„åˆ™åŒ–æ–¹æ³•æ›¿ä»£")
            final_compression_result = self._phase_modular_compression(self.adaptoflux, input_data, target)
            # æ›´æ–°æœ€ç»ˆæ¨¡å‹
            self.adaptoflux = final_compression_result['final_model']
            results['total_compressions'] = final_compression_result['compressed_subgraphs']
        else:
            if self.verbose:
                logger.info("[Post-Training] Modular Compression: SKIPPED (disabled by enable_compression=False)")
            results['total_compressions'] = 0
        
        if final_compression_result:
            results['final_compression_applied'] = final_compression_result['compression_applied']
        else:
            results['final_compression_applied'] = False

        # === æ˜¾å¼è®°å½•æœ€ç»ˆæ¨¡å‹å’Œæœ€ä½³æ¨¡å‹çš„ loss/acc åˆ° results æ ¹å±‚çº§ ===
        # 1. æœ€ç»ˆæ¨¡å‹æŒ‡æ ‡ï¼ˆä½¿ç”¨å½“å‰ self.adaptofluxï¼‰
        final_loss = self._evaluate_loss(input_data, target)
        final_acc = self._evaluate_accuracy(input_data, target)
        results['final_loss'] = final_loss
        results['final_accuracy'] = final_acc

        # 2. æœ€ä½³æ¨¡å‹æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if results['best_model_snapshot'] is not None:
            best_af_temp = self.adaptoflux  # ä¸´æ—¶ä¿å­˜
            self.adaptoflux = results['best_model_snapshot']
            try:
                best_loss = self._evaluate_loss(input_data, target)
                best_acc = self._evaluate_accuracy(input_data, target)
                results['best_loss'] = best_loss
                results['best_accuracy'] = best_acc  # å¯èƒ½å·²å­˜åœ¨ï¼Œä½†ç¡®ä¿ä¸€è‡´æ€§
            finally:
                self.adaptoflux = best_af_temp  # æ¢å¤
        else:
            results['best_loss'] = float('inf')
            results['best_accuracy'] = -1.0
            
        # ä¿å­˜æ¨¡å‹
        if save_model:
            try:
                base_save_path = model_save_path or "models"
                os.makedirs(base_save_path, exist_ok=True)

                # ä¿å­˜æœ€ç»ˆæ¨¡å‹
                final_path = os.path.join(base_save_path, final_model_subfolder)
                self.adaptoflux.save_model(folder=final_path)
                if self.verbose:
                    logger.info(f"Final model saved to '{final_path}'")
                results["final_model_saved"] = final_path

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if save_best_model and results['best_model_snapshot'] is not None:
                    best_path = os.path.join(base_save_path, best_model_subfolder)

                    # ä¸´æ—¶åˆ‡æ¢
                    original_af = self.adaptoflux
                    self.adaptoflux = results['best_model_snapshot']
                    try:
                        self.adaptoflux.save_model(folder=best_path)
                        if self.verbose:
                            logger.info(f"Best model (Cycle {results['best_model_cycle']}, Acc={results['best_accuracy']:.4f}) saved to '{best_path}'")
                    finally:
                        self.adaptoflux = original_af

                    results["best_model_saved"] = best_path

                # ä¿å­˜è®­ç»ƒæ—¥å¿—
                log_filename = kwargs.get("log_filename", "graph_evo_training_log.json")
                log_path = os.path.join(base_save_path, log_filename)
                with open(log_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=4, default=str)
                results["training_log_saved"] = log_path

            except Exception as e:
                logger.error(f"Failed to save model(s): {e}")
                import traceback
                logger.error(traceback.format_exc())
                
        # è®°å½•æ€»ç²¾ç‚¼å°è¯•æ¬¡æ•°ï¼ˆæ— è®ºæ˜¯å¦æˆåŠŸï¼‰
        results['total_refinement_attempts'] = self._total_refinement_attempts

        return results
        
    def build_candidate_pool(compatibility_mode, methods, original_method_name, all_method_names):
        if compatibility_mode == "all":
            return all_method_names
        else:
            node_group = methods[original_method_name].get("group", "default")
            group_methods = [
                name for name, info in methods.items()
                if info.get("group", "default") == node_group
            ]
            if compatibility_mode == "group_only":
                return group_methods if group_methods else all_method_names[:1]
            else:  # group_with_fallback
                return group_methods if len(group_methods) >= 2 else all_method_names

    def _phase_numerical_compression_legacy(self, adaptoflux_instance, input_data: np.ndarray, target: np.ndarray) -> Dict[str, Any]:
        """
        ã€DEPRECATEDã€‘æ—§çš„æ•°å€¼å‹ç¼©é€»è¾‘ï¼ˆMSE + å•èŠ‚ç‚¹æ›¿æ¢ï¼‰ã€‚
        ä»…ç”¨äºå…¼å®¹æ€§ä¿ç•™ï¼Œä¸æ¨èä½¿ç”¨ã€‚
        """
        gp = adaptoflux_instance.graph_processor
        # 1. é‡‡æ ·å­å›¾
        subgraph = self.subgraph_sampler.sample(gp.graph)
        if subgraph is None:
            return self._return_original_result(adaptoflux_instance, input_data, target)
        # 2. æå– I/O
        try:
            sub_inputs, sub_outputs = self.io_extractor.extract(adaptoflux_instance, subgraph, input_data)
        except Exception as e:
            logger.warning(f"IO extraction failed: {e}")
            return self._return_original_result(adaptoflux_instance, input_data, target)
        # 3. ç®€åŒ–ï¼šç›´æ¥é€‰ä¸€ä¸ªå€™é€‰æ–¹æ³•ï¼ˆå¦‚ "add"ï¼‰ä½œä¸ºæ›¿ä»£ï¼ˆè·³è¿‡è®­ç»ƒï¼‰
        candidate_method = "add"  # åç»­å¯æ›¿æ¢ä¸ºè®­ç»ƒé€»è¾‘
        if candidate_method not in adaptoflux_instance.methods:
            return self._return_original_result(adaptoflux_instance, input_data, target)
        # 4. éªŒè¯ç­‰æ•ˆæ€§
        temp_af = self._create_single_node_graph(adaptoflux_instance, candidate_method)
        rep_output = temp_af.infer_with_graph(input_data)
        orig_output = list(sub_outputs.values())[0]
        if not self.equivalence_checker.is_equivalent(orig_output, rep_output):
            return self._return_original_result(adaptoflux_instance, input_data, target)
        # 5. æ‰§è¡Œæ›¿æ¢
        try:
            new_node_id = self.replacer.replace_with_node(gp, subgraph, candidate_method)
            logger.info(f"Replaced subgraph with node '{new_node_id}' ({candidate_method})")
            new_loss = self._evaluate_loss(input_data, target, adaptoflux_instance=adaptoflux_instance)
            new_acc = self._evaluate_accuracy(input_data, target, adaptoflux_instance=adaptoflux_instance)
            return {
                'final_model': adaptoflux_instance,
                'final_loss': new_loss,
                'final_accuracy': new_acc,
                'compression_applied': True,
                'compressed_subgraphs': 1
            }
        except Exception as e:
            logger.error(f"Replacement failed: {e}")
            return self._return_original_result(adaptoflux_instance, input_data, target)

    def _phase_symbolic_compression(self, adaptoflux_instance, input_data: np.ndarray, target: np.ndarray) -> Dict[str, Any]:
        if not self.symbolic_compression_rules:
            if self.verbose:
                logger.info("Symbolic compression skipped: no rules provided.")
            return self._return_original_result(adaptoflux_instance, input_data, target)

        gp = adaptoflux_instance.graph_processor
        graph = gp.graph
        total_compressed = 0

        from networkx.algorithms.isomorphism import DiGraphMatcher

        for src_subgraph, tgt_spec in self.symbolic_compression_rules:
            root_ph = "root"
            collapse_ph = "collapse"

            # === 1. é¢„å¤„ç† patternï¼šåˆ†ç¦»å†…éƒ¨å›¾ + æ¥å£è§„èŒƒ ===
            if root_ph not in src_subgraph or collapse_ph not in src_subgraph:
                logger.warning("Pattern must contain 'root' and 'collapse'")
                continue

            # å†…éƒ¨å›¾ï¼ˆç”¨äºåŒ¹é…ï¼‰
            internal_nodes_pattern = [n for n in src_subgraph.nodes() if n not in (root_ph, collapse_ph)]
            match_graph = src_subgraph.subgraph(internal_nodes_pattern).copy()

            # è¾“å…¥ç«¯å£è§„èŒƒ: port_name -> (target_node, input_slot)
            input_ports = {}
            for _, tgt, data in src_subgraph.out_edges(root_ph, data=True):
                port_name = data.get('port_name')
                input_slot = data.get('input_slot')
                if port_name is None or input_slot is None:
                    raise ValueError("Pattern input edge must have 'port_name' and 'input_slot'")
                if port_name in input_ports:
                    raise ValueError(f"Duplicate input port: {port_name}")
                input_ports[port_name] = (tgt, input_slot)

            # è¾“å‡ºç«¯å£è§„èŒƒ: port_name -> (source_node, output_index)
            output_ports = {}
            for src, _, data in src_subgraph.in_edges(collapse_ph, data=True):
                port_name = data.get('port_name')
                output_index = data.get('output_index')
                if port_name is None or output_index is None:
                    raise ValueError("Pattern output edge must have 'port_name' and 'output_index'")
                if port_name in output_ports:
                    raise ValueError(f"Duplicate output port: {port_name}")
                output_ports[port_name] = (src, output_index)

            # === 2. åŒ¹é…å†…éƒ¨å›¾ ===
            def node_match(n1, n2):
                return n1.get('method_name') == n2.get('method_name')
            
            def edge_match(e1, e2):
                return (
                    e1.get('output_index') == e2.get('output_index') and
                    e1.get('data_type') == e2.get('data_type')
                )

            matcher = DiGraphMatcher(graph, match_graph, node_match=node_match, edge_match=edge_match)
            matches = list(matcher.subgraph_isomorphisms_iter())
            if self.verbose:
                print(f"Found {len(matches)} matches for compression rule.")
            if not matches:
                continue

            # è´ªå¿ƒéé‡å 
            used_nodes = set()
            valid_matches = []
            for mapping in sorted(matches, key=lambda m: -len(m)):
                main_nodes = set(mapping.keys())
                if main_nodes & used_nodes:
                    continue
                valid_matches.append(mapping)
                used_nodes.update(main_nodes)

            # === 3. å¤„ç†æ¯ä¸ªåŒ¹é… ===
            for mapping in valid_matches:
                subgraph_nodes = set(mapping.keys())

                # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ„å»º pattern_node -> host_node çš„åå‘æ˜ å°„
                pattern_to_host = {pattern_node: host_node for host_node, pattern_node in mapping.items()}

                # --- æ„å»º input_port_bindings ---
                input_bindings = {}
                for port_name, (pattern_tgt, expected_slot) in input_ports.items():
                    # âœ… ä½¿ç”¨åå‘æ˜ å°„è·å– host èŠ‚ç‚¹
                    host_tgt = pattern_to_host[pattern_tgt]
                    candidates = []
                    for src, _, key, data in graph.in_edges(host_tgt, keys=True, data=True):
                        if src in subgraph_nodes:
                            continue
                        if data.get('input_slot') == expected_slot:
                            candidates.append((src, key, data))
                    if len(candidates) != 1:
                        raise ValueError(f"Input port {port_name} (slot={expected_slot}): expected 1 edge, got {len(candidates)}")
                    input_bindings[port_name] = candidates[0]

                # --- æ„å»º output_port_bindings ---
                output_bindings = {}
                for port_name, (pattern_src, expected_idx) in output_ports.items():
                    # âœ… ä½¿ç”¨åå‘æ˜ å°„è·å– host èŠ‚ç‚¹
                    host_src = pattern_to_host[pattern_src]
                    candidates = []
                    for _, dst, key, data in graph.out_edges(host_src, keys=True, data=True):
                        if dst in subgraph_nodes:
                            continue
                        if data.get('output_index') == expected_idx:
                            candidates.append((dst, key, data))
                    if len(candidates) != 1:
                        raise ValueError(f"Output port {port_name} (output={expected_idx}): expected 1 edge, got {len(candidates)}")
                    output_bindings[port_name] = candidates[0]

                # === 4. è°ƒç”¨æ›¿æ¢ ===
                try:
                    if isinstance(tgt_spec, nx.DiGraph):
                        new_nodes = gp.replace_subgraph_with_graph(
                            subgraph_nodes=subgraph_nodes,
                            replacement_graph=tgt_spec,
                            input_port_bindings=input_bindings,
                            output_port_bindings=output_bindings
                        )
                        logger.info(f"âœ… Replaced subgraph with graph: {len(new_nodes)} nodes inserted")
                        total_compressed += 1
                    else:
                        logger.warning(f"Unsupported target spec type: {type(tgt_spec)}")
                except Exception as e:
                    logger.warning(f"Compression failed: {e}", exc_info=True)

        # è¯„ä¼°
        new_loss = self._evaluate_loss(input_data, target, adaptoflux_instance=adaptoflux_instance)
        new_acc = self._evaluate_accuracy(input_data, target, adaptoflux_instance=adaptoflux_instance)

        return {
            'final_model': adaptoflux_instance,
            'final_loss': new_loss,
            'final_accuracy': new_acc,
            'compression_applied': total_compressed > 0,
            'compressed_subgraphs': total_compressed
        }

    