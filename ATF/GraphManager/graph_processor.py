import networkx as nx
import numpy as np
from collections import Counter
import math
from ..CollapseManager.collapse_functions import CollapseFunctionManager, CollapseMethod

class GraphProcessor:
    def __init__(self, graph: nx.MultiDiGraph, methods: dict, collapse_method=CollapseMethod.SUM):
        """
        åˆå§‹åŒ–å›¾å¤„ç†å™¨ã€‚
        
        å‚æ•°:
            graph (nx.MultiDiGraph): åˆå§‹å›¾ç»“æ„
            methods (dict): å¯ç”¨æ–¹æ³•å­—å…¸ {method_name: {"function": ..., "input_count": int, "output_count": int}}
            collapse_method (callable): èšåˆå‡½æ•°ï¼Œé»˜è®¤ä¸º sum
        """
        self.graph = graph.copy() if graph else nx.MultiDiGraph()
        self.methods = methods
        self.layer = 0  # è®°å½•å½“å‰å±‚æ•°ï¼ˆå¯é€‰ï¼‰

        self.collapse_manager = CollapseFunctionManager(method=collapse_method)

    def set_graph(self, new_graph):
        """æ›´æ–°å›¾ç»“æ„"""
        if not hasattr(new_graph, 'nodes') or not hasattr(new_graph, 'edges'):
            raise ValueError("new_graph ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å›¾å¯¹è±¡")
        self.graph = new_graph
        print("å›¾ç»“æ„å·²æ›´æ–°ã€‚")

    def set_methods(self, new_methods):
        """æ›´æ–° methodsï¼ˆå‡½æ•°å­—å…¸æˆ–æ¨¡å—ï¼‰"""
        if not isinstance(new_methods, dict) and not callable(new_methods):
            raise TypeError("methods åº”è¯¥æ˜¯ä¸€ä¸ªå‡½æ•°å­—å…¸æˆ–å¯è°ƒç”¨å¯¹è±¡")
        self.methods = new_methods
        print("Methods å·²æ›´æ–°ã€‚")

    def append_nx_layer(self, result, discard_unmatched='to_discard', discard_node_method_name="null"):
        """
        å‘å›¾ä¸­æ·»åŠ ä¸€å±‚æ–°èŠ‚ç‚¹ã€‚
        """
        self.layer += 1
        new_index_edge = 0
        method_counts = {method_name: 0 for method_name in self.methods}
        method_counts["unmatched"] = 0
        v = "collapse"
        collapse_edges = list(self.graph.in_edges(v, data=True))

        # å¤„ç†æœ‰æ•ˆåˆ†ç»„
        for method_name, groups in result['valid_groups'].items():
            if method_name == "unmatched":
                continue
            for group in groups:
                new_target_node = f"{self.layer}_{method_counts[method_name]}_{method_name}"
                self.graph.add_node(new_target_node, method_name=method_name)

                for u, _, data in collapse_edges:
                    if data.get('data_coord') in group:
                        self.graph.remove_edge(u, v)
                        self.graph.add_edge(u, new_target_node, **data)

                for local_output_index in range(self.methods[method_name]["output_count"]):
                    self.graph.add_edge(new_target_node, v, output_index=local_output_index, data_coord=new_index_edge, data_type=self.methods[method_name]["output_types"][local_output_index])
                    new_index_edge += 1

                method_counts[method_name] += 1
            
            # # === æ–°å¢ï¼šæ£€æµ‹æ— å…¥è¾¹çš„æ–°èŠ‚ç‚¹ ===
            # for method_name, count in method_counts.items():
            #     if method_name == "unmatched":
            #         continue
            #     for i in range(count):
            #         new_node = f"{self.layer}_{i}_{method_name}"
            #         if self.graph.in_degree(new_node) == 0:
            #             print(f"[è­¦å‘Š] èŠ‚ç‚¹ '{new_node}' æ²¡æœ‰å…¥è¾¹ï¼å…¶å±æ€§ä¸ºï¼š")
            #             print(dict(self.graph.nodes[new_node]))
            #             print(result['valid_groups'])

        # æ”¶é›†æ‰€æœ‰è¾“å…¥è¾¹çš„ data_type
        input_data_types = []
        
        # å¤„ç† unmatched
        unmatched_groups = result.get('unmatched', [])
        if unmatched_groups and discard_unmatched == 'to_discard':
            for group in unmatched_groups:
                node_name = f"{self.layer}_{method_counts['unmatched']}_unmatched"
                self.graph.add_node(node_name, method_name=discard_node_method_name)

                # æ”¶é›†æ‰€æœ‰è¾“å…¥è¾¹çš„ data_typeï¼Œå¹¶é‡å®šå‘è¾¹
                input_data_types = []
                for u, _, data in collapse_edges:
                    if data.get('data_coord') in group:
                        input_data_types.append(data.get('data_type'))  # æå–åŸå§‹è¾¹çš„æ•°æ®ç±»å‹
                        self.graph.remove_edge(u, v)
                        self.graph.add_edge(u, node_name, **data)

                # æŒ‰é¡ºåºä¸ºæ¯æ¡è¾“å…¥è¾¹åˆ›å»ºä¸€æ¡è¾“å‡ºè¾¹ï¼Œç»§æ‰¿å…¶ data_type
                for local_output_index, used_data_type in enumerate(input_data_types):
                    self.graph.add_edge(
                        node_name, v,
                        output_index=local_output_index,
                        data_coord=new_index_edge,
                        data_type=used_data_type  # â† ä½¿ç”¨å¯¹åº”è¾“å…¥è¾¹çš„ç±»å‹
                    )
                    new_index_edge += 1

                method_counts["unmatched"] += 1

        elif unmatched_groups and discard_unmatched != 'ignore':
            raise ValueError(f"æœªçŸ¥çš„ discard_unmatched å€¼ï¼š{discard_unmatched}")

        return self.graph

    def remove_last_nx_layer(self):
        """
        åˆ é™¤å›¾ä¸­çš„æœ€åä¸€å±‚èŠ‚ç‚¹ã€‚
        """
        collapse_node = "collapse"
        incoming_edges = list(self.graph.in_edges(collapse_node, data=True))
        nodes_to_remove = set(u for u, v, d in incoming_edges)

        if not nodes_to_remove:
            print("æ²¡æœ‰å¯åˆ é™¤çš„å±‚ã€‚")
            return

        input_edges_map = {
            node: list(self.graph.in_edges(node, data=True)) for node in nodes_to_remove
        }

        for node in nodes_to_remove:
            for prev_node, _, edge_data in input_edges_map[node]:
                self.graph.add_edge(prev_node, collapse_node, **edge_data)

        for node in nodes_to_remove:
            if node != "root":
                self.graph.remove_node(node)
            else:
                print(f"è·³è¿‡åˆ é™¤èŠ‚ç‚¹ï¼š{node}ï¼ˆè¿™æ˜¯ä¿ç•™çš„æ ¹èŠ‚ç‚¹ï¼‰")

        self.layer -= 1
        return self.graph

    def infer_with_graph(self, values):
        """
        ä½¿ç”¨å›¾ç»“æ„å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ¨ç†ã€‚
        """
        node_outputs = {}
        nodes_in_order = list(nx.topological_sort(self.graph))
        nodes_in_order.remove("collapse")
        if "root" in nodes_in_order:
            nodes_in_order.remove("root")

        node_outputs["root"] = values.copy()

        for node in nodes_in_order:
            node_data = self.graph.nodes[node]
            method_name = node_data.get("method_name", None)

            if method_name == "null":
                predecessors = list(self.graph.predecessors(node))
                if len(predecessors) > 1:
                    raise ValueError(f"èŠ‚ç‚¹ {node} ä½¿ç”¨äº† 'null' æ–¹æ³•ï¼Œä½†æœ‰å¤šä¸ªå‰é©±èŠ‚ç‚¹ã€‚")
                if predecessors:
                    node_outputs[node] = node_outputs.get(predecessors[0], np.array([]))
                continue

            if method_name not in self.methods:
                raise ValueError(f"æœªçŸ¥æ–¹æ³•å {method_name}")

            method_info = self.methods[method_name]
            func = method_info["function"]
            input_count = method_info["input_count"]
            output_count = method_info["output_count"]

            in_edges = list(self.graph.in_edges(node, data=True))
            inputs = []

            for src, dst, edge_data in in_edges:
                if src not in node_outputs:
                    raise ValueError(f"å‰é©±èŠ‚ç‚¹ {src} æ²¡æœ‰è¾“å‡º")
                output_index = edge_data.get("output_index")
                if output_index is not None:
                    try:
                        selected_column = [[sample[output_index]] for sample in node_outputs[src]]
                    except IndexError:
                        raise ValueError(f"å‰é©±èŠ‚ç‚¹ {src} è¾“å‡ºé•¿åº¦ä¸è¶³ï¼Œæ— æ³•è·å– output_index={output_index}")
                    inputs.append(selected_column)
                else:
                    inputs.extend(node_outputs[src])

            if not inputs:
                raise ValueError("æ²¡æœ‰å¯åˆå¹¶çš„è¾“å…¥åˆ—")
            num_samples = len(inputs[0])
            for col in inputs:
                if len(col) != num_samples:
                    raise ValueError("æ‰€æœ‰è¾“å…¥åˆ—æ ·æœ¬æ•°å¿…é¡»ä¸€è‡´")

            final_inputs = []
            for i in range(num_samples):
                merged = []
                for col in inputs:
                    merged.extend(col[i])
                final_inputs.append(merged)

            flat_inputs = np.array(final_inputs)
            results = []

            for row in flat_inputs:
                result = func(*row)
                if isinstance(result, (int, float)):
                    result = [result]
                elif isinstance(result, np.ndarray):
                    result = result.tolist()
                results.append(result)

            new_output = np.zeros((num_samples, output_count))
            for i, res in enumerate(results):
                for j, val in enumerate(res):
                    new_output[i, j] = val

            node_outputs[node] = new_output

        temp_result = []
        for u, v, data in self.graph.in_edges("collapse", data=True):
            if v == "collapse":
                local_index = data.get('output_index')
                global_coord = data.get('data_coord')
                if local_index is None or global_coord is None:
                    raise ValueError("ç¼ºå°‘å¿…è¦å±æ€§")
                try:
                    column_data = node_outputs[u][:, local_index]
                    temp_result.append((global_coord, column_data))
                except IndexError:
                    raise ValueError(f"èŠ‚ç‚¹ {u} è¾“å‡ºç»´åº¦ä¸è¶³ï¼Œæ— æ³•æå– output_index={local_index}")

        temp_result.sort(key=lambda x: x[0])
        collapse_result = [col for _, col in temp_result]
        raw_output = np.column_stack(collapse_result)
        collapsed_output = np.apply_along_axis(self.collapse_manager.collapse, axis=1, arr=raw_output)
        return collapsed_output
    
    def infer_with_task_parallel(self, values, num_workers=4):
        from concurrent.futures import ThreadPoolExecutor
        import threading
        import queue

        # åˆå§‹åŒ–
        node_outputs = {"root": values}
        lock = threading.Lock()
        in_degree_remaining = {}
        ready_queue = queue.Queue()

        # æ„å»ºæ‹“æ‰‘ä¾èµ–å›¾ï¼Œå¹¶åˆå§‹åŒ–æ¯ä¸ªèŠ‚ç‚¹çš„å¾…å®Œæˆå‰é©±æ•°
        for node in self.graph.nodes:
            if node in ["root", "collapse"]:
                continue
            preds = list(self.graph.predecessors(node))
            in_degree_remaining[node] = len(preds)
            if len(preds) == 0:
                ready_queue.put(node)

        for succ in self.graph.successors("root"):
            # å¯¹æ¯ä¸ªä» root æŒ‡å‘çš„èŠ‚ç‚¹ï¼Œå‡å°‘ä¸€ä¸ªä¾èµ–ï¼ˆå› ä¸º root å·²å®Œæˆï¼‰
            if succ in in_degree_remaining:
                in_degree_remaining[succ] -= 1
                if in_degree_remaining[succ] == 0:
                    ready_queue.put(succ)

        # collapse ç‰¹æ®Šå¤„ç†ï¼šæ‰€æœ‰æŒ‡å‘å®ƒçš„èŠ‚ç‚¹å®Œæˆåæ‰å¯æ‰§è¡Œ
        collapse_in_edges = list(self.graph.in_edges("collapse"))
        collapse_deps = len(collapse_in_edges)
        if collapse_deps == 0:
            return np.array([])

        # å·¥ä½œå‡½æ•°
        import traceback  # ğŸ‘ˆ ç¡®ä¿æ–‡ä»¶é¡¶éƒ¨å·²å¯¼å…¥

        def process_node(node):
            try:
                with lock:
                    predecessors = list(self.graph.predecessors(node))
                    inputs = []
                    for src in predecessors:
                        try:
                            # âœ… ä¿®å¤ï¼šéå†æ‰€æœ‰ä» src åˆ° node çš„è¾¹
                            edges_from_src = self.graph[src][node]  # {key: edge_data}
                            for edge_key in edges_from_src:
                                edge_data = edges_from_src[edge_key]
                                output_idx = edge_data.get("output_index")
                                if src not in node_outputs:
                                    raise KeyError(f"å‰ç½®èŠ‚ç‚¹ '{src}' çš„è¾“å‡ºå°šæœªè®¡ç®—")
                                src_output = node_outputs[src]
                                if output_idx is not None:
                                    col = src_output[:, output_idx:output_idx+1]
                                else:
                                    col = src_output
                                inputs.append(col)
                        except Exception as e:
                            raise RuntimeError(f"æ„å»ºèŠ‚ç‚¹ '{node}' çš„è¾“å…¥æ—¶å‡ºé”™ï¼ˆæ¥è‡ªå‰ç½®èŠ‚ç‚¹ '{src}'ï¼‰: {e}") from e

                    if len(inputs) == 0:
                        raise ValueError(f"èŠ‚ç‚¹ '{node}' æ²¡æœ‰è¾“å…¥æ•°æ®")
                    flat_input = np.hstack(inputs) if len(inputs) > 1 else inputs[0]

                # æ‰§è¡Œå‡½æ•°
                method_name = self.graph.nodes[node].get("method_name")

                # âœ… æ–°å¢ï¼šå¤„ç† null æ–¹æ³•èŠ‚ç‚¹
                if method_name == "null":
                    with lock:
                        predecessors = list(self.graph.predecessors(node))
                        if len(predecessors) > 1:
                            raise ValueError(f"èŠ‚ç‚¹ {node} ä½¿ç”¨äº† 'null' æ–¹æ³•ï¼Œä½†æœ‰å¤šä¸ªå‰é©±èŠ‚ç‚¹ã€‚")
                        if predecessors:
                            src = predecessors[0]
                            if src not in node_outputs:
                                raise KeyError(f"å‰ç½®èŠ‚ç‚¹ '{src}' è¾“å‡ºæœªå°±ç»ª")
                            node_outputs[node] = node_outputs[src].copy()
                        else:
                            # æ— å‰é©±ï¼Œç”Ÿæˆé»˜è®¤è¾“å‡º
                            sample_count = flat_input.shape[0] if 'flat_input' in locals() else 100
                            output_count = 1
                            node_outputs[node] = np.zeros((sample_count, output_count))
                        
                        # è§¦å‘åç»§èŠ‚ç‚¹
                        for succ in self.graph.successors(node):
                            if succ == "collapse": continue
                            if succ in in_degree_remaining:
                                in_degree_remaining[succ] -= 1
                                if in_degree_remaining[succ] == 0:
                                    ready_queue.put(succ)
                    
                    output_shape = node_outputs[node].shape
                    # print(f"[âœ… SUCCESS] èŠ‚ç‚¹ {node} (method=null) æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {output_shape}")
                    return  # âš ï¸ ç›´æ¥è¿”å›ï¼Œè·³è¿‡å‡½æ•°æ‰§è¡Œé€»è¾‘

                # ========== åŸæœ‰å‡½æ•°æ‰§è¡Œé€»è¾‘ ==========
                if not method_name:
                    raise ValueError(f"èŠ‚ç‚¹ '{node}' æœªæŒ‡å®š method_name")

                if method_name not in self.methods:
                    raise KeyError(f"æ–¹æ³• '{method_name}' æœªåœ¨ self.methods ä¸­æ³¨å†Œ")

                func = self.methods[method_name]["function"]
                if not callable(func):
                    raise TypeError(f"æ–¹æ³• '{method_name}' ä¸æ˜¯å¯è°ƒç”¨å¯¹è±¡")

                outputs = []
                for i, row in enumerate(flat_input):
                    try:
                        res = func(*row)
                        if isinstance(res, (int, float)):
                            res = [res]
                        elif isinstance(res, np.ndarray):
                            res = res.tolist()
                        outputs.append(res)
                    except Exception as e:
                        raise RuntimeError(f"åœ¨èŠ‚ç‚¹ '{node}' æ‰§è¡Œç¬¬ {i} è¡Œè¾“å…¥æ—¶å‡ºé”™: {e} | è¾“å…¥æ•°æ®: {row}") from e

                output_array = np.array(outputs)

                # å†™å›è¾“å‡ºï¼ˆéœ€åŠ é”ï¼‰
                with lock:
                    node_outputs[node] = output_array
                    # è§¦å‘åç»§èŠ‚ç‚¹æ£€æŸ¥
                    for succ in self.graph.successors(node):
                        if succ == "collapse":
                            continue
                        if succ not in in_degree_remaining:
                            print(f"[WARNING] åç»§èŠ‚ç‚¹ '{succ}' ä¸åœ¨ in_degree_remaining ä¸­ï¼Œè·³è¿‡ä¾èµ–æ›´æ–°ã€‚")
                            continue
                        in_degree_remaining[succ] -= 1
                        if in_degree_remaining[succ] == 0:
                            ready_queue.put(succ)

                # print(f"[âœ… SUCCESS] èŠ‚ç‚¹ {node} æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {output_array.shape}")
                # print(f"[ğŸ§µ THREAD DONE] èŠ‚ç‚¹ {node} çº¿ç¨‹å·²å®Œå…¨é€€å‡º")
                return  # ç¡®ä¿æ˜¾å¼è¿”å›

            except Exception as e:
                error_msg = f"[ğŸ”¥ CRITICAL ERROR in process_node] èŠ‚ç‚¹ '{node}' æ‰§è¡Œå¤±è´¥: {e}"
                print(error_msg)
                traceback.print_exc()
                # å¯é€‰ï¼šå°†é”™è¯¯èŠ‚ç‚¹æ”¾å…¥ç‰¹æ®Šé˜Ÿåˆ— or è®¾ç½®å…¨å±€é”™è¯¯æ ‡å¿—
                # ä¾‹å¦‚ï¼š
                # with lock:
                #     global_error_flag.set()
                #     error_queue.put((node, str(e)))
                raise  # é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚æ•è·ï¼ˆå¦‚ ThreadPoolExecutor ä¼šæ ‡è®° future ä¸ºå¤±è´¥ï¼‰

        # å¯åŠ¨çº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            # ğŸ‘‡ è®¡ç®—æ€»èŠ‚ç‚¹æ•°ï¼ˆæ’é™¤ root å’Œ collapseï¼‰
            total_nodes_to_execute = len([
                n for n in self.graph.nodes 
                if n not in ["root", "collapse"]
            ])
            submitted_nodes = set()  # ç”¨äºå»é‡å’Œè®¡æ•°

            # print(f"[ğŸ¯ æ€»å…±éœ€è¦æ‰§è¡Œ {total_nodes_to_execute} ä¸ªèŠ‚ç‚¹]")

            while len(submitted_nodes) < total_nodes_to_execute:
                try:
                    node = ready_queue.get(timeout=1)
                    if node in submitted_nodes:
                        continue  # é˜²æ­¢é‡å¤æäº¤ï¼ˆè™½ç„¶ç†è®ºä¸Šä¸ä¼šï¼Œä½†å®‰å…¨ç¬¬ä¸€ï¼‰
                    submitted_nodes.add(node)
                    futures.append(executor.submit(process_node, node))
                    # print(f"[ğŸ“¤ å·²æäº¤èŠ‚ç‚¹ {len(submitted_nodes)}/{total_nodes_to_execute}]: {node}")
                except queue.Empty:
                    # é˜Ÿåˆ—æš‚æ—¶ç©ºï¼Œä½†è¿˜æ²¡æäº¤å®Œæ‰€æœ‰èŠ‚ç‚¹ â†’ ç­‰å¾…å­çº¿ç¨‹ç”Ÿæˆæ–°èŠ‚ç‚¹
                    # print(f"[â³ é˜Ÿåˆ—ç©ºï¼Œç­‰å¾…ä¸­... å·²æäº¤ {len(submitted_nodes)}/{total_nodes_to_execute}]")
                    # time.sleep(0.1)  # é¿å…å¿™ç­‰ï¼ŒèŠ‚çœ CPU å®é™…å·¥ç¨‹ä¸­å¯ä»¥ä½¿ç”¨ï¼Œè¿™é‡Œè¿½æ±‚å®éªŒç²¾åº¦æ²¡å†™ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š
                    continue

            # print(f"[âœ… æ‰€æœ‰ {total_nodes_to_execute} ä¸ªèŠ‚ç‚¹å·²æäº¤ï¼Œå…± {len(futures)} ä¸ªä»»åŠ¡ï¼Œå¼€å§‹ç­‰å¾…æ‰§è¡Œå®Œæˆ...]")

            # ç­‰å¾…å…¨éƒ¨å®Œæˆ
            for f in futures:
                f.result()

        # æœ€åå¤„ç† collapse èŠ‚ç‚¹
        # print('æ­£åœ¨èšåˆ collapse èŠ‚ç‚¹...')
        collapse_inputs = []
        for u, v, data in self.graph.in_edges("collapse", data=True):
            local_idx = data["output_index"]
            global_coord = data["data_coord"]
            col_data = node_outputs[u][:, local_idx]
            collapse_inputs.append((global_coord, col_data))

        collapse_inputs.sort(key=lambda x: x[0])
        raw_output = np.column_stack([col for _, col in collapse_inputs])
        result = np.apply_along_axis(self.collapse_manager.collapse, axis=1, arr=raw_output)
        # print('å®Œæˆ')
        return result

    def infer_with_graph_single(self, sample, use_pipeline=False, num_workers=4):
        """
        ä½¿ç”¨å›¾ç»“æ„å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œæ¨ç†è®¡ç®—ï¼Œå¯é€‰æ‹©æ˜¯å¦ä½¿ç”¨å¹¶è¡Œæµæ°´çº¿ã€‚

        å‚æ•°:
            sample (np.ndarray or list): å•ä¸ªæ ·æœ¬ï¼Œå½¢çŠ¶ä¸º [ç‰¹å¾ç»´åº¦]
            use_pipeline (bool): æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹æµæ°´çº¿æ¨ç†
            num_workers (int): æµæ°´çº¿ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ˆä»…å½“ use_pipeline=True æ—¶æœ‰æ•ˆï¼‰

        è¿”å›:
            float or np.ndarray: ç»è¿‡å›¾ç»“æ„å¤„ç†åçš„ç»“æœï¼ˆé€šè¿‡ collapse è¾“å‡ºï¼‰
        """
        # ç¡®ä¿è¾“å…¥æ˜¯ä¸€ç»´æ•°ç»„
        sample = np.array(sample)
        assert len(sample.shape) == 1, "è¾“å…¥å¿…é¡»æ˜¯ä¸€ç»´æ•°ç»„"

        # æ‰©å±•ä¸ºäºŒç»´ (1, ç‰¹å¾ç»´åº¦)ï¼Œé€‚é…æ‰¹é‡æ¥å£
        values = sample.reshape(1, -1)

        # é€‰æ‹©æ¨ç†æ–¹å¼
        if use_pipeline:
            result = self.infer_with_pipeline(values, num_workers=num_workers)
        else:
            result = self.infer_with_graph(values)

        # è¿”å›å•ä¸ªæ ·æœ¬çš„ç»“æœï¼ˆå·²ç»æ˜¯ (1,) æˆ–æ ‡é‡ï¼‰
        return result[0]
    
    # åœ¨ GraphProcessor ç±»ä¸­
    def replace_node_method(
        self,
        old_node_id: str,
        new_method_name: str
    ) -> str:
        """
        å®‰å…¨åœ°æ›¿æ¢å›¾ä¸­ä¸€ä¸ªèŠ‚ç‚¹çš„æ–¹æ³•ï¼Œå¹¶æ›´æ–°å…¶ ID å’Œæ‰€æœ‰ç›¸è¿çš„è¾¹ã€‚
        ä¸åšå›¾å…¨èŠ‚ç‚¹åˆ·æ–°ï¼ˆå…¨èŠ‚ç‚¹åˆ·æ–°è€—èƒ½é«˜å¹¶ä¸”æ¨ç†ä¸ä¾èµ–å…·ä½“idï¼Œå¯èƒ½åç»­åšä¸ªå•ç‹¬æ–¹æ³•ï¼‰
        
        :param old_node_id: è¦æ›¿æ¢çš„æ—§èŠ‚ç‚¹ IDï¼ˆå¦‚ "2_3_return_value"ï¼‰
        :param new_method_name: æ–°çš„æ–¹æ³•åï¼ˆå¦‚ "add_values"ï¼‰
        :return: æ–°èŠ‚ç‚¹çš„ IDï¼ˆå¦‚ "2_0_add_values"ï¼‰
        """
        if new_method_name not in self.methods:
            raise ValueError(f"Method '{new_method_name}' not registered in methods.")
        graph = self.graph

        # === 1. è·å–æ—§èŠ‚ç‚¹ä¿¡æ¯ ===
        if old_node_id not in graph:
            raise ValueError(f"Node '{old_node_id}' not found in graph.")
        
        old_data = graph.nodes[old_node_id]
        old_method = old_data.get("method_name")
        if old_method is None:
            raise ValueError(f"Node '{old_node_id}' has no 'method_name' attribute.")

        # === 2. è§£ææ—§ ID è·å– layer å’Œ index å‰ç¼€ ===
        # æ—§ ID æ ¼å¼: {layer}_{index}_{method_name} æˆ– {layer}_{index}_unmatched
        id_parts = old_node_id.split('_', 2)  # æœ€å¤š split æˆ 3 éƒ¨åˆ†
        if len(id_parts) < 3:
            raise ValueError(f"Invalid node ID format: '{old_node_id}'")
        
        layer_str, index_str, _ = id_parts
        try:
            layer = int(layer_str)
        except ValueError:
            raise ValueError(f"Invalid layer in node ID: '{old_node_id}'")

        # === 3. ç”Ÿæˆæ–° ID ===
        if new_method_name == "null":
            new_base_name = "unmatched"
        else:
            new_base_name = new_method_name

        # æŸ¥æ‰¾è¯¥å±‚ä¸­å·²å­˜åœ¨çš„åŒæ–¹æ³•èŠ‚ç‚¹æ•°é‡ï¼Œç¡®å®šæ–° index
        existing_same_method = [
            nid for nid in graph.nodes
            if nid.startswith(f"{layer}_") and nid.endswith(f"_{new_base_name}")
        ]
        new_index = len(existing_same_method)
        new_node_id = f"{layer}_{new_index}_{new_base_name}"

        # === 4. ä¿å­˜æ—§èŠ‚ç‚¹çš„å…¥è¾¹å’Œå‡ºè¾¹ ===
        in_edges = list(graph.in_edges(old_node_id, keys=True, data=True))
        out_edges = list(graph.out_edges(old_node_id, keys=True, data=True))

        # === 5. åˆ é™¤æ—§èŠ‚ç‚¹ ===
        graph.remove_node(old_node_id)

        # === 6. æ·»åŠ æ–°èŠ‚ç‚¹ ===
        graph.add_node(new_node_id, method_name=new_method_name)

        # === 7. é‡è¿å…¥è¾¹ï¼ˆsource -> new_node_idï¼‰===
        for src, _, key, data in in_edges:
            graph.add_edge(src, new_node_id, key=key, **data)

        # === 8. é‡è¿å‡ºè¾¹ï¼ˆnew_node_id -> targetï¼‰===
        for _, dst, key, data in out_edges:
            graph.add_edge(new_node_id, dst, key=key, **data)

        logger.debug(
            "Replaced node '%s' (%s) with '%s' (%s)",
            old_node_id, old_method, new_node_id, new_method_name
        )
        
        return new_node_id