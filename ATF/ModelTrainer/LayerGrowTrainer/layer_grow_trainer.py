# layer_grow_trainer.py
from ..model_trainer import ModelTrainer
import numpy as np
import logging
import random
import copy
from typing import Optional
import os
import json
from ...PathGenerator.path_generator import PathGenerator
from ...GraphManager.graph_processor import GraphProcessor

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class LayerGrowTrainer(ModelTrainer):
    """
    ä¸€ä¸ªç»§æ‰¿è‡ª ModelTrainer çš„å…·ä½“è®­ç»ƒå™¨ã€‚
    è¯¥è®­ç»ƒå™¨å®ç°äº† AdaptoFlux çš„æ ¸å¿ƒæ„å»ºæœºåˆ¶â€”â€”â€œå±‚å å¼ç”Ÿæˆ-è¯„ä¼°-å›é€€â€(Layered Generate-Evaluate-Backtrack)ã€‚
    å®ƒé€šè¿‡åœ¨ç°æœ‰å›¾ç»“æ„ä¸Šè¿­ä»£å°è¯•æ·»åŠ æ–°å±‚ï¼Œå¹¶åŸºäºæ€§èƒ½è¯„ä¼°å†³å®šæ˜¯å¦ä¿ç•™ï¼Œä»è€Œå®ç°å›¾çš„åŠ¨æ€æ‰©å±•ã€‚
    """

    def __init__(
        self,
        adaptoflux_instance,
        max_attempts: int = 5,
        decision_threshold: float = 0.0,
        verbose: bool = True
    ):
        """
        åˆå§‹åŒ– LayerGrowTrainerã€‚

        :param adaptoflux_instance: å·²åˆå§‹åŒ–çš„ AdaptoFlux å¯¹è±¡
        :param max_attempts: ä¸ºæ·»åŠ ä¸€å±‚è€Œè¿›è¡Œçš„æœ€å¤§å°è¯•æ¬¡æ•°
        :param decision_threshold: å†³ç­–é˜ˆå€¼ã€‚è‹¥ (æ—§æŸå¤± - æ–°æŸå¤±) > thresholdï¼Œåˆ™æ¥å—æ–°å±‚ã€‚
                                   threshold=0.0 è¡¨ç¤ºè´ªå¿ƒç­–ç•¥ï¼ˆå¿…é¡»ä¸¥æ ¼å˜å¥½ï¼‰ã€‚
        :param verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        super().__init__(adaptoflux_instance)
        self.max_attempts = max_attempts
        self.decision_threshold = decision_threshold
        self.verbose = verbose
        

    def _evaluate_loss(self, input_data: np.ndarray, target: np.ndarray, use_pipeline=False, num_workers=4) -> float:
        """
        æ ¸å¿ƒæœºåˆ¶çš„ "Evaluate" æ­¥éª¤ã€‚
        åœ¨å½“å‰å›¾ç»“æ„ä¸Šæ‰§è¡Œå‰å‘ä¼ æ’­å¹¶è®¡ç®—æŸå¤±ã€‚

        :param input_data: ç”¨äºè¯„ä¼°çš„è¾“å…¥æ•°æ®ï¼ˆå»ºè®®ä½¿ç”¨å°æ‰¹é‡ä»¥åŠ é€Ÿï¼‰
        :param target: å¯¹åº”çš„æ ‡ç­¾
        :param use_pipeline: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œæµæ°´çº¿æ¨ç†ï¼ˆå¤šçº¿ç¨‹ï¼‰
        :param num_workers: å¹¶è¡Œæ¨ç†ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ˆä»…åœ¨ use_pipeline=True æ—¶æœ‰æ•ˆï¼‰
        :return: è®¡ç®—å¾—åˆ°çš„æŸå¤±å€¼ï¼Œè‹¥å¤±è´¥è¿”å› float('inf')
        """
        try:
            # é€‰æ‹©æ¨ç†æ–¹å¼
            gp = self.adaptoflux.graph_processor
            if use_pipeline:
                output = gp.infer_with_graph_pipeline(values=input_data, num_workers=num_workers)
            else:
                output = gp.infer_with_graph(values=input_data)

            # ç¡®ä¿è¾“å‡ºå’Œç›®æ ‡å½¢çŠ¶å…¼å®¹
            if output.shape[0] != target.shape[0]:
                raise ValueError(f"Output batch size {output.shape[0]} != target batch size {target.shape[0]}")

            # ä½¿ç”¨ AdaptoFlux å®ä¾‹çš„æŸå¤±å‡½æ•°
            loss = self.loss_fn(output, target)
            return float(loss)

        except Exception as e:
            logger.error(f"Evaluation failed: {e}")
            return float('inf')
    
    def _evaluate_accuracy(self, input_data: np.ndarray, target: np.ndarray, use_pipeline=False, num_workers=4) -> float:
        """
        è®¡ç®—å½“å‰å›¾ç»“æ„çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚

        :param input_data: è¾“å…¥æ•°æ®
        :param target: çœŸå®æ ‡ç­¾ (shape: [N,] æˆ– [N, 1])
        :param use_pipeline: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œæµæ°´çº¿æ¨ç†
        :param num_workers: å¹¶è¡Œæ¨ç†ä½¿ç”¨çš„çº¿ç¨‹æ•°
        :return: å‡†ç¡®ç‡ (0~1)ï¼Œè‹¥å¤±è´¥è¿”å› 0.0
        """
        try:
            # é€‰æ‹©æ¨ç†æ–¹å¼
            gp = self.adaptoflux.graph_processor
            if use_pipeline:
                output = gp.infer_with_graph_pipeline(values=input_data, num_workers=num_workers)
            else:
                output = gp.infer_with_graph(values=input_data)

            # ç¡®ä¿è¾“å‡ºæ˜¯ NumPy æ•°ç»„
            output = np.array(output)

            # é¢„æµ‹ç±»åˆ«
            if len(output.shape) == 1 or output.shape[1] == 1:
                # äºŒåˆ†ç±»ï¼šé˜ˆå€¼ 0.5
                pred_classes = (output >= 0.5).astype(int).flatten()
            else:
                # å¤šåˆ†ç±»ï¼šå–æœ€å¤§æ¦‚ç‡ç±»åˆ«
                pred_classes = np.argmax(output, axis=1)

            # çœŸå®æ ‡ç­¾å¤„ç†
            true_labels = np.array(target).flatten()

            # è®¡ç®—å‡†ç¡®ç‡
            accuracy = float(np.mean(pred_classes == true_labels))
            return accuracy

        except Exception as e:
            logger.error(f"Accuracy evaluation failed: {e}")
            return 0.0  # å¤±è´¥æ—¶è¿”å› 0

    def _should_accept(self, old_loss: float, new_loss: float) -> bool:
        """
        æ ¸å¿ƒæœºåˆ¶çš„ "Decide" æ­¥éª¤ã€‚
        æ ¹æ®å†³ç­–ç­–ç•¥åˆ¤æ–­æ˜¯å¦æ¥å—æ–°å±‚ã€‚

        :param old_loss: æ·»åŠ æ–°å±‚ä¹‹å‰çš„æŸå¤±
        :param new_loss: æ·»åŠ æ–°å±‚ä¹‹åçš„æŸå¤±
        :return: True è¡¨ç¤ºæ¥å—ï¼ŒFalse è¡¨ç¤ºæ‹’ç»
        """
        improvement = old_loss - new_loss
        return improvement > self.decision_threshold

    def train(
        self,
        input_data: np.ndarray,
        target: np.ndarray,
        max_layers: int = 10,
        discard_unmatched='to_discard', 
        discard_node_method_name="null",
        save_model: bool = True,
        on_retry_exhausted: str = "stop",  # æ–°å¢ï¼šå¤±è´¥åç­–ç•¥
        rollback_layers: int = 1,          # æ–°å¢ï¼šå›é€€å±‚æ•°
        max_total_attempts: Optional[int] = None,  # ğŸ‘ˆ æ–°å¢ï¼šå…¨å±€æœ€å¤§å°è¯•æ¬¡æ•°
        model_save_path: Optional[str] = None,
        save_best_model: bool = True,           # ğŸ‘ˆ æ–°å¢ï¼šæ˜¯å¦ä¿å­˜æœ€ä½³æ¨¡å‹
        best_model_subfolder: str = "best",     # ğŸ‘ˆ æ–°å¢ï¼šæœ€ä½³æ¨¡å‹å­ç›®å½•
        final_model_subfolder: str = "final",   # ğŸ‘ˆ æ–°å¢ï¼šæœ€ç»ˆæ¨¡å‹å­ç›®å½•
        **kwargs
    ) -> dict:
        """
        å®ç°åŸºç±»çš„ train æ–¹æ³•ã€‚
        æ‰§è¡Œå®Œæ•´çš„â€œå±‚å å¼ç”Ÿæˆ-è¯„ä¼°-å›é€€â€å¾ªç¯ï¼Œå°è¯•ä¸ºå½“å‰å›¾æ·»åŠ å¤šä¸ªæ–°å±‚ã€‚
        å¦‚æœè€ƒè™‘åŠ é€Ÿå¯ä»¥æŠŠä¸Šä¸€å±‚å¤„ç†çš„ç»“æœç¼“å­˜ä¸‹æ¥ï¼Œé¿å…é‡å¤è®¡ç®—ã€‚ä¸è¿‡è¿™ä¸ªæ–¹æ³•åœ¨æ¨ç†é˜¶æ®µä½¿ç”¨é€‚é…å¾ˆå·®ï¼ŒåæœŸå†å†™ã€‚

        :param input_data: ç”¨äºå¿«é€Ÿè¯„ä¼°çš„è¾“å…¥æ•°æ®ï¼ˆå°æ‰¹é‡ï¼‰
        :param target: å¯¹åº”çš„æ ‡ç­¾
        :param max_layers: æœ€å¤šå°è¯•æ·»åŠ çš„æ–°å±‚æ•°é‡
        :param discard_unmatched: æ˜¯å¦ä¸¢å¼ƒä¸åŒ¹é…çš„èŠ‚ç‚¹
        :param discard_node_method_name: ä¸¢å¼ƒèŠ‚ç‚¹çš„æ–¹æ³•åç§°
        :param save_model: æ˜¯å¦åœ¨è®­ç»ƒç»“æŸåä¿å­˜æ¨¡å‹
        :param on_retry_exhausted: å½“æ‰€æœ‰å°è¯•å¤±è´¥æ—¶çš„ç­–ç•¥ï¼ˆå¦‚ "stop", "continue"ï¼‰
        :param rollback_layers: å¦‚æœæ·»åŠ å¤±è´¥ï¼Œå›é€€çš„å±‚æ•°
        :param max_total_attempts: å…¨å±€æœ€å¤§å¢é•¿å°è¯•æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯ã€‚é»˜è®¤ä¸º max_layers * 30
        :param model_save_path: æ¨¡å‹ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚ä»…åœ¨ save_model=True æ—¶ç”Ÿæ•ˆã€‚é»˜è®¤ä¸º Noneï¼ˆä½¿ç”¨ 'models'ï¼‰
        :param kwargs: å…¶ä»–å¯é€‰å‚æ•°
        :return: ä¸€ä¸ªåŒ…å«è®­ç»ƒè¿‡ç¨‹ä¿¡æ¯çš„å­—å…¸
        """

        best_acc = -1.0
        best_graph_snapshot = None
        best_layer_count = 0
        if self.verbose:
            logger.info(f"Starting LayerGrowTrainer. Max layers to grow: {max_layers}")

        # åˆå§‹åŒ– results æ—¶æ·»åŠ 
        results = {
            "layers_added": 0,
            "attempt_history": [],
            "total_growth_attempts": 0,
            "total_candidate_attempts": 0,
            "rollback_count": 0,
            "rollback_events": []
        }


        # è®¾ç½®é»˜è®¤å€¼ï¼šå¦‚æœä¸æŒ‡å®šï¼Œåˆ™ä¸º max_layers * 30
        if max_total_attempts is None:
            max_total_attempts = max_layers * 30

        iteration_count = 0
        layer_idx = 0
        while layer_idx < max_layers and iteration_count < max_total_attempts:
            iteration_count += 1
            results["total_growth_attempts"] += 1

            if self.verbose:
                logger.info(f"--- Starting to grow layer {layer_idx + 1} ---")

            # è®°å½•å½“å‰çŠ¶æ€ï¼ˆæŸå¤± + å‡†ç¡®ç‡ï¼‰
            base_loss = self._evaluate_loss(input_data, target)
            base_acc = self._evaluate_accuracy(input_data, target)
            if self.verbose:
                logger.info(f"Base loss before attempt: {base_loss:.6f}, Accuracy: {base_acc:.4f}")

            layer_success = False
            attempt_record = {"layer": layer_idx + 1, "attempts": []}

            # å°è¯•å¾ªç¯
            for attempt in range(1, self.max_attempts + 1):
                results["total_candidate_attempts"] += 1  # æ¯æ¬¡å°è¯•éƒ½ç®—ä¸€æ¬¡å€™é€‰ç”Ÿæˆ
                attempt_info = {"attempt": attempt, "accepted": False, "new_loss": None}
                if self.verbose:
                    logger.info(f"  Attempt {attempt}/{self.max_attempts}")

                # 1. GENERATE: ç”Ÿæˆå€™é€‰æ–¹æ¡ˆ
                candidate_plan = self.adaptoflux.process_random_method()
                # ç”Ÿæˆä¸ºç©ºåˆ™è·³è¿‡ï¼Œè¿™ä¸ªåœ°æ–¹ä»£ç é€»è¾‘æœ‰ä¸€ä¸¢ä¸¢é—®é¢˜ï¼Œåº”è¯¥è¦å…¨ä¸ºç©ºä½†æ˜¯é—®é¢˜ä¸å¤§
                if not candidate_plan["valid_groups"]:
                    if self.verbose:
                        logger.warning("  process_random_method is empty. Skipping.")
                    attempt_info["status"] = "empty_plan"
                    attempt_record["attempts"].append(attempt_info)
                    continue

                # 2. EVALUATE: ä¸´æ—¶åº”ç”¨å€™é€‰å±‚
                # è¿™é‡Œç›´æ¥è°ƒç”¨ AdaptoFlux å®ä¾‹çš„ append_nx_layer æ–¹æ³•
                try:
                    self.adaptoflux.append_nx_layer(
                        candidate_plan,
                        discard_unmatched=discard_unmatched,
                        discard_node_method_name=discard_node_method_name
                    )
                except Exception as e:
                    logger.error(f"  Failed to append layer: {e}")
                    import traceback
                    logger.error(f"Exception traceback:\n{traceback.format_exc()}")  # ğŸ‘ˆ å…³é”®ï¼šæ‰“å°å®Œæ•´å †æ ˆ
                    attempt_info["status"] = f"append_failed: {e}"
                    attempt_record["attempts"].append(attempt_info)
                    continue

                # 2.2 EVALUATE: è¯„ä¼°æ–°å›¾çš„æ€§èƒ½
                new_loss = self._evaluate_loss(input_data, target)
                attempt_info["new_loss"] = new_loss
                new_acc = self._evaluate_accuracy(input_data, target)
                attempt_info["new_acc"] = new_acc

                # 3. DECIDE: å†³å®šæ˜¯å¦æ¥å—
                if self._should_accept(base_loss, new_loss):
                    # 4. ACCEPT: å†³ç­–æˆåŠŸï¼Œæ–°å±‚å·²é€šè¿‡ append_nx_layer æ°¸ä¹…é›†æˆ
                    if self.verbose:
                        logger.info(f"  âœ… Layer accepted on attempt {attempt}. "
                                    f"Loss: {base_loss:.6f} â†’ {new_loss:.6f}, "
                                    f"Acc: {base_acc:.4f} â†’ {new_acc:.4f}")
                    attempt_info["accepted"] = True
                    attempt_info["status"] = "accepted"
                    attempt_record["attempts"].append(attempt_info)
                    layer_success = True
                    break
                else:
                    # 4. BACKTRACK: å†³ç­–å¤±è´¥ï¼Œæ’¤é”€ä¸Šä¸€æ­¥
                    try:
                        self.adaptoflux.remove_last_nx_layer()
                    except Exception as e:
                        logger.error(f"  Failed to remove last layer: {e}")
                        # å¦‚æœæ— æ³•å›é€€ï¼Œå›¾ç»“æ„å¯èƒ½å·²æŸåï¼Œåº”ä¸­æ–­
                        attempt_info["status"] = f"rollback_failed: {e}"
                        attempt_record["attempts"].append(attempt_info)
                        break

                    if self.verbose:
                        logger.info(f"  âŒ Layer rejected. Loss: {new_loss:.6f} (base: {base_loss:.6f}), "
                                    f"Acc: {new_acc:.4f} (base: {base_acc:.4f}). "
                                    f"Reverted to previous state.")

                    attempt_info["status"] = "rejected"
                    attempt_record["attempts"].append(attempt_info)

            # è®°å½•æœ¬æ¬¡å±‚çš„å°è¯•å†å²
            results["attempt_history"].append(attempt_record)

            # æ›´æ–°æœ€ç»ˆç»“æœ
            if layer_success:
                layer_idx += 1
                results["layers_added"] += 1
                base_loss = new_loss  # æ›´æ–° base_loss ç”¨äºä¸‹ä¸€å±‚çš„æ¯”è¾ƒ

                if new_acc > best_acc:
                    if self.verbose:
                        logger.info(f"ğŸ‰ New best accuracy: {best_acc:.4f} â†’ {new_acc:.4f}, layers={results['layers_added']}")
                    best_acc = new_acc
                    # ä¿å­˜å›¾ç»“æ„å’Œæ–¹æ³•æ± çš„å¿«ç…§
                    best_graph_snapshot = copy.deepcopy(self.adaptoflux.graph)
                    best_methods_snapshot = copy.deepcopy(self.adaptoflux.methods)
                    best_layer_count = results["layers_added"]
            else:
                if on_retry_exhausted == "stop":
                    if self.verbose:
                        logger.info(f"--- Failed to add layer {layer_idx + 1} after {self.max_attempts} attempts. "
                                    f"Stopping growth. ---")
                    break

                elif on_retry_exhausted == "rollback":
                    if self.verbose:
                        logger.info(f"--- Layer {layer_idx + 1} failed after {self.max_attempts} attempts. "
                                    f"Rolling back {rollback_layers} layer(s). ---")

                    results["rollback_count"] += 1
                    rolled_back_success = 0
                    rolled_back_fail = 0

                    current_layers = results["layers_added"]
                    actual_rollback = min(rollback_layers, current_layers)  # å®‰å…¨é™åˆ¶

                    for _ in range(actual_rollback):
                        try:
                            if layer_idx > 0:  # ç¡®ä¿æœ‰å±‚å¯ä»¥å›é€€
                                if self.verbose:
                                    logger.info(f"  Rolling back layer {layer_idx + 1}...")
                                self.adaptoflux.remove_last_nx_layer()
                                results["layers_added"] -= 1
                                layer_idx -= 1
                                rolled_back_success += 1
                        except Exception as e:
                            logger.error(f"Rollback failed: {e}")
                            rolled_back_fail += 1

                    # è®°å½•äº‹ä»¶
                    results["rollback_events"].append({
                        "at_layer": layer_idx + 1,
                        "rollback_layers": rollback_layers,
                        "success_count": rolled_back_success,
                        "failed_count": rolled_back_fail,
                        "reason": "retry_exhausted"
                    })

                    if self.verbose:
                        logger.info(f"Rolled back {rolled_back_success} layers (failed: {rolled_back_fail}).")

                    # ğŸ‘‡ å…³é”®ï¼šæ›´æ–°å½“å‰æ€§èƒ½åŸºå‡†
                    base_loss = self._evaluate_loss(input_data, target)
                    base_acc = self._evaluate_accuracy(input_data, target)
                    if self.verbose:
                        logger.info(f"  Reset base loss to: {base_loss:.6f}, acc: {base_acc:.4f}")

                else:
                    logger.warning(f"Invalid on_retry_exhausted='{on_retry_exhausted}'. Must be 'stop' or 'rollback'. Stopping.")
                    break

        # å¾ªç¯ç»“æŸåï¼Œåˆ¤æ–­ç»ˆæ­¢åŸå› 
        if iteration_count >= max_total_attempts:
            if self.verbose:
                logger.info(f"--- Training stopped: reached global maximum attempts ({max_total_attempts}) ---")
        elif layer_idx >= max_layers:
            if self.verbose:
                logger.info(f"--- Training stopped: reached maximum layers ({max_layers}) ---")
        else:
            if self.verbose:
                logger.info("--- Training stopped: unknown reason ---")
        if self.verbose:
            logger.info(f"LayerGrowTrainer finished. Successfully added {results['layers_added']} layers.")

        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦ä¿å­˜æ¨¡å‹
        if save_model:
            try:
                base_save_path = model_save_path or "models"
                os.makedirs(base_save_path, exist_ok=True)

                # === ä¿å­˜æœ€ç»ˆæ¨¡å‹ ===
                final_path = os.path.join(base_save_path, final_model_subfolder)
                self.adaptoflux.save_model(folder=final_path)
                if self.verbose:
                    logger.info(f"Final model saved to '{final_path}'")

                # === ä¿å­˜æœ€ä½³æ¨¡å‹ ===
                if save_best_model and best_graph_snapshot is not None:
                    best_path = os.path.join(base_save_path, best_model_subfolder)

                    # ä¸´æ—¶æ›¿æ¢å½“å‰å›¾ç»“æ„ä»¥ä¿å­˜æœ€ä½³çŠ¶æ€
                    original_graph = self.adaptoflux.graph
                    original_methods = self.adaptoflux.methods

                    self.adaptoflux.graph = best_graph_snapshot
                    self.adaptoflux.methods = best_methods_snapshot
                    try:
                        self.adaptoflux.save_model(folder=best_path)
                        if self.verbose:
                            logger.info(f"Best model saved to '{best_path}' (accuracy={best_acc:.4f}, layers={best_layer_count})")
                    finally:
                        # æ¢å¤åŸå§‹çŠ¶æ€
                        self.adaptoflux.graph = original_graph
                        self.adaptoflux.methods = original_methods

                # æ·»åŠ åˆ° results
                results["final_model_saved"] = final_path
                results["final_model_accuracy"] = self._evaluate_accuracy(input_data, target)
                results["final_model_layers"] = results["layers_added"]
                if save_best_model and best_graph_snapshot is not None:
                    results["best_model_saved"] = best_path
                    results["best_model_accuracy"] = best_acc
                    results["best_model_layers"] = best_layer_count
                
                # è‡ªåŠ¨ä¿å­˜è®­ç»ƒæ—¥å¿—ä¸º JSON
                log_filename = kwargs.get("log_filename", "training_log.json")
                log_path = os.path.join(base_save_path, log_filename)
                with open(log_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=4, default=str)
                results["training_log_saved"] = log_path

            except Exception as e:
                logger.error(f"Failed to save model(s): {e}")
                import traceback
                logger.error(traceback.format_exc())

        return results
