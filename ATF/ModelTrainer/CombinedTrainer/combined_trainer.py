# combined_trainer.py
import logging
import copy
import os
from typing import Optional, Dict, Any
from ..LayerGrowTrainer.layer_grow_trainer import LayerGrowTrainer
from ..GraphEvoTrainer.graph_evo_trainer import GraphEvoTrainer

# å¯¼å…¥é—ä¼ é€‰æ‹©å™¨ï¼ˆå¯æ’æ‹”ï¼‰
try:
    from .GeneticMethodPoolSelector.genetic_method_pool_selector import GeneticMethodPoolSelector
    GENETIC_AVAILABLE = True
except ImportError as e:
    logging.warning(f"GeneticMethodPoolSelector not available: {e}")
    GENETIC_AVAILABLE = False

logger = logging.getLogger(__name__)


class CombinedTrainer:
    """
    ç»„åˆè®­ç»ƒå™¨ï¼šå®ç° AdaptoFlux çš„å®Œæ•´è‡ªè¿›åŒ–é—­ç¯ã€‚
    æ”¯æŒå¯æ’æ‹”çš„é—ä¼ ç­›é€‰æ¨¡å—ï¼Œç”¨äºæ§åˆ¶æ–¹æ³•æ± è§„æ¨¡ä¸è´¨é‡ã€‚

    é—ä¼ ç­›é€‰æ¨¡å¼ï¼ˆgenetic_modeï¼‰ï¼š
    - "disabled": ä¸ä½¿ç”¨é—ä¼ ï¼ˆé»˜è®¤ï¼‰
    - "once": ä»…åœ¨è®­ç»ƒå¼€å§‹å‰æ‰§è¡Œä¸€æ¬¡ï¼ˆå¯¹åº”è®ºæ–‡ Â§3.3.5 é˜¶æ®µ1ï¼‰
    - "periodic": æ¯ genetic_interval è½®æ‰§è¡Œä¸€æ¬¡ï¼Œç”¨äºå‘¨æœŸæ€§å‹ç¼©/é‡é€‰æ–¹æ³•æ± 
    """

    def __init__(
        self,
        adaptoflux_instance,
        layer_grow_config: dict,
        graph_evo_config: dict,
        num_evolution_cycles: int = 1,
        save_dir: Optional[str] = None,
        verbose: bool = True,
        # === é—ä¼ ç­›é€‰å¯æ’æ‹”é…ç½® ===
        genetic_mode: str = "disabled",           # "disabled", "once", "periodic"
        genetic_interval: int = 1,                # ä»…åœ¨ periodic æ¨¡å¼ä¸‹ç”Ÿæ•ˆ
        target_subpool_size: Optional[int] = None,  # æ§åˆ¶ç­›é€‰åæ–¹æ³•æ± å¤§å°
        genetic_config: Optional[dict] = None,
        refine_only_new_layers: bool = False,
        # === æ–°å¢ï¼šLayerGrowTrainer.train() å‚æ•° ===
        lg_train_kwargs: Optional[Dict[str, Any]] = None,
        # === æ–°å¢ï¼šGraphEvoTrainer.train() å‚æ•° ===
        ge_train_kwargs: Optional[Dict[str, Any]] = None,
        enable_early_stop: bool = True,
        early_stop_eps: float = 1e-6,
    ):
        if genetic_mode not in {"disabled", "once", "periodic"}:
            raise ValueError("genetic_mode must be one of: 'disabled', 'once', 'periodic'")

        if genetic_mode != "disabled" and not GENETIC_AVAILABLE:
            raise ImportError("GeneticMethodPoolSelector is required but not available.")

        self.base_adaptoflux = adaptoflux_instance
        self.layer_grow_config = layer_grow_config
        self.graph_evo_config = graph_evo_config
        self.num_evolution_cycles = num_evolution_cycles
        self.save_dir = save_dir or "combined_training"
        self.verbose = verbose

        # é—ä¼ é…ç½®
        self.genetic_mode = genetic_mode
        self.genetic_interval = genetic_interval
        self.target_subpool_size = target_subpool_size
        self.genetic_config = genetic_config or {}
        self.refine_only_new_layers = refine_only_new_layers

        # === å­˜å‚¨æ–°å¢å‚æ•° ===
        self.lg_train_kwargs = lg_train_kwargs or {}
        self.ge_train_kwargs = ge_train_kwargs or {}

        self._final_adaptoflux_instance = None
        self._clean_initial_adaptoflux = copy.deepcopy(adaptoflux_instance)

        # æ—©åœé…ç½®
        self.enable_early_stop = enable_early_stop
        self.early_stop_eps = early_stop_eps

    def _perform_genetic_selection(self, adaptoflux_instance, input_data, target) -> tuple:
        """
        æ‰§è¡Œä¸€æ¬¡é—ä¼ ç­›é€‰ï¼Œè¿”å› (ç­›é€‰åçš„ adaptoflux å®ä¾‹, é—ä¼ ç»“æœå­—å…¸)
        """
        if self.verbose:
            logger.info("=== å¼€å§‹é—ä¼ ç­›é€‰æ–¹æ³•æ±  ===")

        # è®¾ç½®é»˜è®¤å‚æ•°
        default_params = {
            "population_size": 12,
            "generations": 6,
            "subpool_size": self.target_subpool_size or 8,
            "layer_grow_layers": 2,
            "layer_grow_attempts": 2,
            "data_fraction": 0.2,
            "elite_ratio": 0.25,
            "mutation_rate": 0.1,
            "verbose": self.verbose,
        }
        genetic_params = {**default_params, **self.genetic_config}

        selector = GeneticMethodPoolSelector(
            base_adaptoflux=adaptoflux_instance,
            input_data=input_data,
            target=target,
            **genetic_params
        )

        result = selector.select()
        best_subpool = result["best_subpool"]

        # æ„å»ºæ–°å®ä¾‹
        selected_af = copy.deepcopy(self._clean_initial_adaptoflux)

        new_methods = {k: v for k, v in selected_af.methods.items() if k in best_subpool}
        selected_af.set_methods(new_methods)

        if self.verbose:
            logger.info(f"é—ä¼ ç­›é€‰å®Œæˆã€‚é€‰å‡º {len(best_subpool)} ä¸ªæ–¹æ³•")
            logger.info(f"é€‚åº”åº¦: {result['best_fitness']:.4f}")

        genetic_log = {
            "used": True,
            "mode": self.genetic_mode,
            "best_subpool": best_subpool,
            "fitness": result["best_fitness"],
            "subpool_size": len(best_subpool),
        }

        return selected_af, genetic_log

    def train(
        self,
        input_data,
        target,
        **kwargs
    ) -> Dict[str, Any]:
        os.makedirs(self.save_dir, exist_ok=True)

        results = {
            "genetic_logs": [],  # è®°å½•æ¯æ¬¡é—ä¼ æ“ä½œ
            "cycles": [],
            "final_model_path": None,
            "best_overall_accuracy": -1.0,
            "best_cycle": -1
        }

        current_af = copy.deepcopy(self.base_adaptoflux)

        # === åˆå§‹é—ä¼ ç­›é€‰ï¼ˆonce æˆ– periodic çš„ç¬¬0è½®ï¼‰===
        if self.genetic_mode == "once":
            current_af, log = self._perform_genetic_selection(current_af, input_data, target)
            results["genetic_logs"].append({"cycle": 0, **log})
        elif self.genetic_mode == "periodic":
            # åœ¨ Cycle 0 å‰æ‰§è¡Œä¸€æ¬¡
            current_af, log = self._perform_genetic_selection(current_af, input_data, target)
            results["genetic_logs"].append({"cycle": 0, **log})

        # === è‡ªè¿›åŒ–å¾ªç¯ ===
        for cycle in range(self.num_evolution_cycles):
            if self.verbose:
                logger.info(f"=== Combined Training Cycle {cycle + 1}/{self.num_evolution_cycles} ===")

            cycle_result = {}

            old_nodes = set(current_af.graph.nodes)  # è®°å½• LayerGrow å‰çš„èŠ‚ç‚¹ï¼ˆå³â€œæ—§èŠ‚ç‚¹â€ï¼‰

            init_params = {
                k: v for k, v in self.layer_grow_config.items()
                if k in {'max_attempts', 'decision_threshold', 'verbose'}
            }

            # LayerGrow
            lg_trainer = LayerGrowTrainer(
                adaptoflux_instance=current_af,
                **init_params
            )

            # æŠŠ max_layers ä¼ ç»™ train()
            lg_train_kwargs_to_pass = self.lg_train_kwargs.copy()
            lg_train_kwargs_to_pass.update({
                "input_data": input_data,
                "target": target,
                "model_save_path": os.path.join(self.save_dir, f"cycle_{cycle+1}", "layer_grow"),
                "save_best_model": True,
                "max_layers": self.layer_grow_config.get("max_layers", 10),
                "enable_early_stop": self.enable_early_stop,      # â† æ·»åŠ 
                "early_stop_eps": self.early_stop_eps,            # â† æ·»åŠ 
                **kwargs
            })

            lg_result = lg_trainer.train(**lg_train_kwargs_to_pass)

            current_af = lg_trainer.best_adaptoflux # è·å– LayerGrow åçš„å®ä¾‹(ä½¿ç”¨æœ€ä½³æ¨¡å‹)
            cycle_result["layer_grow"] = lg_result

            # === 2. GraphEvoï¼ˆå¯é€‰ï¼šä»…ç²¾ç‚¼æ–°èŠ‚ç‚¹ï¼‰===
            ge_config = self.graph_evo_config.copy()

            if self.refine_only_new_layers:
                # è®¡ç®—æ–°èŠ‚ç‚¹ï¼šLayerGrow åæœ‰ã€ä½†ä¹‹å‰æ²¡æœ‰çš„èŠ‚ç‚¹
                new_nodes = set(current_af.graph.nodes) - old_nodes
                # è¦å†»ç»“çš„èŠ‚ç‚¹ = æ‰€æœ‰æ—§èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ root/collapseï¼‰
                frozen_nodes = list(old_nodes)

                # åˆå¹¶ç”¨æˆ·å¯èƒ½å·²è®¾ç½®çš„ frozen_nodes
                user_frozen = ge_config.get("frozen_nodes", [])
                ge_config["frozen_nodes"] = list(set(frozen_nodes) | set(user_frozen))

                if self.verbose:
                    logger.info(f"  [Refine-Only-New] Freezing {len(frozen_nodes)} old nodes, refining {len(new_nodes)} new nodes.")

            # 5. è°ƒç”¨ GraphEvo æ—¶ä¼ å…¥ frozen_nodes
            ge_trainer = GraphEvoTrainer(
                adaptoflux_instance=current_af,
                **ge_config
            )

            ge_train_kwargs_to_pass = self.ge_train_kwargs.copy()
            ge_train_kwargs_to_pass.update({
                "input_data": input_data,
                "target": target,
                "model_save_path": os.path.join(self.save_dir, f"cycle_{cycle+1}", "graph_evo"),
                "save_best_model": True,
                "skip_initialization": True,
                "enable_early_stop": self.enable_early_stop,      # â† æ·»åŠ 
                "early_stop_eps": self.early_stop_eps,            # â† æ·»åŠ 
                **kwargs
            })

            ge_result = ge_trainer.train(**ge_train_kwargs_to_pass)

            current_af = ge_trainer.adaptoflux  # è·å– GraphEvo åçš„å®ä¾‹
            cycle_result["graph_evo"] = ge_result

            # å…¨å±€æœ€ä¼˜æ›´æ–°
            final_acc = ge_result.get("best_accuracy", -1.0)
            if final_acc > results["best_overall_accuracy"]:
                results["best_overall_accuracy"] = final_acc
                results["best_cycle"] = cycle + 1

                # âœ… ä¿å­˜åˆ°å¸¦ cycle ç¼–å·çš„å”¯ä¸€å­ç›®å½•
                best_path = os.path.join(self.save_dir, f"best_overall_cycle_{cycle + 1}")
                
                current_af.save_model(folder=best_path)
                results["best_model_path"] = best_path  # è®°å½•æœ€æ–°æœ€ä¼˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰

                # âœ… å¯é€‰ï¼šè®°å½•æ‰€æœ‰å†å²æœ€ä¼˜è·¯å¾„
                if "best_model_paths" not in results:
                    results["best_model_paths"] = []
                results["best_model_paths"].append({
                    "cycle": cycle + 1,
                    "accuracy": final_acc,
                    "path": best_path
                })

            results["cycles"].append(cycle_result)
            
            # åœ¨ cycle å¾ªç¯æœ«å°¾ï¼ˆä¿å­˜æœ€ä¼˜æ¨¡å‹ä¹‹åï¼‰
            if self.enable_early_stop and final_acc >= 1.0 - self.early_stop_eps:
                if self.verbose:
                    logger.info(f"ğŸ¯ å…¨å±€æ—©åœè§¦å‘ï¼šCycle {cycle+1} åå‡†ç¡®ç‡ = {final_acc:.6f} â‰¥ {1.0 - self.early_stop_eps}ï¼Œç»ˆæ­¢åç»­å¾ªç¯ã€‚")
                break  # è·³å‡º for cycle in range(...)

            # === å‘¨æœŸæ€§é—ä¼ ç­›é€‰ï¼ˆä»… periodic æ¨¡å¼ï¼‰===
            if (
                self.genetic_mode == "periodic"
                and (cycle + 1) % self.genetic_interval == 0
                and (cycle + 1) < self.num_evolution_cycles  # ä¸åœ¨æœ€åä¸€è½®åæ‰§è¡Œ
            ):
                current_af, log = self._perform_genetic_selection(current_af, input_data, target)
                results["genetic_logs"].append({"cycle": cycle + 1, **log})

        # === æ±‡æ€»æ€»å°è¯•æ¬¡æ•° ===
        total_attempts = 0
        for cycle_log in results["cycles"]:
            lg_att = cycle_log["layer_grow"].get("total_candidate_attempts", 0)
            ge_att = cycle_log["graph_evo"].get("total_refinement_attempts", 0)
            total_attempts += lg_att + ge_att

        results["total_candidate_and_refinement_attempts"] = total_attempts

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = os.path.join(self.save_dir, "final")
        current_af.save_model(folder=final_path)
        results["final_model_path"] = final_path
        self._final_adaptoflux_instance = current_af

        # ä¿å­˜æ—¥å¿—
        import json
        log_path = os.path.join(self.save_dir, "combined_training_log.json")
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=4, default=str)
        results["training_log_saved"] = log_path

        return results

    @property
    def adaptoflux(self):
        """
        è·å–è®­ç»ƒå®Œæˆåçš„ AdaptoFlux å®ä¾‹ã€‚

        Returns:
            AdaptoFlux: è®­ç»ƒå®Œæˆåçš„ AdaptoFlux å®ä¾‹ï¼Œå¦‚æœå°šæœªè®­ç»ƒåˆ™ä¸º Noneã€‚
        """
        return self._final_adaptoflux_instance

    def _validate_graph_method_consistency(self, adaptoflux_instance):
        """
        æ ¡éªŒå›¾ä¸­æ¯ä¸ªèŠ‚ç‚¹çš„ method_name æ˜¯å¦å­˜åœ¨äºå½“å‰æ–¹æ³•æ± ä¸­ã€‚
        å¦‚æœå‘ç°éæ³•å¼•ç”¨ï¼Œç«‹å³æŠ›å‡ºå¼‚å¸¸ã€‚
        """
        graph = adaptoflux_instance.graph_processor.graph
        methods = adaptoflux_instance.methods
        
        for node_id, node_data in graph.nodes(data=True):
            # è·³è¿‡ç‰¹æ®ŠèŠ‚ç‚¹ï¼ˆå¦‚rootã€collapseï¼‰
            if node_id in ("root", "collapse"):
                continue
                
            method_name = node_data.get("method_name")
            if method_name is None:
                raise ValueError(f"Node '{node_id}' has no 'method_name' attribute. Node data: {node_data}")
                
            if method_name not in methods:
                raise ValueError(
                    f"Node '{node_id}' references method '{method_name}', "
                    f"which is not in the current method pool.\n"
                    f"Available methods: {sorted(methods.keys())}\n"
                    f"Node data: {node_data}"
                )