# test_graph_evo_trainer_phase1.py

import numpy as np
import logging
from typing import Any, Dict, List
import networkx as nx
from itertools import cycle

from ATF.ModelTrainer.GraphEvoTrainer.graph_evo_trainer import GraphEvoTrainer

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============== æ¨¡æ‹Ÿ AdaptoFlux ç±» ===============
class MockAdaptoFlux:
    def __init__(self):
        self.graph_processor = MockGraphProcessor()
        self.graph_processor._parent = self  # ğŸ‘ˆ æ·»åŠ è¿™ä¸€è¡Œï¼
        self.methods = {
            "add": {"group": "math", "input_types": ["scalar"], "output_types": ["scalar"]},
            "multiply": {"group": "math", "input_types": ["scalar"], "output_types": ["scalar"]},
            "subtract": {"group": "math", "input_types": ["scalar"], "output_types": ["scalar"]},
            "relu": {"group": "activation", "input_types": ["scalar"], "output_types": ["scalar"]},
            "sigmoid": {"group": "activation", "input_types": ["scalar"], "output_types": ["scalar"]},
        }

    def clone(self):
        # è¿”å›ä¸€ä¸ªæ·±æ‹·è´
        import copy
        return copy.deepcopy(self)

    def process_random_method(self) -> Dict[str, Any]:
        # éšæœºé€‰ä¸€ä¸ªæ–¹æ³•ç»„
        group = np.random.choice(["math", "activation"])
        return {
            "valid_groups": [group],
            "selected_group": group,
            "method_candidates": [m for m, info in self.methods.items() if info.get('group') == group]
        }

    def append_nx_layer(self, plan: Dict[str, Any], discard_unmatched: str, discard_node_method_name: str):
        # éšæœºé€‰ä¸€ä¸ªæ–¹æ³•æ·»åŠ åˆ°å›¾ä¸­
        candidates = plan.get("method_candidates", [])
        if not candidates:
            return
        selected_method = np.random.choice(candidates)
        self.graph_processor.add_node_with_method(selected_method)

    def infer_with_graph(self, values: np.ndarray) -> np.ndarray:
        # æ¨¡æ‹Ÿï¼šå¯¹è¾“å…¥åŠ ä¸€ä¸ªéšæœºæ‰°åŠ¨ï¼Œç”¨äºåˆ¶é€ ä¸åŒæŸå¤±
        np.random.seed(hash(str(self.graph_processor.get_structure_signature())) % (2**32))
        noise = np.random.normal(0, 0.1, size=values.shape)
        return values + noise  # æ¨¡æ‹Ÿè¾“å‡º

    def save_model(self, folder: str):
        # å ä½ï¼Œä¸å®é™…ä¿å­˜
        pass


class MockGraphProcessor:
    def __init__(self):
        self.graph = nx.DiGraph()
        self.node_counter = 0

    def add_node_with_method(self, method_name: str):
        node_id = f"node_{self.node_counter}"
        self.graph.add_node(node_id, method_name=method_name, group=method_name)
        self.node_counter += 1
        # ç®€å•è¿æ¥ï¼šå¦‚æœå­˜åœ¨å‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå°±è¿èµ·æ¥
        if self.node_counter > 1:
            prev_node = f"node_{self.node_counter - 2}"
            self.graph.add_edge(prev_node, node_id)

    def _is_processing_node(self, node: str) -> bool:
        return True  # æ‰€æœ‰èŠ‚ç‚¹éƒ½è§†ä¸ºå¤„ç†èŠ‚ç‚¹

    def get_structure_signature(self) -> str:
        """è¿”å›å›¾ç»“æ„çš„ç­¾åï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ä¸åŒ"""
        methods = [
            self.graph.nodes[node]['method_name']
            for node in sorted(self.graph.nodes)
        ]
        return "_".join(methods)
    
    def infer_with_graph(self, values: np.ndarray) -> np.ndarray:
        # å§”æ‰˜ç»™å¤–å±‚ adaptoflux å®ä¾‹ï¼ˆæˆ‘ä»¬å‡è®¾å®ƒå­˜åœ¨ï¼‰
        # åœ¨ MockAdaptoFlux ä¸­ï¼Œæˆ‘ä»¬å·²å®šä¹‰ infer_with_graph
        # æ‰€ä»¥è¿™é‡Œç›´æ¥è°ƒç”¨å¤–å±‚å®ä¾‹çš„æ–¹æ³•
        if hasattr(self, '_parent') and self._parent:
            return self._parent.infer_with_graph(values)
        else:
            # å¤‡ç”¨ï¼šè¿”å›è¾“å…¥å€¼åŠ å™ªå£°
            np.random.seed(hash(str(self.get_structure_signature())) % (2**32))
            noise = np.random.normal(0, 0.1, size=values.shape)
            return values + noise


# =============== æµ‹è¯•å‡½æ•° ===============
def test_phase1_fixed_mode():
    print("\n" + "="*60)
    print("ğŸ§ª TEST 1: Fixed Mode Initialization (All models with 3 layers)")
    print("="*60)

    # åˆ›å»º mock å®ä¾‹
    mock_af = MockAdaptoFlux()

    # åˆ›å»º trainer
    trainer = GraphEvoTrainer(
        adaptoflux_instance=mock_af,
        num_initial_models=5,
        max_init_layers=3,
        init_mode="fixed",
        verbose=True
    )

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    X = np.random.randn(10, 1).astype(np.float32)
    y = (X > 0).astype(np.float32)

    # æ‰§è¡Œç¬¬ä¸€é˜¶æ®µ
    result = trainer._phase_diverse_initialization(X, y)

    # éªŒè¯ç»“æœ
    assert result is not None
    assert 'best_model' in result
    assert 'best_loss' in result
    assert 'best_accuracy' in result

    print(f"\nâœ… Selected best model with Loss: {result['best_loss']:.6f}, Accuracy: {result['best_accuracy']:.4f}")

    # éªŒè¯æ˜¯å¦çœŸçš„ç”Ÿæˆäº†ä¸åŒç»“æ„
    print("\nğŸ” Checking if generated models have different structures...")
    structures = set()
    for i in range(trainer.num_initial_models):
        # é‡æ–°ç”Ÿæˆï¼ˆä¸ºäº†æµ‹è¯•ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹ï¼‰
        temp_af = mock_af.clone()
        trainer._randomly_initialize_graph(temp_af, num_layers_to_add=3)
        sig = temp_af.graph_processor.get_structure_signature()
        structures.add(sig)
        print(f"  Candidate {i+1} structure: {sig}")

    if len(structures) > 1:
        print(f"âœ… Detected {len(structures)} unique structures out of {trainer.num_initial_models} candidates.")
    else:
        print("âš ï¸  Warning: All candidates have identical structure. Randomness may be broken.")


def test_phase1_list_mode():
    print("\n" + "="*60)
    print("ğŸ§ª TEST 2: List Mode Initialization (Custom layer counts: [1, 2, 3, 2, 1])")
    print("="*60)

    mock_af = MockAdaptoFlux()

    trainer = GraphEvoTrainer(
        adaptoflux_instance=mock_af,
        num_initial_models=5,
        init_mode="list",
        init_layers_list=[1, 2, 3, 2, 1],  # æ¯ä¸ªå€™é€‰æ¨¡å‹çš„å±‚æ•°
        verbose=True
    )

    X = np.random.randn(10, 1).astype(np.float32)
    y = (X > 0).astype(np.float32)

    result = trainer._phase_diverse_initialization(X, y)

    assert result is not None
    print(f"\nâœ… Selected best model with Loss: {result['best_loss']:.6f}, Accuracy: {result['best_accuracy']:.4f}")

    # éªŒè¯æ¯ä¸ªæ¨¡å‹çš„å±‚æ•°æ˜¯å¦ç¬¦åˆé¢„æœŸ
    print("\nğŸ” Verifying layer counts per candidate...")
    expected_layers = [1, 2, 3, 2, 1]
    for i in range(len(expected_layers)):
        temp_af = mock_af.clone()
        trainer._randomly_initialize_graph(temp_af, num_layers_to_add=expected_layers[i])
        node_count = len(temp_af.graph_processor.graph.nodes)
        print(f"  Candidate {i+1}: expected {expected_layers[i]} layers, got {node_count} nodes")
        assert node_count == expected_layers[i], f"Candidate {i+1} layer count mismatch!"


def test_phase1_best_selection():
    print("\n" + "="*60)
    print("ğŸ§ª TEST 3: Best Model Selection (Does it pick the lowest loss?)")
    print("="*60)

    mock_af = MockAdaptoFlux()

    # å›ºå®šéšæœºç§å­ï¼Œè®©è¾“å‡ºå¯é¢„æµ‹ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
    np.random.seed(42)

    trainer = GraphEvoTrainer(
        adaptoflux_instance=mock_af,
        num_initial_models=3,
        max_init_layers=2,
        init_mode="fixed",
        verbose=True
    )

    X = np.array([[1.0], [2.0], [3.0]], dtype=np.float32)
    y = np.array([[0.0], [1.0], [1.0]], dtype=np.float32)

    # æˆ‘ä»¬ monkey-patch _evaluate_loss_with_instance ä»¥ä¾¿æ§åˆ¶æŸå¤±å€¼
    original_eval_loss = trainer._evaluate_loss_with_instance

    # æ¨¡æ‹Ÿä¸åŒæ¨¡å‹è¿”å›ä¸åŒæŸå¤±
    test_losses = [0.9, 0.3, 0.7]  # ç¬¬äºŒä¸ªæ¨¡å‹æŸå¤±æœ€ä½
    loss_iter = cycle(test_losses)

    def mock_eval_loss(instance, x, t):
        return next(loss_iter)

    trainer._evaluate_loss_with_instance = mock_eval_loss

    # ä¸´æ—¶ä¿®æ”¹ accuracy è¯„ä¼°ä¹Ÿè¿”å›å›ºå®šå€¼
    def mock_eval_acc(instance, x, t):
        return 1.0 - trainer._evaluate_loss_with_instance(instance, x, t)  # ç®€åŒ–

    trainer._evaluate_accuracy_with_instance = mock_eval_acc

    result = trainer._phase_diverse_initialization(X, y)

    print(f"\nğŸ¯ Expected best candidate: ID=1 (loss=0.3), Got ID={result['best_model'].id if hasattr(result['best_model'], 'id') else 'unknown'}")
    print(f"ğŸ“Š Returned best loss: {result['best_loss']:.4f}")

    # é‡ç½®æ–¹æ³•
    trainer._evaluate_loss_with_instance = original_eval_loss

    # æ‰‹åŠ¨éªŒè¯ï¼šæœ€å°æŸå¤±åº”ä¸º 0.3
    assert abs(result['best_loss'] - 0.3) < 1e-5, "Best model selection failed!"
    print("âœ… Best model selection passed!")


# =============== ä¸»ç¨‹åº ===============
if __name__ == "__main__":
    print("ğŸš€ Starting GraphEvoTrainer Phase 1 Tests...")

    test_phase1_fixed_mode()
    test_phase1_list_mode()
    test_phase1_best_selection()

    print("\nğŸ‰ All Phase 1 tests completed successfully!")